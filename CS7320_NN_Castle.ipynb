{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Name: James Castle\n",
    "# Class: CS 7320 Sec 401\n",
    "# Assignment 7: Neural Networks\n",
    "# This program represents the creation of a simple neural network that\n",
    "# predicts success (binary) based on a small set of input data."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a989b78d86b7c306"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Wolf\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T19:53:01.991553200Z",
     "start_time": "2023-12-02T19:52:57.464893Z"
    }
   },
   "id": "1b03457c4e6635b5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Read in file and setup Dataframe"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea97e5b8ce0a360b"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         f1        f2    f3    f4 rank state    f5  success\n",
      "0  0.018441  0.308841  0.18 -0.12   LO    TX -0.23        1\n",
      "1 -0.718349  0.695683 -0.47  1.01   HI    NY  0.95        0\n",
      "2  1.000000  0.000000  1.55  0.10   HI    NY  0.11        0\n",
      "3 -0.801414  0.598111 -0.21  0.24   HI   CAL  0.10        0\n",
      "4  1.900969  0.066116  2.12   NaN   HI   CAL -0.43        1\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 8 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   f1       100 non-null    float64\n",
      " 1   f2       100 non-null    float64\n",
      " 2   f3       99 non-null     float64\n",
      " 3   f4       99 non-null     float64\n",
      " 4   rank     100 non-null    object \n",
      " 5   state    100 non-null    object \n",
      " 6   f5       100 non-null    float64\n",
      " 7   success  100 non-null    int64  \n",
      "dtypes: float64(5), int64(1), object(2)\n",
      "memory usage: 6.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "file_name = \"7320.finaldata.csv\"\n",
    "# Read in file\n",
    "df = pd.read_csv(file_name, delimiter=\",\")\n",
    "\n",
    "print(df.head())\n",
    "print(df.info())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T19:54:08.043665800Z",
     "start_time": "2023-12-02T19:54:08.029100100Z"
    }
   },
   "id": "51ed12a99bcffdb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Start Data Cleaning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1f5f1d9ed0aaf8ff"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 98 entries, 0 to 99\n",
      "Data columns (total 8 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   f1       98 non-null     float64\n",
      " 1   f2       98 non-null     float64\n",
      " 2   f3       98 non-null     float64\n",
      " 3   f4       98 non-null     float64\n",
      " 4   rank     98 non-null     object \n",
      " 5   state    98 non-null     object \n",
      " 6   f5       98 non-null     float64\n",
      " 7   success  98 non-null     int64  \n",
      "dtypes: float64(5), int64(1), object(2)\n",
      "memory usage: 6.9+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 98 entries, 0 to 99\n",
      "Data columns (total 8 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   f1       98 non-null     float64\n",
      " 1   f2       98 non-null     float64\n",
      " 2   f3       98 non-null     float64\n",
      " 3   f4       98 non-null     float64\n",
      " 4   rank     98 non-null     int64  \n",
      " 5   state    98 non-null     object \n",
      " 6   f5       98 non-null     float64\n",
      " 7   success  98 non-null     int64  \n",
      "dtypes: float64(5), int64(2), object(1)\n",
      "memory usage: 6.9+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 98 entries, 0 to 99\n",
      "Data columns (total 8 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   f1       98 non-null     float64\n",
      " 1   f2       98 non-null     float64\n",
      " 2   f3       98 non-null     float64\n",
      " 3   f4       98 non-null     float64\n",
      " 4   rank     98 non-null     int64  \n",
      " 5   state    98 non-null     int64  \n",
      " 6   f5       98 non-null     float64\n",
      " 7   success  98 non-null     int64  \n",
      "dtypes: float64(5), int64(3)\n",
      "memory usage: 6.9 KB\n",
      "None\n",
      "          f1        f2    f3    f4  rank  state    f5  success\n",
      "0   0.018441  0.308841  0.18 -0.12     0      2 -0.23        1\n",
      "1  -0.718349  0.695683 -0.47  1.01     2      1  0.95        0\n",
      "2   1.000000  0.000000  1.55  0.10     2      1  0.11        0\n",
      "3  -0.801414  0.598111 -0.21  0.24     2      0  0.10        0\n",
      "5   0.715472 -0.458668  0.92 -0.65     2      2 -0.61        1\n",
      "7   0.900969  0.433884  0.56  0.51     0      2  0.46        0\n",
      "8  -0.900969  0.433884 -1.11  0.69     2      2  0.67        0\n",
      "9   0.000000  0.500000  0.22  0.85     1      1  0.83        1\n",
      "10  0.997945  0.064070  0.89  0.82     1      0  0.93        0\n",
      "11 -0.032052  0.999486 -0.33  0.75     1      2  0.57        0\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna()  # Drop any rows with missing data\n",
    "print(df.info())  # have 3 columns (rank, state not in fl/int format\n",
    "df.replace({'rank': {'LO': 0, 'MED': 1, 'HI': 2}},\n",
    "           inplace=True)\n",
    "print(df.info())  # verify rank replaced with ints.\n",
    "df.replace({'state': {'CAL': 0, 'NY': 1, 'TX': 2}},\n",
    "           inplace=True)\n",
    "print(df.info())  # verify state replaced with ints\n",
    "print(df.head(10))\n",
    "\n",
    "seed = 0\n",
    "np.random.seed(seed)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T19:54:56.394077700Z",
     "start_time": "2023-12-02T19:54:56.358522800Z"
    }
   },
   "id": "dca1b5128d89df06"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Setup X and Y for Training and Validation sets. (Originally set as NParr\n",
    "However, decided to stay with Pandas DF for correlation mapping \n",
    "familiarity"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c8945f9aeccc3bb"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         f1        f2    f3    f4  rank  state    f5\n",
      "0  0.018441  0.308841  0.18 -0.12     0      2 -0.23\n",
      "1 -0.718349  0.695683 -0.47  1.01     2      1  0.95\n",
      "2  1.000000  0.000000  1.55  0.10     2      1  0.11\n",
      "3 -0.801414  0.598111 -0.21  0.24     2      0  0.10\n",
      "5  0.715472 -0.458668  0.92 -0.65     2      2 -0.61\n",
      "0    1\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "5    1\n",
      "Name: success, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# dataset = df.to_numpy()\n",
    "# X = dataset[:, 0:7]\n",
    "# Y = dataset[:, 7]\n",
    "\n",
    "# attempt to keep things as a pandas DF\n",
    "X = df.drop(['success'], axis=1)\n",
    "print(X.head())\n",
    "Y = df['success']\n",
    "print(Y.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T20:01:12.212475700Z",
     "start_time": "2023-12-02T20:01:12.188458700Z"
    }
   },
   "id": "b111735eaba7b108"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Setup Train Test Split for Model A"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c6c9af3e832478d8"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    Y,\n",
    "                                                    test_size=0.33,\n",
    "                                                    random_state=seed)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T20:04:41.636889200Z",
     "start_time": "2023-12-02T20:04:41.623109800Z"
    }
   },
   "id": "e4cc62996739b099"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define Model A\n",
    "* Sequential Model\n",
    "* Decorrelation: None\n",
    "* 7 input nodes (7 features)\n",
    "* 16 neuron hidden layer with RELU activation function\n",
    "* Single node output layer with sigmoid activation function\n",
    "  (due to yes/no binary output)\n",
    "\n",
    "Hyperparams:\n",
    "* Epochs: 100\n",
    "* Train-Test Split: 67/33\n",
    "* Batch Size: 32\n",
    "\n",
    "Compile model A using Binary Cross Entropy Loss function \n",
    "(due to binary output of success or not. Using adam optimizer and \n",
    "Accuracy as the metric of interest. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e7d4a5c125cf31d1"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part A model constructed\n"
     ]
    }
   ],
   "source": [
    "# Create NN and define hyperparams\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(16, input_shape=(7,),\n",
    "                       activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "print('Part A model constructed')\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer='adam', \n",
    "              metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T20:14:45.432942Z",
     "start_time": "2023-12-02T20:14:45.407547Z"
    }
   },
   "id": "426f221c3f7fa2a1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Run and Time Model A"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4bd4bbc8ef3f4df1"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------START PART A: Single Layer no std or decorr DF----\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3835 - accuracy: 0.8615 - val_loss: 0.4537 - val_accuracy: 0.7576\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3817 - accuracy: 0.8615 - val_loss: 0.4526 - val_accuracy: 0.7576\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3801 - accuracy: 0.8615 - val_loss: 0.4516 - val_accuracy: 0.7576\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3787 - accuracy: 0.8615 - val_loss: 0.4508 - val_accuracy: 0.7879\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3773 - accuracy: 0.8615 - val_loss: 0.4503 - val_accuracy: 0.7879\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3757 - accuracy: 0.8615 - val_loss: 0.4498 - val_accuracy: 0.7879\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3743 - accuracy: 0.8615 - val_loss: 0.4493 - val_accuracy: 0.7879\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3729 - accuracy: 0.8615 - val_loss: 0.4488 - val_accuracy: 0.7879\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3716 - accuracy: 0.8615 - val_loss: 0.4482 - val_accuracy: 0.7879\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3702 - accuracy: 0.8769 - val_loss: 0.4477 - val_accuracy: 0.7879\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3686 - accuracy: 0.8769 - val_loss: 0.4472 - val_accuracy: 0.7879\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3670 - accuracy: 0.8615 - val_loss: 0.4469 - val_accuracy: 0.7879\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3652 - accuracy: 0.8615 - val_loss: 0.4465 - val_accuracy: 0.7879\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3640 - accuracy: 0.8615 - val_loss: 0.4462 - val_accuracy: 0.7879\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3625 - accuracy: 0.8615 - val_loss: 0.4461 - val_accuracy: 0.7879\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3611 - accuracy: 0.8615 - val_loss: 0.4462 - val_accuracy: 0.7879\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3596 - accuracy: 0.8769 - val_loss: 0.4461 - val_accuracy: 0.7879\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3583 - accuracy: 0.8615 - val_loss: 0.4458 - val_accuracy: 0.7879\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3569 - accuracy: 0.8615 - val_loss: 0.4455 - val_accuracy: 0.7879\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3554 - accuracy: 0.8615 - val_loss: 0.4454 - val_accuracy: 0.7879\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3540 - accuracy: 0.8615 - val_loss: 0.4451 - val_accuracy: 0.7879\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3526 - accuracy: 0.8615 - val_loss: 0.4450 - val_accuracy: 0.7879\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3513 - accuracy: 0.8615 - val_loss: 0.4447 - val_accuracy: 0.7879\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3501 - accuracy: 0.8615 - val_loss: 0.4445 - val_accuracy: 0.7879\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3488 - accuracy: 0.8615 - val_loss: 0.4442 - val_accuracy: 0.7879\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3474 - accuracy: 0.8615 - val_loss: 0.4442 - val_accuracy: 0.7879\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3460 - accuracy: 0.8615 - val_loss: 0.4443 - val_accuracy: 0.7879\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3452 - accuracy: 0.8615 - val_loss: 0.4443 - val_accuracy: 0.7879\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3437 - accuracy: 0.8615 - val_loss: 0.4433 - val_accuracy: 0.7879\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3422 - accuracy: 0.8615 - val_loss: 0.4417 - val_accuracy: 0.7879\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3404 - accuracy: 0.8615 - val_loss: 0.4407 - val_accuracy: 0.7879\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3391 - accuracy: 0.8769 - val_loss: 0.4398 - val_accuracy: 0.7879\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3378 - accuracy: 0.8769 - val_loss: 0.4391 - val_accuracy: 0.7879\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3365 - accuracy: 0.8769 - val_loss: 0.4383 - val_accuracy: 0.7879\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3350 - accuracy: 0.8769 - val_loss: 0.4372 - val_accuracy: 0.7879\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3336 - accuracy: 0.8769 - val_loss: 0.4360 - val_accuracy: 0.7879\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3322 - accuracy: 0.8769 - val_loss: 0.4353 - val_accuracy: 0.7879\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3308 - accuracy: 0.8769 - val_loss: 0.4351 - val_accuracy: 0.7879\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3296 - accuracy: 0.8769 - val_loss: 0.4351 - val_accuracy: 0.7879\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3285 - accuracy: 0.8769 - val_loss: 0.4350 - val_accuracy: 0.7879\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3275 - accuracy: 0.8769 - val_loss: 0.4345 - val_accuracy: 0.7879\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3262 - accuracy: 0.8769 - val_loss: 0.4338 - val_accuracy: 0.7879\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3250 - accuracy: 0.8769 - val_loss: 0.4332 - val_accuracy: 0.7879\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3239 - accuracy: 0.8769 - val_loss: 0.4325 - val_accuracy: 0.7879\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3226 - accuracy: 0.8769 - val_loss: 0.4317 - val_accuracy: 0.7879\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3215 - accuracy: 0.8769 - val_loss: 0.4308 - val_accuracy: 0.7879\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3203 - accuracy: 0.8769 - val_loss: 0.4303 - val_accuracy: 0.7879\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3192 - accuracy: 0.8769 - val_loss: 0.4301 - val_accuracy: 0.7879\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3183 - accuracy: 0.8769 - val_loss: 0.4298 - val_accuracy: 0.7879\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3172 - accuracy: 0.8769 - val_loss: 0.4293 - val_accuracy: 0.7879\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3160 - accuracy: 0.8923 - val_loss: 0.4288 - val_accuracy: 0.7879\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3150 - accuracy: 0.8923 - val_loss: 0.4284 - val_accuracy: 0.7879\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3139 - accuracy: 0.8923 - val_loss: 0.4282 - val_accuracy: 0.7879\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3129 - accuracy: 0.8923 - val_loss: 0.4283 - val_accuracy: 0.7879\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3118 - accuracy: 0.8923 - val_loss: 0.4284 - val_accuracy: 0.7879\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3107 - accuracy: 0.8769 - val_loss: 0.4289 - val_accuracy: 0.7879\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3097 - accuracy: 0.8769 - val_loss: 0.4292 - val_accuracy: 0.7879\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3089 - accuracy: 0.8769 - val_loss: 0.4292 - val_accuracy: 0.7879\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3077 - accuracy: 0.8769 - val_loss: 0.4285 - val_accuracy: 0.7879\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3063 - accuracy: 0.8923 - val_loss: 0.4275 - val_accuracy: 0.7879\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3051 - accuracy: 0.8923 - val_loss: 0.4268 - val_accuracy: 0.7879\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3041 - accuracy: 0.8923 - val_loss: 0.4260 - val_accuracy: 0.7879\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3030 - accuracy: 0.8923 - val_loss: 0.4254 - val_accuracy: 0.7879\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3020 - accuracy: 0.9077 - val_loss: 0.4248 - val_accuracy: 0.7879\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3007 - accuracy: 0.9077 - val_loss: 0.4243 - val_accuracy: 0.7879\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2996 - accuracy: 0.9077 - val_loss: 0.4245 - val_accuracy: 0.7879\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2984 - accuracy: 0.9077 - val_loss: 0.4247 - val_accuracy: 0.7879\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2974 - accuracy: 0.9077 - val_loss: 0.4248 - val_accuracy: 0.7879\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2963 - accuracy: 0.9077 - val_loss: 0.4250 - val_accuracy: 0.7879\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2951 - accuracy: 0.9077 - val_loss: 0.4254 - val_accuracy: 0.7879\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2943 - accuracy: 0.9077 - val_loss: 0.4253 - val_accuracy: 0.7879\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2934 - accuracy: 0.8923 - val_loss: 0.4246 - val_accuracy: 0.7879\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2927 - accuracy: 0.8923 - val_loss: 0.4240 - val_accuracy: 0.7879\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2921 - accuracy: 0.8923 - val_loss: 0.4231 - val_accuracy: 0.7879\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2916 - accuracy: 0.8923 - val_loss: 0.4225 - val_accuracy: 0.7879\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2911 - accuracy: 0.8923 - val_loss: 0.4219 - val_accuracy: 0.7879\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2905 - accuracy: 0.8923 - val_loss: 0.4211 - val_accuracy: 0.7879\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2898 - accuracy: 0.9077 - val_loss: 0.4203 - val_accuracy: 0.7879\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2891 - accuracy: 0.9077 - val_loss: 0.4191 - val_accuracy: 0.7879\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2885 - accuracy: 0.9077 - val_loss: 0.4182 - val_accuracy: 0.7879\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2881 - accuracy: 0.9077 - val_loss: 0.4173 - val_accuracy: 0.7879\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2874 - accuracy: 0.9077 - val_loss: 0.4169 - val_accuracy: 0.7879\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2867 - accuracy: 0.9077 - val_loss: 0.4172 - val_accuracy: 0.7879\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2857 - accuracy: 0.9077 - val_loss: 0.4181 - val_accuracy: 0.7879\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2849 - accuracy: 0.9077 - val_loss: 0.4183 - val_accuracy: 0.7879\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2847 - accuracy: 0.9077 - val_loss: 0.4183 - val_accuracy: 0.7879\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2844 - accuracy: 0.9077 - val_loss: 0.4186 - val_accuracy: 0.7879\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2838 - accuracy: 0.9077 - val_loss: 0.4191 - val_accuracy: 0.7879\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2837 - accuracy: 0.9077 - val_loss: 0.4202 - val_accuracy: 0.7879\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2829 - accuracy: 0.9077 - val_loss: 0.4200 - val_accuracy: 0.7879\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2825 - accuracy: 0.9077 - val_loss: 0.4193 - val_accuracy: 0.7879\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2819 - accuracy: 0.9077 - val_loss: 0.4186 - val_accuracy: 0.7879\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2812 - accuracy: 0.9077 - val_loss: 0.4174 - val_accuracy: 0.7879\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2810 - accuracy: 0.9077 - val_loss: 0.4164 - val_accuracy: 0.7879\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2803 - accuracy: 0.9077 - val_loss: 0.4155 - val_accuracy: 0.7879\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2800 - accuracy: 0.9077 - val_loss: 0.4146 - val_accuracy: 0.7879\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2799 - accuracy: 0.9077 - val_loss: 0.4140 - val_accuracy: 0.7879\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2794 - accuracy: 0.9077 - val_loss: 0.4137 - val_accuracy: 0.7879\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2788 - accuracy: 0.9077 - val_loss: 0.4136 - val_accuracy: 0.7879\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.2781 - accuracy: 0.9077 - val_loss: 0.4134 - val_accuracy: 0.7879\n",
      "3.1412 seconds elapsed.\n"
     ]
    }
   ],
   "source": [
    "print('--------START PART A: Single Layer no std or decorr DF----')\n",
    "tic = time.time()\n",
    "# fit model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
    "          epochs=100, batch_size=32)\n",
    "toc = time.time()\n",
    "print(f'{(toc - tic):.04f} seconds elapsed.')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T20:16:32.927393Z",
     "start_time": "2023-12-02T20:16:29.783779600Z"
    }
   },
   "id": "f9e441bc7952f5ca"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Standardize the Data for Part B1 using StandardScaler\n",
    "Use fit_transform on the training data and transform on test data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "269b78560570c842"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T20:26:24.427899200Z",
     "start_time": "2023-12-02T20:26:24.420663700Z"
    }
   },
   "id": "f3b9e6ea0e4f5509"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Run Model B1:\n",
    "Uses the same setup as model A. \n",
    "    Note: Doing this allows for the model to\n",
    "    start at the previously trained level from Test A.\n",
    "\n",
    "The only change here is that we are\n",
    "using the new standardized training and testing inputs \n",
    "from StandardScaler\n",
    "\n",
    "Hyperparams:\n",
    "* Epochs: 100\n",
    "* Train-Test Split: 67/33\n",
    "* Batch Size: 32"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a1234ac01038ba47"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------START PART B1: STANDARDIZED TEST-------------\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.3328 - accuracy: 0.8615 - val_loss: 0.4864 - val_accuracy: 0.7273\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3288 - accuracy: 0.8769 - val_loss: 0.4785 - val_accuracy: 0.7576\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3221 - accuracy: 0.8923 - val_loss: 0.4704 - val_accuracy: 0.7576\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3161 - accuracy: 0.8923 - val_loss: 0.4639 - val_accuracy: 0.7879\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3108 - accuracy: 0.8923 - val_loss: 0.4585 - val_accuracy: 0.8485\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3052 - accuracy: 0.8923 - val_loss: 0.4542 - val_accuracy: 0.8788\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3008 - accuracy: 0.8923 - val_loss: 0.4504 - val_accuracy: 0.8788\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2965 - accuracy: 0.8923 - val_loss: 0.4473 - val_accuracy: 0.8788\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2935 - accuracy: 0.8923 - val_loss: 0.4445 - val_accuracy: 0.8788\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2904 - accuracy: 0.8923 - val_loss: 0.4420 - val_accuracy: 0.8788\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2873 - accuracy: 0.8923 - val_loss: 0.4401 - val_accuracy: 0.8788\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2848 - accuracy: 0.8923 - val_loss: 0.4386 - val_accuracy: 0.8788\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2826 - accuracy: 0.8923 - val_loss: 0.4373 - val_accuracy: 0.8788\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2808 - accuracy: 0.8923 - val_loss: 0.4357 - val_accuracy: 0.8788\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2780 - accuracy: 0.8923 - val_loss: 0.4337 - val_accuracy: 0.8788\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2757 - accuracy: 0.8923 - val_loss: 0.4321 - val_accuracy: 0.8788\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2733 - accuracy: 0.8923 - val_loss: 0.4307 - val_accuracy: 0.8788\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2712 - accuracy: 0.8923 - val_loss: 0.4296 - val_accuracy: 0.8788\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2691 - accuracy: 0.8923 - val_loss: 0.4287 - val_accuracy: 0.8788\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2673 - accuracy: 0.8923 - val_loss: 0.4276 - val_accuracy: 0.8788\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2653 - accuracy: 0.8923 - val_loss: 0.4263 - val_accuracy: 0.8788\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2630 - accuracy: 0.8923 - val_loss: 0.4253 - val_accuracy: 0.8788\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2612 - accuracy: 0.8923 - val_loss: 0.4243 - val_accuracy: 0.8788\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2589 - accuracy: 0.8769 - val_loss: 0.4233 - val_accuracy: 0.8788\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2569 - accuracy: 0.8769 - val_loss: 0.4223 - val_accuracy: 0.8788\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2546 - accuracy: 0.8769 - val_loss: 0.4217 - val_accuracy: 0.8788\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2527 - accuracy: 0.8923 - val_loss: 0.4213 - val_accuracy: 0.8788\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2509 - accuracy: 0.8923 - val_loss: 0.4211 - val_accuracy: 0.8788\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2492 - accuracy: 0.9077 - val_loss: 0.4211 - val_accuracy: 0.8788\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2475 - accuracy: 0.9077 - val_loss: 0.4213 - val_accuracy: 0.8788\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2464 - accuracy: 0.9077 - val_loss: 0.4214 - val_accuracy: 0.8485\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2453 - accuracy: 0.9231 - val_loss: 0.4216 - val_accuracy: 0.8485\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2442 - accuracy: 0.9231 - val_loss: 0.4217 - val_accuracy: 0.8485\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2433 - accuracy: 0.9231 - val_loss: 0.4216 - val_accuracy: 0.8485\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2424 - accuracy: 0.9231 - val_loss: 0.4216 - val_accuracy: 0.8485\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2416 - accuracy: 0.9231 - val_loss: 0.4217 - val_accuracy: 0.8485\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2407 - accuracy: 0.9231 - val_loss: 0.4219 - val_accuracy: 0.8485\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2398 - accuracy: 0.9231 - val_loss: 0.4223 - val_accuracy: 0.8485\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2387 - accuracy: 0.9231 - val_loss: 0.4227 - val_accuracy: 0.8485\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2379 - accuracy: 0.9231 - val_loss: 0.4230 - val_accuracy: 0.8485\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2371 - accuracy: 0.9231 - val_loss: 0.4234 - val_accuracy: 0.8485\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2362 - accuracy: 0.9231 - val_loss: 0.4238 - val_accuracy: 0.8485\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2352 - accuracy: 0.9231 - val_loss: 0.4242 - val_accuracy: 0.8485\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2344 - accuracy: 0.9231 - val_loss: 0.4245 - val_accuracy: 0.8485\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2336 - accuracy: 0.9231 - val_loss: 0.4247 - val_accuracy: 0.8485\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2328 - accuracy: 0.9231 - val_loss: 0.4250 - val_accuracy: 0.8485\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2322 - accuracy: 0.9231 - val_loss: 0.4252 - val_accuracy: 0.8485\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2315 - accuracy: 0.9231 - val_loss: 0.4254 - val_accuracy: 0.8485\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2308 - accuracy: 0.9231 - val_loss: 0.4258 - val_accuracy: 0.8485\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2299 - accuracy: 0.9231 - val_loss: 0.4262 - val_accuracy: 0.8485\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2291 - accuracy: 0.9231 - val_loss: 0.4267 - val_accuracy: 0.8485\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2284 - accuracy: 0.9231 - val_loss: 0.4273 - val_accuracy: 0.8485\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2275 - accuracy: 0.9231 - val_loss: 0.4281 - val_accuracy: 0.8485\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2267 - accuracy: 0.9231 - val_loss: 0.4289 - val_accuracy: 0.8485\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2258 - accuracy: 0.9231 - val_loss: 0.4294 - val_accuracy: 0.8485\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2250 - accuracy: 0.9231 - val_loss: 0.4300 - val_accuracy: 0.8485\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2242 - accuracy: 0.9231 - val_loss: 0.4305 - val_accuracy: 0.8485\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2235 - accuracy: 0.9231 - val_loss: 0.4310 - val_accuracy: 0.8485\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2228 - accuracy: 0.9231 - val_loss: 0.4313 - val_accuracy: 0.8485\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2222 - accuracy: 0.9231 - val_loss: 0.4318 - val_accuracy: 0.8485\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2217 - accuracy: 0.9231 - val_loss: 0.4322 - val_accuracy: 0.8485\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2210 - accuracy: 0.9231 - val_loss: 0.4327 - val_accuracy: 0.8485\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2201 - accuracy: 0.9231 - val_loss: 0.4332 - val_accuracy: 0.8485\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2196 - accuracy: 0.9231 - val_loss: 0.4338 - val_accuracy: 0.8485\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2186 - accuracy: 0.9231 - val_loss: 0.4343 - val_accuracy: 0.8485\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2179 - accuracy: 0.9231 - val_loss: 0.4348 - val_accuracy: 0.8485\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2172 - accuracy: 0.9231 - val_loss: 0.4352 - val_accuracy: 0.8485\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2165 - accuracy: 0.9231 - val_loss: 0.4356 - val_accuracy: 0.8485\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2159 - accuracy: 0.9231 - val_loss: 0.4359 - val_accuracy: 0.8485\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2153 - accuracy: 0.9231 - val_loss: 0.4362 - val_accuracy: 0.8485\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2147 - accuracy: 0.9231 - val_loss: 0.4365 - val_accuracy: 0.8485\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2142 - accuracy: 0.9231 - val_loss: 0.4369 - val_accuracy: 0.8485\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2137 - accuracy: 0.9231 - val_loss: 0.4372 - val_accuracy: 0.8485\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2133 - accuracy: 0.9231 - val_loss: 0.4376 - val_accuracy: 0.8485\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2129 - accuracy: 0.9231 - val_loss: 0.4379 - val_accuracy: 0.8485\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2124 - accuracy: 0.9231 - val_loss: 0.4384 - val_accuracy: 0.8485\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2119 - accuracy: 0.9231 - val_loss: 0.4391 - val_accuracy: 0.8485\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2114 - accuracy: 0.9231 - val_loss: 0.4398 - val_accuracy: 0.8485\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2109 - accuracy: 0.9231 - val_loss: 0.4405 - val_accuracy: 0.8182\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2102 - accuracy: 0.9231 - val_loss: 0.4411 - val_accuracy: 0.8182\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2098 - accuracy: 0.9231 - val_loss: 0.4416 - val_accuracy: 0.8182\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2093 - accuracy: 0.9231 - val_loss: 0.4420 - val_accuracy: 0.8182\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2090 - accuracy: 0.9231 - val_loss: 0.4424 - val_accuracy: 0.8182\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2085 - accuracy: 0.9231 - val_loss: 0.4428 - val_accuracy: 0.8182\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2081 - accuracy: 0.9231 - val_loss: 0.4432 - val_accuracy: 0.8182\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2078 - accuracy: 0.9231 - val_loss: 0.4436 - val_accuracy: 0.8182\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2073 - accuracy: 0.9231 - val_loss: 0.4441 - val_accuracy: 0.8182\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2069 - accuracy: 0.9231 - val_loss: 0.4446 - val_accuracy: 0.8182\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2064 - accuracy: 0.9231 - val_loss: 0.4450 - val_accuracy: 0.8182\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2059 - accuracy: 0.9231 - val_loss: 0.4452 - val_accuracy: 0.8182\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2054 - accuracy: 0.9231 - val_loss: 0.4455 - val_accuracy: 0.8182\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2050 - accuracy: 0.9231 - val_loss: 0.4458 - val_accuracy: 0.8182\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2047 - accuracy: 0.9231 - val_loss: 0.4463 - val_accuracy: 0.8182\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2042 - accuracy: 0.9231 - val_loss: 0.4468 - val_accuracy: 0.8182\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2038 - accuracy: 0.9231 - val_loss: 0.4472 - val_accuracy: 0.8182\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2035 - accuracy: 0.9231 - val_loss: 0.4476 - val_accuracy: 0.8182\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2030 - accuracy: 0.9231 - val_loss: 0.4480 - val_accuracy: 0.8182\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2027 - accuracy: 0.9231 - val_loss: 0.4483 - val_accuracy: 0.8182\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2024 - accuracy: 0.9231 - val_loss: 0.4487 - val_accuracy: 0.8182\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2019 - accuracy: 0.9231 - val_loss: 0.4489 - val_accuracy: 0.8182\n",
      "3.4031 seconds elapsed.\n"
     ]
    }
   ],
   "source": [
    "print('-------------START PART B1: STANDARDIZED TEST-------------')\n",
    "tic = time.time()\n",
    "# fit model\n",
    "model.fit(X_train_std, y_train,\n",
    "          validation_data=(X_test_std, y_test), epochs=100, \n",
    "          batch_size=32)\n",
    "toc = time.time()\n",
    "print(f'{(toc - tic):.04f} seconds elapsed.')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T20:28:35.402184800Z",
     "start_time": "2023-12-02T20:28:31.995010600Z"
    }
   },
   "id": "4f05af9e72dffc5c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Check for highly correlated data. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b795afa85bb9f26"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corrMatrix = df.corr()\n",
    "sns.heatmap(corrMatrix, annot=True, cmap='viridis')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T20:36:43.342920100Z",
     "start_time": "2023-12-02T20:36:43.056454Z"
    }
   },
   "id": "25928030811cfd69"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Remove highly correlated data\n",
    "\tRemoving any correlations greater than +/- 90%\n",
    "\tI will drop the feature that is most highly correlated with the \n",
    "    target feature (i.e. success).\n",
    "\tIn this case, F1 is highly correlated with F3, but F1 is most \n",
    "    highly correlated with the target feature, so I will drop F1.\n",
    "\tF4 is also highly correlated with F5, but F4 is more highly \n",
    "    correlated with the target feature, so I will drop F4."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b112a5055c5b61ea"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         f1        f2    f3    f4  rank  state    f5  success\n",
      "0  0.018441  0.308841  0.18 -0.12     0      2 -0.23        1\n",
      "1 -0.718349  0.695683 -0.47  1.01     2      1  0.95        0\n",
      "2  1.000000  0.000000  1.55  0.10     2      1  0.11        0\n",
      "3 -0.801414  0.598111 -0.21  0.24     2      0  0.10        0\n",
      "5  0.715472 -0.458668  0.92 -0.65     2      2 -0.61        1\n",
      "         f2    f3  rank  state    f5  success\n",
      "0  0.308841  0.18     0      2 -0.23        1\n",
      "1  0.695683 -0.47     2      1  0.95        0\n",
      "2  0.000000  1.55     2      1  0.11        0\n",
      "3  0.598111 -0.21     2      0  0.10        0\n",
      "5 -0.458668  0.92     2      2 -0.61        1\n"
     ]
    }
   ],
   "source": [
    "corrDf = df\n",
    "print(corrDf.head())\n",
    "corrDf = corrDf.drop(['f1', 'f4'], axis=1)  # drop highly corr\n",
    "print(corrDf.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T20:37:59.137291900Z",
     "start_time": "2023-12-02T20:37:59.130053600Z"
    }
   },
   "id": "631f2898182c93a5"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show updated heatmap with correlated features removed\n",
    "corrMatrix = corrDf.corr()\n",
    "sns.heatmap(corrMatrix, annot=True, cmap='viridis')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T20:38:33.274497Z",
     "start_time": "2023-12-02T20:38:33.082556400Z"
    }
   },
   "id": "721e618fdd05a6d5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Verify revised X set has F1 and F4 features removed"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8dc08056d278c582"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         f2    f3  rank  state    f5\n",
      "0  0.308841  0.18     0      2 -0.23\n",
      "1  0.695683 -0.47     2      1  0.95\n",
      "2  0.000000  1.55     2      1  0.11\n",
      "3  0.598111 -0.21     2      0  0.10\n",
      "5 -0.458668  0.92     2      2 -0.61\n",
      "0    1\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "5    1\n",
      "Name: success, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_corr = corrDf.drop(['success'], axis=1)\n",
    "Y_corr = corrDf['success']\n",
    "print(X_corr.head())\n",
    "print(Y_corr.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T20:41:15.090481500Z",
     "start_time": "2023-12-02T20:41:15.083933400Z"
    }
   },
   "id": "7bdfdecf808d4d79"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Refit model on de-correlated dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3637d338800e9b07"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# 67% train, 33% test on de-correlated feature dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_corr,\n",
    "                                                    Y_corr,\n",
    "                                                    test_size=0.33,\n",
    "                                                    random_state=seed)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T20:41:20.268872600Z",
     "start_time": "2023-12-02T20:41:20.263869200Z"
    }
   },
   "id": "733a1e0d236ab7a2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Standardize Decorrelated Dataset as with part B1 for use in the B2 model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6bc210546baa29fd"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    " # Standardize Data with correlated features removed for part B2\n",
    "scaler = StandardScaler()\n",
    "X_train_std_corr = scaler.fit_transform(X_train)\n",
    "X_test_std_corr = scaler.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T20:42:15.547878600Z",
     "start_time": "2023-12-02T20:42:15.539064700Z"
    }
   },
   "id": "befff74f4d07a8c7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create model B2:\n",
    "* Uses same basic setup as model A and B1:\n",
    "    * single 16 neuron hidden layer with RELU activation\n",
    "    * single output layer with sigmoid activation\n",
    "    * uses the same loss function: Binary cross entropy\n",
    "    * uses the same optimizer: adam\n",
    "    * uses the same metrics: accuracy\n",
    "* However, uses a 5 node input layer due to only having 5 features as F1\n",
    "  and F4 have been removed (making up the original 7 features)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dbff700a01d9cc13"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part B2 model constructed\n"
     ]
    }
   ],
   "source": [
    "model_corr = keras.Sequential()\n",
    "model_corr.add(layers.Dense(16, input_shape=(5,),\n",
    "                            activation='relu'))  # for Part B\n",
    "model_corr.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# compile model\n",
    "model_corr.compile(loss=\"binary_crossentropy\", optimizer='adam',\n",
    "                   metrics=['accuracy'])\n",
    "print('Part B2 model constructed')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T20:46:13.677900300Z",
     "start_time": "2023-12-02T20:46:13.652895800Z"
    }
   },
   "id": "712794a2164c3057"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Run Model B2:\n",
    "* Standardized Data\n",
    "* De-Correlation: Dropping F1, F4\n",
    "* Input Layer: 5 neurons\n",
    "* Hidden Layers: 1\n",
    "    * Layer 1: 16 neurons; RELU\n",
    "* Output Layer: 1 neuron; Sigmoid\n",
    "* Loss fn: Binary Cross Entropy\n",
    "* Optimizer: Adam\n",
    "* Metrics: Accuracy\n",
    "\n",
    "Hyperparams:\n",
    "* Epochs: 100\n",
    "* Train-Test Split: 67/33\n",
    "* Batch Size: 32"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "be564efd8583ebd3"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------START PART B2: DECORRELATED & STANDARDIZED TEST----\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 65ms/step - loss: 0.5607 - accuracy: 0.8000 - val_loss: 0.5747 - val_accuracy: 0.7879\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5537 - accuracy: 0.8154 - val_loss: 0.5713 - val_accuracy: 0.7879\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5493 - accuracy: 0.8308 - val_loss: 0.5684 - val_accuracy: 0.7879\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5449 - accuracy: 0.8462 - val_loss: 0.5652 - val_accuracy: 0.7879\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5397 - accuracy: 0.8462 - val_loss: 0.5620 - val_accuracy: 0.7879\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5350 - accuracy: 0.8462 - val_loss: 0.5589 - val_accuracy: 0.7879\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5308 - accuracy: 0.8462 - val_loss: 0.5561 - val_accuracy: 0.8182\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5267 - accuracy: 0.8615 - val_loss: 0.5530 - val_accuracy: 0.8182\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5221 - accuracy: 0.8615 - val_loss: 0.5497 - val_accuracy: 0.8182\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5171 - accuracy: 0.8615 - val_loss: 0.5464 - val_accuracy: 0.8182\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5119 - accuracy: 0.8615 - val_loss: 0.5430 - val_accuracy: 0.8182\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5067 - accuracy: 0.8769 - val_loss: 0.5399 - val_accuracy: 0.8182\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5018 - accuracy: 0.8923 - val_loss: 0.5369 - val_accuracy: 0.8182\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4974 - accuracy: 0.8923 - val_loss: 0.5338 - val_accuracy: 0.8485\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4927 - accuracy: 0.8923 - val_loss: 0.5307 - val_accuracy: 0.8485\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4886 - accuracy: 0.9077 - val_loss: 0.5279 - val_accuracy: 0.8485\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4846 - accuracy: 0.8923 - val_loss: 0.5253 - val_accuracy: 0.8485\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4805 - accuracy: 0.8923 - val_loss: 0.5229 - val_accuracy: 0.8485\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4765 - accuracy: 0.8923 - val_loss: 0.5205 - val_accuracy: 0.8485\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4724 - accuracy: 0.9077 - val_loss: 0.5181 - val_accuracy: 0.8182\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4683 - accuracy: 0.9231 - val_loss: 0.5156 - val_accuracy: 0.8182\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4642 - accuracy: 0.9385 - val_loss: 0.5130 - val_accuracy: 0.8182\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4603 - accuracy: 0.9385 - val_loss: 0.5105 - val_accuracy: 0.8182\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4563 - accuracy: 0.9385 - val_loss: 0.5082 - val_accuracy: 0.8182\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4525 - accuracy: 0.9538 - val_loss: 0.5062 - val_accuracy: 0.8182\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4486 - accuracy: 0.9538 - val_loss: 0.5042 - val_accuracy: 0.8182\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4446 - accuracy: 0.9538 - val_loss: 0.5021 - val_accuracy: 0.8182\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4408 - accuracy: 0.9538 - val_loss: 0.5004 - val_accuracy: 0.8182\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4371 - accuracy: 0.9538 - val_loss: 0.4990 - val_accuracy: 0.8182\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4340 - accuracy: 0.9538 - val_loss: 0.4980 - val_accuracy: 0.8182\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4311 - accuracy: 0.9538 - val_loss: 0.4965 - val_accuracy: 0.8182\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4279 - accuracy: 0.9538 - val_loss: 0.4944 - val_accuracy: 0.8182\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4248 - accuracy: 0.9538 - val_loss: 0.4922 - val_accuracy: 0.8182\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4216 - accuracy: 0.9538 - val_loss: 0.4903 - val_accuracy: 0.8182\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4188 - accuracy: 0.9538 - val_loss: 0.4885 - val_accuracy: 0.8182\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4160 - accuracy: 0.9538 - val_loss: 0.4866 - val_accuracy: 0.8182\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4130 - accuracy: 0.9538 - val_loss: 0.4847 - val_accuracy: 0.8182\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4099 - accuracy: 0.9538 - val_loss: 0.4830 - val_accuracy: 0.8182\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4070 - accuracy: 0.9538 - val_loss: 0.4812 - val_accuracy: 0.8182\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4041 - accuracy: 0.9538 - val_loss: 0.4795 - val_accuracy: 0.8182\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4013 - accuracy: 0.9538 - val_loss: 0.4777 - val_accuracy: 0.8182\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3984 - accuracy: 0.9538 - val_loss: 0.4760 - val_accuracy: 0.8182\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3955 - accuracy: 0.9538 - val_loss: 0.4744 - val_accuracy: 0.8182\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3925 - accuracy: 0.9538 - val_loss: 0.4729 - val_accuracy: 0.8182\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3897 - accuracy: 0.9538 - val_loss: 0.4711 - val_accuracy: 0.8182\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3868 - accuracy: 0.9692 - val_loss: 0.4691 - val_accuracy: 0.8182\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3839 - accuracy: 0.9692 - val_loss: 0.4673 - val_accuracy: 0.8182\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3811 - accuracy: 0.9692 - val_loss: 0.4653 - val_accuracy: 0.8182\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3784 - accuracy: 0.9692 - val_loss: 0.4632 - val_accuracy: 0.8182\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3755 - accuracy: 0.9692 - val_loss: 0.4611 - val_accuracy: 0.8182\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3728 - accuracy: 0.9692 - val_loss: 0.4594 - val_accuracy: 0.8182\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3704 - accuracy: 0.9692 - val_loss: 0.4581 - val_accuracy: 0.8182\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3683 - accuracy: 0.9692 - val_loss: 0.4564 - val_accuracy: 0.8182\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3660 - accuracy: 0.9692 - val_loss: 0.4547 - val_accuracy: 0.8182\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3637 - accuracy: 0.9692 - val_loss: 0.4532 - val_accuracy: 0.8182\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3614 - accuracy: 0.9692 - val_loss: 0.4519 - val_accuracy: 0.8182\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3590 - accuracy: 0.9692 - val_loss: 0.4507 - val_accuracy: 0.8182\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3569 - accuracy: 0.9692 - val_loss: 0.4493 - val_accuracy: 0.8182\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3546 - accuracy: 0.9692 - val_loss: 0.4478 - val_accuracy: 0.8182\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3523 - accuracy: 0.9692 - val_loss: 0.4463 - val_accuracy: 0.8182\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3501 - accuracy: 0.9692 - val_loss: 0.4448 - val_accuracy: 0.8182\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3478 - accuracy: 0.9538 - val_loss: 0.4433 - val_accuracy: 0.8182\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3453 - accuracy: 0.9538 - val_loss: 0.4419 - val_accuracy: 0.8182\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3431 - accuracy: 0.9538 - val_loss: 0.4405 - val_accuracy: 0.8182\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3410 - accuracy: 0.9538 - val_loss: 0.4392 - val_accuracy: 0.8182\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3388 - accuracy: 0.9538 - val_loss: 0.4380 - val_accuracy: 0.8182\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3367 - accuracy: 0.9538 - val_loss: 0.4369 - val_accuracy: 0.8182\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3346 - accuracy: 0.9538 - val_loss: 0.4358 - val_accuracy: 0.8182\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3325 - accuracy: 0.9538 - val_loss: 0.4348 - val_accuracy: 0.8182\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3305 - accuracy: 0.9538 - val_loss: 0.4339 - val_accuracy: 0.8182\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3285 - accuracy: 0.9538 - val_loss: 0.4329 - val_accuracy: 0.8182\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3264 - accuracy: 0.9538 - val_loss: 0.4318 - val_accuracy: 0.8182\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3244 - accuracy: 0.9538 - val_loss: 0.4308 - val_accuracy: 0.8182\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3224 - accuracy: 0.9538 - val_loss: 0.4298 - val_accuracy: 0.8182\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3204 - accuracy: 0.9538 - val_loss: 0.4289 - val_accuracy: 0.8182\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3185 - accuracy: 0.9538 - val_loss: 0.4280 - val_accuracy: 0.8182\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3165 - accuracy: 0.9538 - val_loss: 0.4273 - val_accuracy: 0.8182\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3145 - accuracy: 0.9538 - val_loss: 0.4268 - val_accuracy: 0.8182\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3128 - accuracy: 0.9538 - val_loss: 0.4267 - val_accuracy: 0.8182\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3114 - accuracy: 0.9538 - val_loss: 0.4264 - val_accuracy: 0.8182\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3099 - accuracy: 0.9538 - val_loss: 0.4258 - val_accuracy: 0.8182\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3082 - accuracy: 0.9538 - val_loss: 0.4250 - val_accuracy: 0.8182\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3065 - accuracy: 0.9538 - val_loss: 0.4243 - val_accuracy: 0.8182\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3050 - accuracy: 0.9538 - val_loss: 0.4238 - val_accuracy: 0.8182\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3038 - accuracy: 0.9538 - val_loss: 0.4233 - val_accuracy: 0.8182\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3024 - accuracy: 0.9538 - val_loss: 0.4226 - val_accuracy: 0.8182\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3009 - accuracy: 0.9538 - val_loss: 0.4217 - val_accuracy: 0.8182\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2995 - accuracy: 0.9538 - val_loss: 0.4208 - val_accuracy: 0.8182\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2981 - accuracy: 0.9538 - val_loss: 0.4199 - val_accuracy: 0.8182\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2966 - accuracy: 0.9538 - val_loss: 0.4192 - val_accuracy: 0.8182\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2954 - accuracy: 0.9538 - val_loss: 0.4188 - val_accuracy: 0.8182\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2942 - accuracy: 0.9538 - val_loss: 0.4182 - val_accuracy: 0.8182\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2930 - accuracy: 0.9538 - val_loss: 0.4176 - val_accuracy: 0.8182\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2915 - accuracy: 0.9538 - val_loss: 0.4170 - val_accuracy: 0.8182\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2901 - accuracy: 0.9538 - val_loss: 0.4166 - val_accuracy: 0.8182\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2886 - accuracy: 0.9538 - val_loss: 0.4163 - val_accuracy: 0.8182\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2869 - accuracy: 0.9538 - val_loss: 0.4160 - val_accuracy: 0.8182\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2853 - accuracy: 0.9538 - val_loss: 0.4156 - val_accuracy: 0.8182\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2837 - accuracy: 0.9538 - val_loss: 0.4152 - val_accuracy: 0.8182\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2822 - accuracy: 0.9538 - val_loss: 0.4148 - val_accuracy: 0.8182\n",
      "3.6393 seconds elapsed.\n"
     ]
    }
   ],
   "source": [
    "print('--------START PART B2: DECORRELATED & STANDARDIZED TEST----')\n",
    "tic = time.time()\n",
    "# fit model\n",
    "model_corr.fit(X_train_std_corr, y_train,\n",
    "               validation_data=(X_test_std_corr, y_test),\n",
    "               epochs=100, batch_size=32)\n",
    "toc = time.time()\n",
    "print(f'{(toc - tic):.04f} seconds elapsed.')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T20:48:37.185447700Z",
     "start_time": "2023-12-02T20:48:33.542154900Z"
    }
   },
   "id": "d96f78b2775a9a56"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Build Model C1\n",
    "Standardized Data \n",
    "Decorrelation: None\n",
    "* Input Layer: 7 neurons\n",
    "* Hidden Layers: 1\n",
    "    * Layer 1: 16 neurons; RELU\n",
    "* Output Layer: 1 neuron; Sigmoid\n",
    "* Loss fn: Binary Cross Entropy\n",
    "* Optimizer: Adam\n",
    "* Metrics: Accuracy\n",
    "\n",
    "Hyperparams:\n",
    "* Epochs: 100\n",
    "* Train-Test Split: 67/33\n",
    "* Batch Size: 32"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "11d50e51c34ed90c"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part C1 model constructed\n"
     ]
    }
   ],
   "source": [
    "modelC1 = keras.Sequential()\n",
    "modelC1.add(layers.Dense(16, input_shape=(7,),\n",
    "                        activation='relu'))\n",
    "modelC1.add(layers.Dense(16, activation='relu'))\n",
    "modelC1.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "modelC1.compile(loss=\"binary_crossentropy\", optimizer='adam',\n",
    "                metrics=['accuracy'])\n",
    "print('Part C1 model constructed')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T20:57:46.201664Z",
     "start_time": "2023-12-02T20:57:46.144624800Z"
    }
   },
   "id": "18dc57feeb1faae8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train and test model C1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4621e457b69eb34e"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----START PART C1: STANDARDIZED TEST w/ 2 hidden layers----\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 82ms/step - loss: 0.7145 - accuracy: 0.4769 - val_loss: 0.6797 - val_accuracy: 0.5152\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6982 - accuracy: 0.5077 - val_loss: 0.6692 - val_accuracy: 0.5758\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6875 - accuracy: 0.5692 - val_loss: 0.6603 - val_accuracy: 0.6061\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6782 - accuracy: 0.6000 - val_loss: 0.6528 - val_accuracy: 0.6061\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6700 - accuracy: 0.6308 - val_loss: 0.6452 - val_accuracy: 0.6061\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6618 - accuracy: 0.6615 - val_loss: 0.6371 - val_accuracy: 0.6061\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6530 - accuracy: 0.6615 - val_loss: 0.6284 - val_accuracy: 0.6364\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6440 - accuracy: 0.6769 - val_loss: 0.6196 - val_accuracy: 0.6364\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6348 - accuracy: 0.6615 - val_loss: 0.6115 - val_accuracy: 0.6667\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6256 - accuracy: 0.6923 - val_loss: 0.6041 - val_accuracy: 0.6667\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6179 - accuracy: 0.7077 - val_loss: 0.5971 - val_accuracy: 0.6667\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6101 - accuracy: 0.7385 - val_loss: 0.5900 - val_accuracy: 0.7273\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6025 - accuracy: 0.7231 - val_loss: 0.5826 - val_accuracy: 0.7273\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5945 - accuracy: 0.7231 - val_loss: 0.5756 - val_accuracy: 0.7273\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5870 - accuracy: 0.7385 - val_loss: 0.5691 - val_accuracy: 0.6970\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5795 - accuracy: 0.7385 - val_loss: 0.5631 - val_accuracy: 0.6970\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5725 - accuracy: 0.7538 - val_loss: 0.5578 - val_accuracy: 0.7576\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5663 - accuracy: 0.7538 - val_loss: 0.5528 - val_accuracy: 0.7879\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5597 - accuracy: 0.7692 - val_loss: 0.5478 - val_accuracy: 0.7879\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5531 - accuracy: 0.8000 - val_loss: 0.5428 - val_accuracy: 0.7879\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5469 - accuracy: 0.8154 - val_loss: 0.5379 - val_accuracy: 0.7879\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5407 - accuracy: 0.8154 - val_loss: 0.5332 - val_accuracy: 0.7879\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5345 - accuracy: 0.8154 - val_loss: 0.5286 - val_accuracy: 0.7879\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5289 - accuracy: 0.8154 - val_loss: 0.5241 - val_accuracy: 0.7879\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5236 - accuracy: 0.8154 - val_loss: 0.5200 - val_accuracy: 0.7576\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5182 - accuracy: 0.8308 - val_loss: 0.5161 - val_accuracy: 0.7879\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5128 - accuracy: 0.8308 - val_loss: 0.5120 - val_accuracy: 0.7879\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5077 - accuracy: 0.8308 - val_loss: 0.5083 - val_accuracy: 0.7879\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5028 - accuracy: 0.8462 - val_loss: 0.5051 - val_accuracy: 0.7879\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4982 - accuracy: 0.8462 - val_loss: 0.5022 - val_accuracy: 0.7879\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4940 - accuracy: 0.8462 - val_loss: 0.4990 - val_accuracy: 0.7879\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4895 - accuracy: 0.8308 - val_loss: 0.4957 - val_accuracy: 0.7879\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4847 - accuracy: 0.8308 - val_loss: 0.4923 - val_accuracy: 0.7879\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4798 - accuracy: 0.8308 - val_loss: 0.4887 - val_accuracy: 0.8182\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4743 - accuracy: 0.8308 - val_loss: 0.4850 - val_accuracy: 0.8182\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4688 - accuracy: 0.8462 - val_loss: 0.4814 - val_accuracy: 0.8182\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4630 - accuracy: 0.8615 - val_loss: 0.4779 - val_accuracy: 0.8182\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4576 - accuracy: 0.8615 - val_loss: 0.4743 - val_accuracy: 0.8182\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4518 - accuracy: 0.8769 - val_loss: 0.4708 - val_accuracy: 0.8182\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4459 - accuracy: 0.8769 - val_loss: 0.4669 - val_accuracy: 0.8485\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4402 - accuracy: 0.8769 - val_loss: 0.4631 - val_accuracy: 0.8485\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4347 - accuracy: 0.8769 - val_loss: 0.4597 - val_accuracy: 0.8485\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4290 - accuracy: 0.8769 - val_loss: 0.4561 - val_accuracy: 0.8485\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4234 - accuracy: 0.8769 - val_loss: 0.4523 - val_accuracy: 0.8485\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4176 - accuracy: 0.8923 - val_loss: 0.4486 - val_accuracy: 0.8485\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4120 - accuracy: 0.8923 - val_loss: 0.4450 - val_accuracy: 0.8485\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4063 - accuracy: 0.8769 - val_loss: 0.4415 - val_accuracy: 0.8485\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4006 - accuracy: 0.8769 - val_loss: 0.4379 - val_accuracy: 0.8485\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3948 - accuracy: 0.8769 - val_loss: 0.4346 - val_accuracy: 0.8485\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3893 - accuracy: 0.8769 - val_loss: 0.4319 - val_accuracy: 0.8485\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3845 - accuracy: 0.8769 - val_loss: 0.4302 - val_accuracy: 0.8485\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3805 - accuracy: 0.8923 - val_loss: 0.4284 - val_accuracy: 0.8485\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3763 - accuracy: 0.8923 - val_loss: 0.4262 - val_accuracy: 0.8485\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3718 - accuracy: 0.8923 - val_loss: 0.4240 - val_accuracy: 0.8485\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3674 - accuracy: 0.8923 - val_loss: 0.4218 - val_accuracy: 0.8485\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3626 - accuracy: 0.9077 - val_loss: 0.4193 - val_accuracy: 0.8485\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3578 - accuracy: 0.9077 - val_loss: 0.4168 - val_accuracy: 0.8485\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3527 - accuracy: 0.9077 - val_loss: 0.4138 - val_accuracy: 0.8485\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3474 - accuracy: 0.9077 - val_loss: 0.4109 - val_accuracy: 0.8485\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3421 - accuracy: 0.9231 - val_loss: 0.4087 - val_accuracy: 0.8485\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3369 - accuracy: 0.9385 - val_loss: 0.4063 - val_accuracy: 0.8485\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3323 - accuracy: 0.9385 - val_loss: 0.4041 - val_accuracy: 0.8182\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3280 - accuracy: 0.9385 - val_loss: 0.4023 - val_accuracy: 0.8485\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3238 - accuracy: 0.9385 - val_loss: 0.4004 - val_accuracy: 0.8485\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3195 - accuracy: 0.9385 - val_loss: 0.3983 - val_accuracy: 0.8182\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3155 - accuracy: 0.9385 - val_loss: 0.3966 - val_accuracy: 0.8182\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3115 - accuracy: 0.9385 - val_loss: 0.3949 - val_accuracy: 0.8182\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3078 - accuracy: 0.9385 - val_loss: 0.3930 - val_accuracy: 0.8182\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3036 - accuracy: 0.9385 - val_loss: 0.3911 - val_accuracy: 0.8182\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2997 - accuracy: 0.9385 - val_loss: 0.3896 - val_accuracy: 0.8182\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2959 - accuracy: 0.9385 - val_loss: 0.3884 - val_accuracy: 0.8182\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2923 - accuracy: 0.9385 - val_loss: 0.3874 - val_accuracy: 0.8182\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2889 - accuracy: 0.9385 - val_loss: 0.3865 - val_accuracy: 0.8182\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2856 - accuracy: 0.9385 - val_loss: 0.3856 - val_accuracy: 0.8182\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2820 - accuracy: 0.9385 - val_loss: 0.3847 - val_accuracy: 0.8182\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2789 - accuracy: 0.9385 - val_loss: 0.3841 - val_accuracy: 0.8485\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2760 - accuracy: 0.9385 - val_loss: 0.3834 - val_accuracy: 0.8485\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2727 - accuracy: 0.9385 - val_loss: 0.3827 - val_accuracy: 0.8485\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2695 - accuracy: 0.9385 - val_loss: 0.3818 - val_accuracy: 0.8182\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2664 - accuracy: 0.9385 - val_loss: 0.3810 - val_accuracy: 0.8182\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2635 - accuracy: 0.9385 - val_loss: 0.3802 - val_accuracy: 0.8182\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2603 - accuracy: 0.9385 - val_loss: 0.3796 - val_accuracy: 0.8182\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2575 - accuracy: 0.9385 - val_loss: 0.3793 - val_accuracy: 0.8182\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2551 - accuracy: 0.9385 - val_loss: 0.3790 - val_accuracy: 0.8182\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2527 - accuracy: 0.9385 - val_loss: 0.3787 - val_accuracy: 0.8182\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2504 - accuracy: 0.9385 - val_loss: 0.3785 - val_accuracy: 0.8182\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2481 - accuracy: 0.9385 - val_loss: 0.3783 - val_accuracy: 0.8182\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2456 - accuracy: 0.9385 - val_loss: 0.3782 - val_accuracy: 0.8182\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2433 - accuracy: 0.9385 - val_loss: 0.3782 - val_accuracy: 0.8182\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2412 - accuracy: 0.9385 - val_loss: 0.3783 - val_accuracy: 0.8182\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2392 - accuracy: 0.9385 - val_loss: 0.3784 - val_accuracy: 0.8182\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2372 - accuracy: 0.9385 - val_loss: 0.3786 - val_accuracy: 0.8182\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2354 - accuracy: 0.9385 - val_loss: 0.3789 - val_accuracy: 0.8182\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2338 - accuracy: 0.9385 - val_loss: 0.3793 - val_accuracy: 0.8182\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2322 - accuracy: 0.9385 - val_loss: 0.3796 - val_accuracy: 0.8182\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2308 - accuracy: 0.9385 - val_loss: 0.3794 - val_accuracy: 0.8182\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2297 - accuracy: 0.9385 - val_loss: 0.3793 - val_accuracy: 0.8182\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2285 - accuracy: 0.9385 - val_loss: 0.3793 - val_accuracy: 0.8182\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2269 - accuracy: 0.9385 - val_loss: 0.3796 - val_accuracy: 0.8182\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2256 - accuracy: 0.9385 - val_loss: 0.3799 - val_accuracy: 0.8182\n",
      "3.7914 seconds elapsed.\n"
     ]
    }
   ],
   "source": [
    "print('----START PART C1: STANDARDIZED TEST w/ 2 hidden layers----')\n",
    "# fit new model with 7 inputs\n",
    "tic = time.time()\n",
    "modelC1.fit(X_train_std, y_train,\n",
    "            validation_data=(X_test_std, y_test),\n",
    "            epochs=100, batch_size=32)\n",
    "toc = time.time()\n",
    "print(f'{(toc - tic):.04f} seconds elapsed.')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T20:58:15.662279300Z",
     "start_time": "2023-12-02T20:58:11.864263300Z"
    }
   },
   "id": "48ca32e6922a40e7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Build Model C2\n",
    "Standardized Data\n",
    "De-Correlation: None\n",
    "* Input Layer: 7 neurons\n",
    "* Hidden Layers: 2\n",
    "    * Layer 1: 16 neurons; RELU\n",
    "    * Layer 2: 16 neurons; RELU\n",
    "* Output Layer: 1 neuron; Sigmoid\n",
    "* Loss fn: Binary Cross Entropy\n",
    "* Optimizer: Adam\n",
    "* Metrics: Accuracy\n",
    "\n",
    "Hyperparams:\n",
    "* Epochs: 100\n",
    "* Train-Test Split: 67/33\n",
    "* Batch Size: 32"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "40aa7c11b1e6667a"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part C2 model constructed\n"
     ]
    }
   ],
   "source": [
    "modelC2 = keras.Sequential()\n",
    "modelC2.add(layers.Dense(16, input_shape=(5,),\n",
    "                         activation='relu'))\n",
    "modelC2.add(layers.Dense(16, activation='relu'))\n",
    "modelC2.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "modelC2.compile(loss=\"binary_crossentropy\", optimizer='adam',\n",
    "                metrics=['accuracy'])\n",
    "print('Part C2 model constructed')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T21:11:25.605979400Z",
     "start_time": "2023-12-02T21:11:25.545430500Z"
    }
   },
   "id": "b236bda3b121ca3e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Test and time C2 (second hidden layer)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d2ab0fa59ac3bfb4"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---START PART C2: DECORRELATED & STD w/ 2 hidden layers----\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 72ms/step - loss: 0.6548 - accuracy: 0.6769 - val_loss: 0.6232 - val_accuracy: 0.6364\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6408 - accuracy: 0.6923 - val_loss: 0.6146 - val_accuracy: 0.6364\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6292 - accuracy: 0.7231 - val_loss: 0.6068 - val_accuracy: 0.6667\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6186 - accuracy: 0.7385 - val_loss: 0.5997 - val_accuracy: 0.6667\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6089 - accuracy: 0.7538 - val_loss: 0.5923 - val_accuracy: 0.6970\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5999 - accuracy: 0.7692 - val_loss: 0.5853 - val_accuracy: 0.7273\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5914 - accuracy: 0.7846 - val_loss: 0.5790 - val_accuracy: 0.7576\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5834 - accuracy: 0.7692 - val_loss: 0.5738 - val_accuracy: 0.7576\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5758 - accuracy: 0.7846 - val_loss: 0.5689 - val_accuracy: 0.7576\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5687 - accuracy: 0.8154 - val_loss: 0.5640 - val_accuracy: 0.7576\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5614 - accuracy: 0.8308 - val_loss: 0.5598 - val_accuracy: 0.7576\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5544 - accuracy: 0.8462 - val_loss: 0.5568 - val_accuracy: 0.7576\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5476 - accuracy: 0.8462 - val_loss: 0.5540 - val_accuracy: 0.7576\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5414 - accuracy: 0.8308 - val_loss: 0.5520 - val_accuracy: 0.7576\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5357 - accuracy: 0.8462 - val_loss: 0.5506 - val_accuracy: 0.7273\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5303 - accuracy: 0.8308 - val_loss: 0.5485 - val_accuracy: 0.7273\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5242 - accuracy: 0.8308 - val_loss: 0.5453 - val_accuracy: 0.7273\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5179 - accuracy: 0.8615 - val_loss: 0.5418 - val_accuracy: 0.7273\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5116 - accuracy: 0.8615 - val_loss: 0.5379 - val_accuracy: 0.7273\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5052 - accuracy: 0.8615 - val_loss: 0.5332 - val_accuracy: 0.7576\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4980 - accuracy: 0.8615 - val_loss: 0.5276 - val_accuracy: 0.7576\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4912 - accuracy: 0.8615 - val_loss: 0.5217 - val_accuracy: 0.7576\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4842 - accuracy: 0.8615 - val_loss: 0.5164 - val_accuracy: 0.7576\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4778 - accuracy: 0.8615 - val_loss: 0.5114 - val_accuracy: 0.7576\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4710 - accuracy: 0.8769 - val_loss: 0.5066 - val_accuracy: 0.7879\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4649 - accuracy: 0.8923 - val_loss: 0.5017 - val_accuracy: 0.7879\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4589 - accuracy: 0.9077 - val_loss: 0.4972 - val_accuracy: 0.7879\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4526 - accuracy: 0.8923 - val_loss: 0.4931 - val_accuracy: 0.7879\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4462 - accuracy: 0.8923 - val_loss: 0.4891 - val_accuracy: 0.7879\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4401 - accuracy: 0.8923 - val_loss: 0.4856 - val_accuracy: 0.7879\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4338 - accuracy: 0.8923 - val_loss: 0.4825 - val_accuracy: 0.7879\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4276 - accuracy: 0.9077 - val_loss: 0.4798 - val_accuracy: 0.7879\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4213 - accuracy: 0.9077 - val_loss: 0.4774 - val_accuracy: 0.7879\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4155 - accuracy: 0.9077 - val_loss: 0.4756 - val_accuracy: 0.7879\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4101 - accuracy: 0.9077 - val_loss: 0.4743 - val_accuracy: 0.7879\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4054 - accuracy: 0.9077 - val_loss: 0.4725 - val_accuracy: 0.7879\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4006 - accuracy: 0.9231 - val_loss: 0.4705 - val_accuracy: 0.7879\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3959 - accuracy: 0.9231 - val_loss: 0.4683 - val_accuracy: 0.7879\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3913 - accuracy: 0.9077 - val_loss: 0.4657 - val_accuracy: 0.7879\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3865 - accuracy: 0.9077 - val_loss: 0.4632 - val_accuracy: 0.7879\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3816 - accuracy: 0.9077 - val_loss: 0.4614 - val_accuracy: 0.7879\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3768 - accuracy: 0.9077 - val_loss: 0.4601 - val_accuracy: 0.7879\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3722 - accuracy: 0.9077 - val_loss: 0.4590 - val_accuracy: 0.7879\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3674 - accuracy: 0.9077 - val_loss: 0.4578 - val_accuracy: 0.7879\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3627 - accuracy: 0.9077 - val_loss: 0.4563 - val_accuracy: 0.7879\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3578 - accuracy: 0.9077 - val_loss: 0.4550 - val_accuracy: 0.7879\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3532 - accuracy: 0.9077 - val_loss: 0.4545 - val_accuracy: 0.7879\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3486 - accuracy: 0.9077 - val_loss: 0.4541 - val_accuracy: 0.7879\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3441 - accuracy: 0.9077 - val_loss: 0.4522 - val_accuracy: 0.7879\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3399 - accuracy: 0.9077 - val_loss: 0.4503 - val_accuracy: 0.7879\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3361 - accuracy: 0.9077 - val_loss: 0.4487 - val_accuracy: 0.7879\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3323 - accuracy: 0.9077 - val_loss: 0.4471 - val_accuracy: 0.7879\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3285 - accuracy: 0.9077 - val_loss: 0.4459 - val_accuracy: 0.7879\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3244 - accuracy: 0.9231 - val_loss: 0.4453 - val_accuracy: 0.7879\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3203 - accuracy: 0.9231 - val_loss: 0.4451 - val_accuracy: 0.7879\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3166 - accuracy: 0.9231 - val_loss: 0.4449 - val_accuracy: 0.7879\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3136 - accuracy: 0.9231 - val_loss: 0.4443 - val_accuracy: 0.7879\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3108 - accuracy: 0.9231 - val_loss: 0.4441 - val_accuracy: 0.7576\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3079 - accuracy: 0.9231 - val_loss: 0.4443 - val_accuracy: 0.7576\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3049 - accuracy: 0.9231 - val_loss: 0.4447 - val_accuracy: 0.7879\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3020 - accuracy: 0.9231 - val_loss: 0.4454 - val_accuracy: 0.7879\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2990 - accuracy: 0.9231 - val_loss: 0.4462 - val_accuracy: 0.7879\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2959 - accuracy: 0.9231 - val_loss: 0.4470 - val_accuracy: 0.7576\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2930 - accuracy: 0.9231 - val_loss: 0.4484 - val_accuracy: 0.7576\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2903 - accuracy: 0.9231 - val_loss: 0.4497 - val_accuracy: 0.7576\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2871 - accuracy: 0.9231 - val_loss: 0.4508 - val_accuracy: 0.7576\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.2840 - accuracy: 0.9231 - val_loss: 0.4523 - val_accuracy: 0.7576\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2811 - accuracy: 0.9231 - val_loss: 0.4539 - val_accuracy: 0.7576\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2784 - accuracy: 0.9231 - val_loss: 0.4559 - val_accuracy: 0.7576\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2753 - accuracy: 0.9231 - val_loss: 0.4572 - val_accuracy: 0.7576\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2723 - accuracy: 0.9231 - val_loss: 0.4585 - val_accuracy: 0.7576\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2696 - accuracy: 0.9231 - val_loss: 0.4594 - val_accuracy: 0.7576\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2668 - accuracy: 0.9385 - val_loss: 0.4603 - val_accuracy: 0.7576\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2641 - accuracy: 0.9385 - val_loss: 0.4605 - val_accuracy: 0.7576\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2617 - accuracy: 0.9231 - val_loss: 0.4605 - val_accuracy: 0.7576\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2590 - accuracy: 0.9231 - val_loss: 0.4611 - val_accuracy: 0.7576\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2563 - accuracy: 0.9231 - val_loss: 0.4621 - val_accuracy: 0.7576\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2540 - accuracy: 0.9231 - val_loss: 0.4637 - val_accuracy: 0.7576\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2515 - accuracy: 0.9231 - val_loss: 0.4652 - val_accuracy: 0.7576\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.2492 - accuracy: 0.9385 - val_loss: 0.4664 - val_accuracy: 0.7576\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2471 - accuracy: 0.9385 - val_loss: 0.4675 - val_accuracy: 0.7576\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2454 - accuracy: 0.9385 - val_loss: 0.4689 - val_accuracy: 0.7576\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2443 - accuracy: 0.9385 - val_loss: 0.4698 - val_accuracy: 0.7576\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2427 - accuracy: 0.9385 - val_loss: 0.4709 - val_accuracy: 0.7576\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2411 - accuracy: 0.9385 - val_loss: 0.4724 - val_accuracy: 0.7576\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2392 - accuracy: 0.9385 - val_loss: 0.4736 - val_accuracy: 0.7576\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2375 - accuracy: 0.9385 - val_loss: 0.4748 - val_accuracy: 0.7576\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2356 - accuracy: 0.9385 - val_loss: 0.4756 - val_accuracy: 0.7576\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2338 - accuracy: 0.9385 - val_loss: 0.4764 - val_accuracy: 0.7576\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2320 - accuracy: 0.9385 - val_loss: 0.4773 - val_accuracy: 0.7576\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2305 - accuracy: 0.9385 - val_loss: 0.4782 - val_accuracy: 0.7576\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2288 - accuracy: 0.9385 - val_loss: 0.4785 - val_accuracy: 0.7576\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2269 - accuracy: 0.9385 - val_loss: 0.4788 - val_accuracy: 0.7576\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2252 - accuracy: 0.9385 - val_loss: 0.4794 - val_accuracy: 0.7576\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2235 - accuracy: 0.9385 - val_loss: 0.4798 - val_accuracy: 0.7576\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2219 - accuracy: 0.9385 - val_loss: 0.4801 - val_accuracy: 0.7576\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2202 - accuracy: 0.9385 - val_loss: 0.4811 - val_accuracy: 0.7576\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2187 - accuracy: 0.9385 - val_loss: 0.4823 - val_accuracy: 0.7576\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2170 - accuracy: 0.9385 - val_loss: 0.4826 - val_accuracy: 0.7576\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2154 - accuracy: 0.9385 - val_loss: 0.4830 - val_accuracy: 0.7576\n",
      "3.8180 seconds elapsed.\n"
     ]
    }
   ],
   "source": [
    "print('---START PART C2: DECORRELATED & STD w/ 2 hidden layers----')\n",
    "\n",
    "# fit new model with 5 feature inputs (decorrelated)\n",
    "tic = time.time()\n",
    "modelC2.fit(X_train_std_corr, y_train,\n",
    "            validation_data=(X_test_std_corr, y_test),\n",
    "            epochs=100, batch_size=32)\n",
    "toc = time.time()\n",
    "print(f'{(toc - tic):.04f} seconds elapsed.')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T21:13:03.896492100Z",
     "start_time": "2023-12-02T21:13:00.075672100Z"
    }
   },
   "id": "50edb091bfd83739"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Experiment C3 (DROP F4):\n",
    "* Explore whether dropping a single feature (F1 OR F4) has an impact on \n",
    "  the model.\n",
    "* Still using 2 hidden layers\n",
    "\n",
    "Create new data frame dropping ONLY feature 4 (F4)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fdb70f52dc900388"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         f1        f2    f3  rank  state    f5  success\n",
      "0  0.018441  0.308841  0.18     0      2 -0.23        1\n",
      "1 -0.718349  0.695683 -0.47     2      1  0.95        0\n",
      "2  1.000000  0.000000  1.55     2      1  0.11        0\n",
      "3 -0.801414  0.598111 -0.21     2      0  0.10        0\n",
      "5  0.715472 -0.458668  0.92     2      2 -0.61        1\n"
     ]
    }
   ],
   "source": [
    "noF4df = df\n",
    "noF4df = noF4df.drop(['f4'], axis=1)\n",
    "print(noF4df.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T21:17:05.448300400Z",
     "start_time": "2023-12-02T21:17:05.434600300Z"
    }
   },
   "id": "af922cad64a6cd5d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train Test Split dataframe\n",
    "Standardize dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b3957e430b54d570"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         f1        f2    f3  rank  state    f5\n",
      "0  0.018441  0.308841  0.18     0      2 -0.23\n",
      "1 -0.718349  0.695683 -0.47     2      1  0.95\n",
      "2  1.000000  0.000000  1.55     2      1  0.11\n",
      "3 -0.801414  0.598111 -0.21     2      0  0.10\n",
      "5  0.715472 -0.458668  0.92     2      2 -0.61\n",
      "0    1\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "5    1\n",
      "Name: success, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Prep inputs for Train Test Split\n",
    "X_corr_noF4 = noF4df.drop(['success'], axis=1)\n",
    "Y_corr_noF4 = noF4df['success']\n",
    "print(X_corr_noF4.head())\n",
    "print(Y_corr_noF4.head())\n",
    "\n",
    "# 67% train, 33% test on de-correlated feature dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_corr_noF4,\n",
    "                                                    Y_corr_noF4,\n",
    "                                                    test_size=0.33,\n",
    "                                                    random_state=seed)\n",
    "# Standardize Data with correlated features removed for part C3\n",
    "scaler = StandardScaler()\n",
    "X_train_nof4 = scaler.fit_transform(X_train)\n",
    "X_test_nof4 = scaler.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T21:19:03.293653800Z",
     "start_time": "2023-12-02T21:19:03.278771300Z"
    }
   },
   "id": "aba583af84f2e613"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create new model C3:\n",
    "Standardized Data\n",
    "De-Correlation: Dropping F4\n",
    "* Input Layer: 6 neurons\n",
    "* Hidden Layers: 2\n",
    "    * Layer 1: 16 neurons; RELU\n",
    "    * Layer 2: 16 neurons; RELU\n",
    "* Output Layer: 1 neuron; Sigmoid\n",
    "* Loss fn: Binary Cross Entropy\n",
    "* Optimizer: Adam\n",
    "* Metrics: Accuracy\n",
    "\n",
    "Hyperparams:\n",
    "* Epochs: 100\n",
    "* Train-Test Split: 67/33\n",
    "* Batch Size: 32"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "17e3ee56e5909827"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part C3 model constructed\n"
     ]
    }
   ],
   "source": [
    "modelC3 = keras.Sequential()\n",
    "modelC3.add(layers.Dense(16, input_shape=(6,),\n",
    "                         activation='relu'))\n",
    "modelC3.add(layers.Dense(16, activation='relu'))\n",
    "modelC3.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "modelC3.compile(loss=\"binary_crossentropy\", optimizer='adam',\n",
    "                metrics=['accuracy'])\n",
    "print('Part C3 model constructed')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T21:29:22.692649700Z",
     "start_time": "2023-12-02T21:29:22.648880300Z"
    }
   },
   "id": "3b107c2d87d871f1"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---START PART C3: No F4, Std,  w/ 2 hidden layers----\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 61ms/step - loss: 0.7837 - accuracy: 0.3692 - val_loss: 0.7691 - val_accuracy: 0.3939\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.7672 - accuracy: 0.4000 - val_loss: 0.7542 - val_accuracy: 0.4545\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.7537 - accuracy: 0.4000 - val_loss: 0.7407 - val_accuracy: 0.4848\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.7425 - accuracy: 0.4462 - val_loss: 0.7288 - val_accuracy: 0.5455\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7321 - accuracy: 0.4769 - val_loss: 0.7187 - val_accuracy: 0.5455\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.7227 - accuracy: 0.4923 - val_loss: 0.7091 - val_accuracy: 0.5455\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.7141 - accuracy: 0.5077 - val_loss: 0.7004 - val_accuracy: 0.5758\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.7066 - accuracy: 0.5231 - val_loss: 0.6918 - val_accuracy: 0.5455\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6992 - accuracy: 0.5538 - val_loss: 0.6842 - val_accuracy: 0.6061\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6923 - accuracy: 0.5538 - val_loss: 0.6782 - val_accuracy: 0.6364\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6863 - accuracy: 0.5538 - val_loss: 0.6725 - val_accuracy: 0.6364\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6807 - accuracy: 0.5538 - val_loss: 0.6666 - val_accuracy: 0.6364\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6750 - accuracy: 0.5692 - val_loss: 0.6605 - val_accuracy: 0.6364\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6691 - accuracy: 0.5692 - val_loss: 0.6539 - val_accuracy: 0.6970\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6628 - accuracy: 0.6308 - val_loss: 0.6475 - val_accuracy: 0.6667\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6564 - accuracy: 0.6769 - val_loss: 0.6415 - val_accuracy: 0.7273\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6501 - accuracy: 0.6769 - val_loss: 0.6354 - val_accuracy: 0.7273\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6443 - accuracy: 0.6769 - val_loss: 0.6292 - val_accuracy: 0.7576\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6387 - accuracy: 0.7077 - val_loss: 0.6236 - val_accuracy: 0.8182\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6330 - accuracy: 0.7077 - val_loss: 0.6186 - val_accuracy: 0.8182\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6278 - accuracy: 0.7538 - val_loss: 0.6139 - val_accuracy: 0.8182\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6222 - accuracy: 0.7538 - val_loss: 0.6093 - val_accuracy: 0.8182\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6174 - accuracy: 0.7538 - val_loss: 0.6044 - val_accuracy: 0.8182\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6115 - accuracy: 0.7538 - val_loss: 0.5998 - val_accuracy: 0.8182\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6065 - accuracy: 0.7538 - val_loss: 0.5952 - val_accuracy: 0.7879\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6012 - accuracy: 0.7692 - val_loss: 0.5906 - val_accuracy: 0.7879\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5954 - accuracy: 0.7692 - val_loss: 0.5864 - val_accuracy: 0.7879\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5902 - accuracy: 0.7692 - val_loss: 0.5822 - val_accuracy: 0.7879\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5850 - accuracy: 0.7846 - val_loss: 0.5786 - val_accuracy: 0.7879\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5799 - accuracy: 0.8154 - val_loss: 0.5752 - val_accuracy: 0.7879\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5750 - accuracy: 0.8462 - val_loss: 0.5714 - val_accuracy: 0.7879\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5704 - accuracy: 0.8462 - val_loss: 0.5670 - val_accuracy: 0.7879\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5651 - accuracy: 0.8462 - val_loss: 0.5625 - val_accuracy: 0.7879\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5598 - accuracy: 0.8462 - val_loss: 0.5585 - val_accuracy: 0.8182\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5548 - accuracy: 0.8462 - val_loss: 0.5548 - val_accuracy: 0.8182\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5500 - accuracy: 0.8462 - val_loss: 0.5506 - val_accuracy: 0.8182\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5450 - accuracy: 0.8462 - val_loss: 0.5455 - val_accuracy: 0.8182\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5402 - accuracy: 0.8462 - val_loss: 0.5396 - val_accuracy: 0.8182\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5353 - accuracy: 0.8462 - val_loss: 0.5340 - val_accuracy: 0.8182\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5300 - accuracy: 0.8308 - val_loss: 0.5291 - val_accuracy: 0.8182\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5249 - accuracy: 0.8308 - val_loss: 0.5241 - val_accuracy: 0.8182\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5196 - accuracy: 0.8462 - val_loss: 0.5191 - val_accuracy: 0.8182\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5147 - accuracy: 0.8769 - val_loss: 0.5140 - val_accuracy: 0.8182\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5093 - accuracy: 0.8769 - val_loss: 0.5090 - val_accuracy: 0.8182\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5049 - accuracy: 0.8615 - val_loss: 0.5046 - val_accuracy: 0.8182\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5001 - accuracy: 0.8769 - val_loss: 0.5003 - val_accuracy: 0.8182\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4955 - accuracy: 0.9077 - val_loss: 0.4961 - val_accuracy: 0.8182\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4907 - accuracy: 0.9077 - val_loss: 0.4920 - val_accuracy: 0.8182\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4856 - accuracy: 0.9077 - val_loss: 0.4879 - val_accuracy: 0.8182\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4804 - accuracy: 0.9077 - val_loss: 0.4832 - val_accuracy: 0.8182\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4744 - accuracy: 0.9077 - val_loss: 0.4786 - val_accuracy: 0.8182\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4695 - accuracy: 0.9077 - val_loss: 0.4738 - val_accuracy: 0.8182\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4637 - accuracy: 0.9077 - val_loss: 0.4687 - val_accuracy: 0.7879\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4575 - accuracy: 0.9077 - val_loss: 0.4638 - val_accuracy: 0.7879\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4516 - accuracy: 0.9231 - val_loss: 0.4593 - val_accuracy: 0.7879\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4453 - accuracy: 0.9231 - val_loss: 0.4546 - val_accuracy: 0.7879\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4393 - accuracy: 0.9077 - val_loss: 0.4499 - val_accuracy: 0.8182\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4338 - accuracy: 0.9077 - val_loss: 0.4455 - val_accuracy: 0.8182\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4279 - accuracy: 0.9077 - val_loss: 0.4414 - val_accuracy: 0.8182\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4225 - accuracy: 0.9077 - val_loss: 0.4371 - val_accuracy: 0.8182\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4167 - accuracy: 0.9077 - val_loss: 0.4331 - val_accuracy: 0.8182\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4105 - accuracy: 0.9077 - val_loss: 0.4293 - val_accuracy: 0.7879\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4047 - accuracy: 0.9077 - val_loss: 0.4255 - val_accuracy: 0.7879\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3992 - accuracy: 0.9077 - val_loss: 0.4218 - val_accuracy: 0.7879\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3935 - accuracy: 0.8923 - val_loss: 0.4177 - val_accuracy: 0.7879\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3878 - accuracy: 0.9077 - val_loss: 0.4136 - val_accuracy: 0.7879\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3826 - accuracy: 0.9077 - val_loss: 0.4111 - val_accuracy: 0.8182\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3780 - accuracy: 0.9077 - val_loss: 0.4084 - val_accuracy: 0.8182\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3730 - accuracy: 0.9231 - val_loss: 0.4058 - val_accuracy: 0.8182\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3686 - accuracy: 0.9231 - val_loss: 0.4042 - val_accuracy: 0.8182\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.3648 - accuracy: 0.9231 - val_loss: 0.4024 - val_accuracy: 0.8182\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3605 - accuracy: 0.9231 - val_loss: 0.4000 - val_accuracy: 0.8182\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3561 - accuracy: 0.9231 - val_loss: 0.3973 - val_accuracy: 0.8485\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3524 - accuracy: 0.9231 - val_loss: 0.3950 - val_accuracy: 0.8485\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3482 - accuracy: 0.9231 - val_loss: 0.3926 - val_accuracy: 0.8485\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3442 - accuracy: 0.9385 - val_loss: 0.3906 - val_accuracy: 0.8485\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3402 - accuracy: 0.9385 - val_loss: 0.3898 - val_accuracy: 0.8485\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3365 - accuracy: 0.9385 - val_loss: 0.3887 - val_accuracy: 0.8485\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3323 - accuracy: 0.9385 - val_loss: 0.3871 - val_accuracy: 0.8485\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3284 - accuracy: 0.9385 - val_loss: 0.3850 - val_accuracy: 0.8485\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3240 - accuracy: 0.9385 - val_loss: 0.3825 - val_accuracy: 0.8485\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3197 - accuracy: 0.9385 - val_loss: 0.3795 - val_accuracy: 0.8485\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3155 - accuracy: 0.9385 - val_loss: 0.3771 - val_accuracy: 0.8485\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3113 - accuracy: 0.9385 - val_loss: 0.3748 - val_accuracy: 0.8485\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3071 - accuracy: 0.9385 - val_loss: 0.3724 - val_accuracy: 0.8485\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3027 - accuracy: 0.9385 - val_loss: 0.3706 - val_accuracy: 0.8485\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2985 - accuracy: 0.9385 - val_loss: 0.3695 - val_accuracy: 0.8485\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2946 - accuracy: 0.9385 - val_loss: 0.3684 - val_accuracy: 0.8485\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2907 - accuracy: 0.9385 - val_loss: 0.3671 - val_accuracy: 0.8485\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2873 - accuracy: 0.9385 - val_loss: 0.3657 - val_accuracy: 0.8485\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2839 - accuracy: 0.9385 - val_loss: 0.3640 - val_accuracy: 0.8485\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2804 - accuracy: 0.9385 - val_loss: 0.3625 - val_accuracy: 0.8485\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2773 - accuracy: 0.9385 - val_loss: 0.3615 - val_accuracy: 0.8485\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2747 - accuracy: 0.9231 - val_loss: 0.3615 - val_accuracy: 0.8182\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2718 - accuracy: 0.9231 - val_loss: 0.3608 - val_accuracy: 0.8182\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2693 - accuracy: 0.9231 - val_loss: 0.3598 - val_accuracy: 0.8182\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2665 - accuracy: 0.9231 - val_loss: 0.3577 - val_accuracy: 0.8182\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2636 - accuracy: 0.9385 - val_loss: 0.3550 - val_accuracy: 0.8485\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2605 - accuracy: 0.9385 - val_loss: 0.3529 - val_accuracy: 0.8485\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2576 - accuracy: 0.9385 - val_loss: 0.3511 - val_accuracy: 0.8485\n",
      "3.8621 seconds elapsed.\n"
     ]
    }
   ],
   "source": [
    "print('---START PART C3: No F4, Std,  w/ 2 hidden layers----')\n",
    "tic = time.time()\n",
    "modelC3.fit(X_train_nof4, y_train,\n",
    "            validation_data=(X_test_nof4, y_test),\n",
    "            epochs=100, batch_size=32)\n",
    "toc = time.time()\n",
    "print(f'{(toc - tic):.04f} seconds elapsed.')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T21:29:41.779284700Z",
     "start_time": "2023-12-02T21:29:37.912055700Z"
    }
   },
   "id": "8d8832c145542d13"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Experiment C4 (DROP F1):\n",
    "* Explore whether dropping a single feature (F1 OR F4) has an impact on \n",
    "  the model.\n",
    "* Still using 2 hidden layers\n",
    "\n",
    "Create new data frame dropping ONLY feature 1 (F1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b2167a00d680cc87"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         f2    f3    f4  rank  state    f5  success\n",
      "0  0.308841  0.18 -0.12     0      2 -0.23        1\n",
      "1  0.695683 -0.47  1.01     2      1  0.95        0\n",
      "2  0.000000  1.55  0.10     2      1  0.11        0\n",
      "3  0.598111 -0.21  0.24     2      0  0.10        0\n",
      "5 -0.458668  0.92 -0.65     2      2 -0.61        1\n"
     ]
    }
   ],
   "source": [
    "noF1df = df\n",
    "noF1df = noF1df.drop(['f1'], axis=1)\n",
    "print(noF1df.head())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T21:34:31.945184900Z",
     "start_time": "2023-12-02T21:34:31.929760400Z"
    }
   },
   "id": "47ee4f86d63cb119"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train Test Split dataframe\n",
    "Standardize dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b2adda88b33b482c"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         f2    f3    f4  rank  state    f5\n",
      "0  0.308841  0.18 -0.12     0      2 -0.23\n",
      "1  0.695683 -0.47  1.01     2      1  0.95\n",
      "2  0.000000  1.55  0.10     2      1  0.11\n",
      "3  0.598111 -0.21  0.24     2      0  0.10\n",
      "5 -0.458668  0.92 -0.65     2      2 -0.61\n",
      "0    1\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "5    1\n",
      "Name: success, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Prep inputs for Train Test Split\n",
    "X_corr_noF1 = noF1df.drop(['success'], axis=1)\n",
    "Y_corr_noF1 = noF1df['success']\n",
    "print(X_corr_noF1.head())\n",
    "print(Y_corr_noF1.head())\n",
    "\n",
    "# 67% train, 33% test on de-correlated feature dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_corr_noF1,\n",
    "                                                    Y_corr_noF1,\n",
    "                                                    test_size=0.33,\n",
    "                                                    random_state=seed)\n",
    "# Standardize Data with correlated features removed for part C4\n",
    "scaler = StandardScaler()\n",
    "X_train_nof1 = scaler.fit_transform(X_train)\n",
    "X_test_nof1 = scaler.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T21:35:34.327959500Z",
     "start_time": "2023-12-02T21:35:34.301312400Z"
    }
   },
   "id": "afd966b5099b62b2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create new model C4:\n",
    "Standardized Data\n",
    "De-Correlation: Dropping F1\n",
    "* Input Layer: 6 neurons\n",
    "* Hidden Layers: 2\n",
    "    * Layer 1: 16 neurons; RELU\n",
    "    * Layer 2: 16 neurons; RELU\n",
    "* Output Layer: 1 neuron; Sigmoid\n",
    "* Loss fn: Binary Cross Entropy\n",
    "* Optimizer: Adam\n",
    "* Metrics: Accuracy\n",
    "\n",
    "Hyperparams:\n",
    "* Epochs: 100\n",
    "* Train-Test Split: 67/33\n",
    "* Batch Size: 32"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f4a8a728942bfafb"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part C4 model constructed\n"
     ]
    }
   ],
   "source": [
    "modelC4 = keras.Sequential()\n",
    "modelC4.add(layers.Dense(16, input_shape=(6,),\n",
    "                         activation='relu'))\n",
    "modelC4.add(layers.Dense(16, activation='relu'))\n",
    "modelC4.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "modelC4.compile(loss=\"binary_crossentropy\", optimizer='adam',\n",
    "                metrics=['accuracy'])\n",
    "print('Part C4 model constructed')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T21:37:18.709793300Z",
     "start_time": "2023-12-02T21:37:18.668359500Z"
    }
   },
   "id": "cb4821f02b9c4bb9"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---START PART C4: No F1, Std,  w/ 2 hidden layers----\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 65ms/step - loss: 0.6643 - accuracy: 0.6154 - val_loss: 0.6324 - val_accuracy: 0.6364\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6552 - accuracy: 0.6308 - val_loss: 0.6284 - val_accuracy: 0.6061\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6489 - accuracy: 0.6769 - val_loss: 0.6240 - val_accuracy: 0.6364\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6427 - accuracy: 0.7231 - val_loss: 0.6194 - val_accuracy: 0.6667\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6365 - accuracy: 0.7385 - val_loss: 0.6148 - val_accuracy: 0.6667\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6306 - accuracy: 0.7538 - val_loss: 0.6107 - val_accuracy: 0.6667\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6248 - accuracy: 0.7692 - val_loss: 0.6073 - val_accuracy: 0.6667\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6196 - accuracy: 0.7692 - val_loss: 0.6035 - val_accuracy: 0.6667\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6143 - accuracy: 0.7846 - val_loss: 0.5994 - val_accuracy: 0.6667\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6087 - accuracy: 0.8000 - val_loss: 0.5958 - val_accuracy: 0.6667\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6038 - accuracy: 0.8000 - val_loss: 0.5932 - val_accuracy: 0.6970\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6000 - accuracy: 0.8154 - val_loss: 0.5910 - val_accuracy: 0.6970\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5961 - accuracy: 0.8154 - val_loss: 0.5883 - val_accuracy: 0.6970\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5916 - accuracy: 0.8154 - val_loss: 0.5852 - val_accuracy: 0.6970\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5867 - accuracy: 0.8154 - val_loss: 0.5814 - val_accuracy: 0.6970\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5813 - accuracy: 0.8154 - val_loss: 0.5773 - val_accuracy: 0.6970\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5763 - accuracy: 0.8462 - val_loss: 0.5732 - val_accuracy: 0.6970\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5708 - accuracy: 0.8462 - val_loss: 0.5694 - val_accuracy: 0.6970\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5657 - accuracy: 0.8462 - val_loss: 0.5656 - val_accuracy: 0.6970\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5608 - accuracy: 0.8462 - val_loss: 0.5620 - val_accuracy: 0.6970\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5564 - accuracy: 0.8462 - val_loss: 0.5586 - val_accuracy: 0.7273\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5517 - accuracy: 0.8462 - val_loss: 0.5551 - val_accuracy: 0.7576\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5471 - accuracy: 0.8462 - val_loss: 0.5522 - val_accuracy: 0.7576\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5431 - accuracy: 0.8615 - val_loss: 0.5501 - val_accuracy: 0.7576\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5399 - accuracy: 0.8615 - val_loss: 0.5476 - val_accuracy: 0.7273\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5363 - accuracy: 0.8615 - val_loss: 0.5449 - val_accuracy: 0.7273\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5326 - accuracy: 0.8615 - val_loss: 0.5426 - val_accuracy: 0.7273\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5288 - accuracy: 0.8615 - val_loss: 0.5405 - val_accuracy: 0.7273\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5249 - accuracy: 0.8769 - val_loss: 0.5377 - val_accuracy: 0.7576\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5206 - accuracy: 0.8769 - val_loss: 0.5342 - val_accuracy: 0.7576\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5158 - accuracy: 0.8769 - val_loss: 0.5306 - val_accuracy: 0.7576\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5108 - accuracy: 0.8769 - val_loss: 0.5271 - val_accuracy: 0.7576\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5057 - accuracy: 0.8769 - val_loss: 0.5239 - val_accuracy: 0.7879\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5005 - accuracy: 0.8769 - val_loss: 0.5210 - val_accuracy: 0.7576\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4951 - accuracy: 0.8769 - val_loss: 0.5180 - val_accuracy: 0.7576\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4897 - accuracy: 0.8769 - val_loss: 0.5152 - val_accuracy: 0.7576\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4844 - accuracy: 0.8769 - val_loss: 0.5123 - val_accuracy: 0.7879\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4790 - accuracy: 0.8923 - val_loss: 0.5095 - val_accuracy: 0.7879\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4736 - accuracy: 0.8923 - val_loss: 0.5064 - val_accuracy: 0.7879\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4687 - accuracy: 0.8923 - val_loss: 0.5034 - val_accuracy: 0.7879\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4633 - accuracy: 0.8923 - val_loss: 0.5010 - val_accuracy: 0.7879\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4582 - accuracy: 0.8923 - val_loss: 0.4991 - val_accuracy: 0.7879\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4532 - accuracy: 0.8923 - val_loss: 0.4969 - val_accuracy: 0.7879\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4483 - accuracy: 0.8923 - val_loss: 0.4946 - val_accuracy: 0.7879\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4440 - accuracy: 0.8923 - val_loss: 0.4921 - val_accuracy: 0.7879\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4401 - accuracy: 0.8923 - val_loss: 0.4899 - val_accuracy: 0.7879\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4361 - accuracy: 0.8923 - val_loss: 0.4875 - val_accuracy: 0.7879\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4321 - accuracy: 0.8923 - val_loss: 0.4846 - val_accuracy: 0.7879\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4278 - accuracy: 0.8923 - val_loss: 0.4816 - val_accuracy: 0.7879\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4237 - accuracy: 0.8923 - val_loss: 0.4786 - val_accuracy: 0.7879\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4195 - accuracy: 0.8923 - val_loss: 0.4762 - val_accuracy: 0.7879\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4152 - accuracy: 0.8923 - val_loss: 0.4739 - val_accuracy: 0.7576\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4110 - accuracy: 0.8923 - val_loss: 0.4713 - val_accuracy: 0.7576\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4068 - accuracy: 0.8923 - val_loss: 0.4687 - val_accuracy: 0.7576\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4022 - accuracy: 0.8923 - val_loss: 0.4664 - val_accuracy: 0.7576\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3979 - accuracy: 0.8923 - val_loss: 0.4643 - val_accuracy: 0.7576\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3934 - accuracy: 0.8923 - val_loss: 0.4622 - val_accuracy: 0.7576\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3892 - accuracy: 0.8923 - val_loss: 0.4601 - val_accuracy: 0.7576\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3849 - accuracy: 0.8923 - val_loss: 0.4584 - val_accuracy: 0.8182\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3805 - accuracy: 0.8923 - val_loss: 0.4568 - val_accuracy: 0.8182\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3766 - accuracy: 0.8923 - val_loss: 0.4553 - val_accuracy: 0.8182\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3726 - accuracy: 0.8923 - val_loss: 0.4539 - val_accuracy: 0.8182\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3684 - accuracy: 0.8923 - val_loss: 0.4522 - val_accuracy: 0.8182\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3643 - accuracy: 0.8923 - val_loss: 0.4505 - val_accuracy: 0.8182\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3600 - accuracy: 0.8923 - val_loss: 0.4484 - val_accuracy: 0.8182\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3557 - accuracy: 0.8923 - val_loss: 0.4462 - val_accuracy: 0.8182\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3515 - accuracy: 0.8923 - val_loss: 0.4445 - val_accuracy: 0.8182\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3474 - accuracy: 0.8923 - val_loss: 0.4430 - val_accuracy: 0.8182\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3436 - accuracy: 0.8923 - val_loss: 0.4417 - val_accuracy: 0.8182\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3398 - accuracy: 0.8923 - val_loss: 0.4409 - val_accuracy: 0.8182\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3360 - accuracy: 0.8923 - val_loss: 0.4400 - val_accuracy: 0.8182\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3324 - accuracy: 0.8923 - val_loss: 0.4389 - val_accuracy: 0.8182\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3288 - accuracy: 0.8923 - val_loss: 0.4375 - val_accuracy: 0.8182\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3251 - accuracy: 0.9077 - val_loss: 0.4352 - val_accuracy: 0.8182\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3214 - accuracy: 0.9231 - val_loss: 0.4330 - val_accuracy: 0.8182\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3176 - accuracy: 0.9231 - val_loss: 0.4300 - val_accuracy: 0.8182\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3138 - accuracy: 0.9231 - val_loss: 0.4277 - val_accuracy: 0.8182\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3099 - accuracy: 0.9385 - val_loss: 0.4262 - val_accuracy: 0.8182\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3061 - accuracy: 0.9385 - val_loss: 0.4247 - val_accuracy: 0.8182\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3022 - accuracy: 0.9385 - val_loss: 0.4232 - val_accuracy: 0.8182\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2987 - accuracy: 0.9385 - val_loss: 0.4217 - val_accuracy: 0.8182\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2949 - accuracy: 0.9385 - val_loss: 0.4206 - val_accuracy: 0.8182\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2914 - accuracy: 0.9385 - val_loss: 0.4197 - val_accuracy: 0.8182\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2881 - accuracy: 0.9385 - val_loss: 0.4194 - val_accuracy: 0.8182\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2846 - accuracy: 0.9385 - val_loss: 0.4184 - val_accuracy: 0.8182\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2818 - accuracy: 0.9385 - val_loss: 0.4165 - val_accuracy: 0.8182\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2791 - accuracy: 0.9385 - val_loss: 0.4145 - val_accuracy: 0.7879\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2774 - accuracy: 0.9385 - val_loss: 0.4128 - val_accuracy: 0.7879\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2751 - accuracy: 0.9385 - val_loss: 0.4116 - val_accuracy: 0.7879\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2734 - accuracy: 0.9385 - val_loss: 0.4103 - val_accuracy: 0.7879\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2711 - accuracy: 0.9385 - val_loss: 0.4090 - val_accuracy: 0.7879\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2687 - accuracy: 0.9385 - val_loss: 0.4080 - val_accuracy: 0.7879\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2662 - accuracy: 0.9385 - val_loss: 0.4074 - val_accuracy: 0.7879\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2638 - accuracy: 0.9385 - val_loss: 0.4067 - val_accuracy: 0.7879\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2612 - accuracy: 0.9385 - val_loss: 0.4062 - val_accuracy: 0.7879\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2586 - accuracy: 0.9385 - val_loss: 0.4061 - val_accuracy: 0.7879\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2559 - accuracy: 0.9385 - val_loss: 0.4066 - val_accuracy: 0.7879\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2533 - accuracy: 0.9385 - val_loss: 0.4073 - val_accuracy: 0.7879\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2507 - accuracy: 0.9385 - val_loss: 0.4075 - val_accuracy: 0.7879\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2484 - accuracy: 0.9385 - val_loss: 0.4070 - val_accuracy: 0.7879\n",
      "3.7984 seconds elapsed.\n"
     ]
    }
   ],
   "source": [
    "print('---START PART C4: No F1, Std,  w/ 2 hidden layers----')\n",
    "tic = time.time()\n",
    "modelC4.fit(X_train_nof1, y_train,\n",
    "            validation_data=(X_test_nof1, y_test),\n",
    "            epochs=100, batch_size=32)\n",
    "toc = time.time()\n",
    "print(f'{(toc - tic):.04f} seconds elapsed.')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T21:37:37.895902700Z",
     "start_time": "2023-12-02T21:37:34.059391100Z"
    }
   },
   "id": "4d0064ff86f586e7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Experiment C5 (DOUBLE EPOCHS):\n",
    "* Explore how doubling the number of epochs from 100 to 200 steps \n",
    "  impacts model performance \n",
    "* Still using 2 hidden layers\n",
    "\n",
    "All other parameters aside from epoch count are the same as C1\n",
    "\n",
    "Create new model C5:\n",
    "Standardized Data\n",
    "De-Correlation: None\n",
    "* Input Layer: 7 neurons\n",
    "* Hidden Layers: 2\n",
    "    * Layer 1: 16 neurons; RELU\n",
    "    * Layer 2: 16 neurons; RELU\n",
    "* Output Layer: 1 neuron; Sigmoid\n",
    "* Loss fn: Binary Cross Entropy\n",
    "* Optimizer: Adam\n",
    "* Metrics: Accuracy\n",
    "\n",
    "Hyperparams:\n",
    "* Epochs: 200\n",
    "* Train-Test Split: 67/33\n",
    "* Batch Size: 32"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1720d58f7b5928d4"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part C5 model constructed\n"
     ]
    }
   ],
   "source": [
    "# C5: No dropping of correlated data. Double Epochs\n",
    "modelC5 = keras.Sequential()\n",
    "modelC5.add(layers.Dense(16, input_shape=(7,),\n",
    "                        activation='relu'))\n",
    "modelC5.add(layers.Dense(16, activation='relu'))\n",
    "modelC5.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "modelC5.compile(loss=\"binary_crossentropy\", optimizer='adam',\n",
    "                metrics=['accuracy'])\n",
    "print('Part C5 model constructed')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T21:49:01.382258Z",
     "start_time": "2023-12-02T21:49:01.302304500Z"
    }
   },
   "id": "43c8f807bff72fea"
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----START PART C5: 2 hidden layers. 200 epochs----\n",
      "Epoch 1/200\n",
      "3/3 [==============================] - 1s 89ms/step - loss: 0.5743 - accuracy: 0.6154 - val_loss: 0.6242 - val_accuracy: 0.6061\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5614 - accuracy: 0.6615 - val_loss: 0.6153 - val_accuracy: 0.5758\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.5508 - accuracy: 0.6923 - val_loss: 0.6062 - val_accuracy: 0.5758\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5402 - accuracy: 0.7077 - val_loss: 0.5968 - val_accuracy: 0.5758\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5289 - accuracy: 0.7538 - val_loss: 0.5876 - val_accuracy: 0.5758\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5190 - accuracy: 0.7538 - val_loss: 0.5793 - val_accuracy: 0.5758\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5095 - accuracy: 0.7846 - val_loss: 0.5713 - val_accuracy: 0.6364\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5006 - accuracy: 0.8154 - val_loss: 0.5638 - val_accuracy: 0.6364\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4922 - accuracy: 0.8154 - val_loss: 0.5566 - val_accuracy: 0.6667\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4843 - accuracy: 0.8154 - val_loss: 0.5497 - val_accuracy: 0.6970\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4761 - accuracy: 0.8462 - val_loss: 0.5427 - val_accuracy: 0.6970\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4686 - accuracy: 0.8615 - val_loss: 0.5362 - val_accuracy: 0.7273\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4608 - accuracy: 0.8615 - val_loss: 0.5307 - val_accuracy: 0.6970\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4539 - accuracy: 0.8769 - val_loss: 0.5254 - val_accuracy: 0.6667\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4476 - accuracy: 0.8769 - val_loss: 0.5205 - val_accuracy: 0.7273\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4414 - accuracy: 0.8923 - val_loss: 0.5159 - val_accuracy: 0.7273\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4350 - accuracy: 0.8923 - val_loss: 0.5115 - val_accuracy: 0.7576\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4291 - accuracy: 0.8923 - val_loss: 0.5074 - val_accuracy: 0.7576\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4233 - accuracy: 0.9077 - val_loss: 0.5038 - val_accuracy: 0.7576\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4179 - accuracy: 0.9077 - val_loss: 0.5000 - val_accuracy: 0.7576\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4123 - accuracy: 0.8923 - val_loss: 0.4964 - val_accuracy: 0.7576\n",
      "Epoch 22/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4066 - accuracy: 0.8923 - val_loss: 0.4931 - val_accuracy: 0.7576\n",
      "Epoch 23/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4009 - accuracy: 0.8923 - val_loss: 0.4899 - val_accuracy: 0.7576\n",
      "Epoch 24/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3960 - accuracy: 0.8923 - val_loss: 0.4870 - val_accuracy: 0.7576\n",
      "Epoch 25/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3909 - accuracy: 0.8769 - val_loss: 0.4840 - val_accuracy: 0.7576\n",
      "Epoch 26/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3862 - accuracy: 0.8769 - val_loss: 0.4814 - val_accuracy: 0.7576\n",
      "Epoch 27/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3816 - accuracy: 0.8769 - val_loss: 0.4788 - val_accuracy: 0.7576\n",
      "Epoch 28/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3776 - accuracy: 0.8769 - val_loss: 0.4758 - val_accuracy: 0.7576\n",
      "Epoch 29/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3728 - accuracy: 0.8769 - val_loss: 0.4724 - val_accuracy: 0.7576\n",
      "Epoch 30/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3681 - accuracy: 0.8769 - val_loss: 0.4693 - val_accuracy: 0.7576\n",
      "Epoch 31/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3635 - accuracy: 0.8769 - val_loss: 0.4665 - val_accuracy: 0.7576\n",
      "Epoch 32/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3585 - accuracy: 0.8769 - val_loss: 0.4639 - val_accuracy: 0.7576\n",
      "Epoch 33/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3536 - accuracy: 0.8769 - val_loss: 0.4616 - val_accuracy: 0.7576\n",
      "Epoch 34/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3487 - accuracy: 0.8769 - val_loss: 0.4595 - val_accuracy: 0.7576\n",
      "Epoch 35/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3445 - accuracy: 0.8615 - val_loss: 0.4577 - val_accuracy: 0.7879\n",
      "Epoch 36/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3402 - accuracy: 0.8615 - val_loss: 0.4557 - val_accuracy: 0.7879\n",
      "Epoch 37/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3362 - accuracy: 0.8769 - val_loss: 0.4533 - val_accuracy: 0.7879\n",
      "Epoch 38/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3315 - accuracy: 0.8769 - val_loss: 0.4512 - val_accuracy: 0.7879\n",
      "Epoch 39/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3270 - accuracy: 0.8769 - val_loss: 0.4492 - val_accuracy: 0.7879\n",
      "Epoch 40/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3231 - accuracy: 0.8769 - val_loss: 0.4474 - val_accuracy: 0.7879\n",
      "Epoch 41/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3186 - accuracy: 0.8769 - val_loss: 0.4461 - val_accuracy: 0.7879\n",
      "Epoch 42/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3143 - accuracy: 0.8769 - val_loss: 0.4453 - val_accuracy: 0.7879\n",
      "Epoch 43/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3103 - accuracy: 0.8769 - val_loss: 0.4448 - val_accuracy: 0.7879\n",
      "Epoch 44/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3066 - accuracy: 0.8769 - val_loss: 0.4448 - val_accuracy: 0.7879\n",
      "Epoch 45/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3039 - accuracy: 0.8923 - val_loss: 0.4452 - val_accuracy: 0.7879\n",
      "Epoch 46/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3011 - accuracy: 0.8923 - val_loss: 0.4459 - val_accuracy: 0.7879\n",
      "Epoch 47/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2989 - accuracy: 0.8923 - val_loss: 0.4459 - val_accuracy: 0.7879\n",
      "Epoch 48/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2961 - accuracy: 0.8923 - val_loss: 0.4455 - val_accuracy: 0.8182\n",
      "Epoch 49/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2938 - accuracy: 0.8923 - val_loss: 0.4453 - val_accuracy: 0.8182\n",
      "Epoch 50/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2913 - accuracy: 0.8923 - val_loss: 0.4452 - val_accuracy: 0.8182\n",
      "Epoch 51/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2885 - accuracy: 0.9077 - val_loss: 0.4453 - val_accuracy: 0.8182\n",
      "Epoch 52/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2860 - accuracy: 0.9077 - val_loss: 0.4456 - val_accuracy: 0.8182\n",
      "Epoch 53/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2833 - accuracy: 0.9231 - val_loss: 0.4457 - val_accuracy: 0.8182\n",
      "Epoch 54/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2807 - accuracy: 0.9385 - val_loss: 0.4451 - val_accuracy: 0.8182\n",
      "Epoch 55/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2783 - accuracy: 0.9385 - val_loss: 0.4449 - val_accuracy: 0.8182\n",
      "Epoch 56/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2762 - accuracy: 0.9385 - val_loss: 0.4444 - val_accuracy: 0.8182\n",
      "Epoch 57/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2744 - accuracy: 0.9385 - val_loss: 0.4438 - val_accuracy: 0.8182\n",
      "Epoch 58/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2727 - accuracy: 0.9385 - val_loss: 0.4437 - val_accuracy: 0.8182\n",
      "Epoch 59/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2710 - accuracy: 0.9231 - val_loss: 0.4438 - val_accuracy: 0.8182\n",
      "Epoch 60/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2694 - accuracy: 0.9231 - val_loss: 0.4445 - val_accuracy: 0.8182\n",
      "Epoch 61/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2676 - accuracy: 0.9231 - val_loss: 0.4458 - val_accuracy: 0.8182\n",
      "Epoch 62/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2656 - accuracy: 0.9231 - val_loss: 0.4471 - val_accuracy: 0.8182\n",
      "Epoch 63/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2641 - accuracy: 0.9231 - val_loss: 0.4484 - val_accuracy: 0.8182\n",
      "Epoch 64/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2625 - accuracy: 0.9231 - val_loss: 0.4495 - val_accuracy: 0.8182\n",
      "Epoch 65/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2609 - accuracy: 0.9231 - val_loss: 0.4507 - val_accuracy: 0.8182\n",
      "Epoch 66/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2595 - accuracy: 0.9231 - val_loss: 0.4518 - val_accuracy: 0.8182\n",
      "Epoch 67/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2578 - accuracy: 0.9231 - val_loss: 0.4530 - val_accuracy: 0.8182\n",
      "Epoch 68/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2563 - accuracy: 0.9231 - val_loss: 0.4540 - val_accuracy: 0.8182\n",
      "Epoch 69/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2549 - accuracy: 0.9231 - val_loss: 0.4549 - val_accuracy: 0.8182\n",
      "Epoch 70/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2534 - accuracy: 0.9231 - val_loss: 0.4558 - val_accuracy: 0.8182\n",
      "Epoch 71/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2524 - accuracy: 0.9231 - val_loss: 0.4568 - val_accuracy: 0.8182\n",
      "Epoch 72/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2510 - accuracy: 0.9231 - val_loss: 0.4578 - val_accuracy: 0.8182\n",
      "Epoch 73/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2497 - accuracy: 0.9231 - val_loss: 0.4589 - val_accuracy: 0.8182\n",
      "Epoch 74/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2481 - accuracy: 0.9231 - val_loss: 0.4601 - val_accuracy: 0.8182\n",
      "Epoch 75/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2470 - accuracy: 0.9231 - val_loss: 0.4615 - val_accuracy: 0.8182\n",
      "Epoch 76/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2461 - accuracy: 0.9231 - val_loss: 0.4629 - val_accuracy: 0.8182\n",
      "Epoch 77/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2449 - accuracy: 0.9231 - val_loss: 0.4644 - val_accuracy: 0.8182\n",
      "Epoch 78/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2440 - accuracy: 0.9231 - val_loss: 0.4658 - val_accuracy: 0.8182\n",
      "Epoch 79/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2431 - accuracy: 0.9231 - val_loss: 0.4672 - val_accuracy: 0.8182\n",
      "Epoch 80/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2425 - accuracy: 0.9231 - val_loss: 0.4689 - val_accuracy: 0.8182\n",
      "Epoch 81/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2415 - accuracy: 0.9231 - val_loss: 0.4706 - val_accuracy: 0.8182\n",
      "Epoch 82/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2410 - accuracy: 0.9231 - val_loss: 0.4721 - val_accuracy: 0.8182\n",
      "Epoch 83/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2396 - accuracy: 0.9231 - val_loss: 0.4731 - val_accuracy: 0.8182\n",
      "Epoch 84/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2383 - accuracy: 0.9231 - val_loss: 0.4742 - val_accuracy: 0.8182\n",
      "Epoch 85/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2372 - accuracy: 0.9231 - val_loss: 0.4751 - val_accuracy: 0.8182\n",
      "Epoch 86/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2364 - accuracy: 0.9231 - val_loss: 0.4762 - val_accuracy: 0.8182\n",
      "Epoch 87/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2359 - accuracy: 0.9231 - val_loss: 0.4776 - val_accuracy: 0.8182\n",
      "Epoch 88/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2352 - accuracy: 0.9231 - val_loss: 0.4793 - val_accuracy: 0.8182\n",
      "Epoch 89/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2348 - accuracy: 0.9231 - val_loss: 0.4807 - val_accuracy: 0.8182\n",
      "Epoch 90/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2340 - accuracy: 0.9231 - val_loss: 0.4820 - val_accuracy: 0.8182\n",
      "Epoch 91/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2334 - accuracy: 0.9231 - val_loss: 0.4836 - val_accuracy: 0.8182\n",
      "Epoch 92/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2329 - accuracy: 0.9231 - val_loss: 0.4858 - val_accuracy: 0.8182\n",
      "Epoch 93/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2321 - accuracy: 0.9231 - val_loss: 0.4876 - val_accuracy: 0.8182\n",
      "Epoch 94/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2314 - accuracy: 0.9231 - val_loss: 0.4886 - val_accuracy: 0.8182\n",
      "Epoch 95/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2303 - accuracy: 0.9231 - val_loss: 0.4888 - val_accuracy: 0.8182\n",
      "Epoch 96/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2291 - accuracy: 0.9231 - val_loss: 0.4890 - val_accuracy: 0.8182\n",
      "Epoch 97/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2278 - accuracy: 0.9231 - val_loss: 0.4893 - val_accuracy: 0.8182\n",
      "Epoch 98/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2267 - accuracy: 0.9231 - val_loss: 0.4887 - val_accuracy: 0.8182\n",
      "Epoch 99/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2255 - accuracy: 0.9231 - val_loss: 0.4866 - val_accuracy: 0.8182\n",
      "Epoch 100/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2241 - accuracy: 0.9231 - val_loss: 0.4853 - val_accuracy: 0.8182\n",
      "Epoch 101/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2230 - accuracy: 0.9231 - val_loss: 0.4843 - val_accuracy: 0.8182\n",
      "Epoch 102/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2215 - accuracy: 0.9231 - val_loss: 0.4837 - val_accuracy: 0.8182\n",
      "Epoch 103/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2204 - accuracy: 0.9231 - val_loss: 0.4834 - val_accuracy: 0.8182\n",
      "Epoch 104/200\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.2195 - accuracy: 0.9231 - val_loss: 0.4834 - val_accuracy: 0.8182\n",
      "Epoch 105/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2186 - accuracy: 0.9231 - val_loss: 0.4838 - val_accuracy: 0.8182\n",
      "Epoch 106/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2177 - accuracy: 0.9231 - val_loss: 0.4843 - val_accuracy: 0.8182\n",
      "Epoch 107/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2170 - accuracy: 0.9231 - val_loss: 0.4850 - val_accuracy: 0.8182\n",
      "Epoch 108/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2162 - accuracy: 0.9231 - val_loss: 0.4860 - val_accuracy: 0.8182\n",
      "Epoch 109/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2155 - accuracy: 0.9231 - val_loss: 0.4870 - val_accuracy: 0.8182\n",
      "Epoch 110/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2146 - accuracy: 0.9231 - val_loss: 0.4886 - val_accuracy: 0.8182\n",
      "Epoch 111/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2138 - accuracy: 0.9231 - val_loss: 0.4910 - val_accuracy: 0.8182\n",
      "Epoch 112/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2133 - accuracy: 0.9231 - val_loss: 0.4934 - val_accuracy: 0.8182\n",
      "Epoch 113/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2125 - accuracy: 0.9231 - val_loss: 0.4956 - val_accuracy: 0.8182\n",
      "Epoch 114/200\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2118 - accuracy: 0.9231 - val_loss: 0.4975 - val_accuracy: 0.8182\n",
      "Epoch 115/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2110 - accuracy: 0.9231 - val_loss: 0.4994 - val_accuracy: 0.8182\n",
      "Epoch 116/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2103 - accuracy: 0.9231 - val_loss: 0.5014 - val_accuracy: 0.8182\n",
      "Epoch 117/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2099 - accuracy: 0.9231 - val_loss: 0.5035 - val_accuracy: 0.8182\n",
      "Epoch 118/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2091 - accuracy: 0.9231 - val_loss: 0.5052 - val_accuracy: 0.8182\n",
      "Epoch 119/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2086 - accuracy: 0.9231 - val_loss: 0.5067 - val_accuracy: 0.8182\n",
      "Epoch 120/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2080 - accuracy: 0.9231 - val_loss: 0.5081 - val_accuracy: 0.8182\n",
      "Epoch 121/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2075 - accuracy: 0.9231 - val_loss: 0.5091 - val_accuracy: 0.8182\n",
      "Epoch 122/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2069 - accuracy: 0.9231 - val_loss: 0.5090 - val_accuracy: 0.8182\n",
      "Epoch 123/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2062 - accuracy: 0.9231 - val_loss: 0.5074 - val_accuracy: 0.8182\n",
      "Epoch 124/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2054 - accuracy: 0.9231 - val_loss: 0.5067 - val_accuracy: 0.8182\n",
      "Epoch 125/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2046 - accuracy: 0.9231 - val_loss: 0.5067 - val_accuracy: 0.8182\n",
      "Epoch 126/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2040 - accuracy: 0.9231 - val_loss: 0.5065 - val_accuracy: 0.8182\n",
      "Epoch 127/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2032 - accuracy: 0.9231 - val_loss: 0.5063 - val_accuracy: 0.8182\n",
      "Epoch 128/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2021 - accuracy: 0.9231 - val_loss: 0.5063 - val_accuracy: 0.8182\n",
      "Epoch 129/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2013 - accuracy: 0.9231 - val_loss: 0.5065 - val_accuracy: 0.8182\n",
      "Epoch 130/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2006 - accuracy: 0.9231 - val_loss: 0.5070 - val_accuracy: 0.8182\n",
      "Epoch 131/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2000 - accuracy: 0.9231 - val_loss: 0.5077 - val_accuracy: 0.8182\n",
      "Epoch 132/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1993 - accuracy: 0.9231 - val_loss: 0.5087 - val_accuracy: 0.8182\n",
      "Epoch 133/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1988 - accuracy: 0.9231 - val_loss: 0.5097 - val_accuracy: 0.8182\n",
      "Epoch 134/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1982 - accuracy: 0.9231 - val_loss: 0.5108 - val_accuracy: 0.8182\n",
      "Epoch 135/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1977 - accuracy: 0.9231 - val_loss: 0.5123 - val_accuracy: 0.8182\n",
      "Epoch 136/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1970 - accuracy: 0.9231 - val_loss: 0.5138 - val_accuracy: 0.8182\n",
      "Epoch 137/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1963 - accuracy: 0.9231 - val_loss: 0.5160 - val_accuracy: 0.8182\n",
      "Epoch 138/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1957 - accuracy: 0.9231 - val_loss: 0.5182 - val_accuracy: 0.8182\n",
      "Epoch 139/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1951 - accuracy: 0.9231 - val_loss: 0.5202 - val_accuracy: 0.8182\n",
      "Epoch 140/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1945 - accuracy: 0.9231 - val_loss: 0.5218 - val_accuracy: 0.8182\n",
      "Epoch 141/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1939 - accuracy: 0.9231 - val_loss: 0.5232 - val_accuracy: 0.8182\n",
      "Epoch 142/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1934 - accuracy: 0.9231 - val_loss: 0.5245 - val_accuracy: 0.8182\n",
      "Epoch 143/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1928 - accuracy: 0.9231 - val_loss: 0.5256 - val_accuracy: 0.8182\n",
      "Epoch 144/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1922 - accuracy: 0.9231 - val_loss: 0.5266 - val_accuracy: 0.8182\n",
      "Epoch 145/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1916 - accuracy: 0.9231 - val_loss: 0.5274 - val_accuracy: 0.8182\n",
      "Epoch 146/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1911 - accuracy: 0.9231 - val_loss: 0.5284 - val_accuracy: 0.8182\n",
      "Epoch 147/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1905 - accuracy: 0.9231 - val_loss: 0.5292 - val_accuracy: 0.8182\n",
      "Epoch 148/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1900 - accuracy: 0.9385 - val_loss: 0.5300 - val_accuracy: 0.8182\n",
      "Epoch 149/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1895 - accuracy: 0.9385 - val_loss: 0.5308 - val_accuracy: 0.8182\n",
      "Epoch 150/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1885 - accuracy: 0.9385 - val_loss: 0.5312 - val_accuracy: 0.8182\n",
      "Epoch 151/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1873 - accuracy: 0.9385 - val_loss: 0.5319 - val_accuracy: 0.8182\n",
      "Epoch 152/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1865 - accuracy: 0.9385 - val_loss: 0.5325 - val_accuracy: 0.8182\n",
      "Epoch 153/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1858 - accuracy: 0.9385 - val_loss: 0.5331 - val_accuracy: 0.8182\n",
      "Epoch 154/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1850 - accuracy: 0.9385 - val_loss: 0.5339 - val_accuracy: 0.8182\n",
      "Epoch 155/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1845 - accuracy: 0.9385 - val_loss: 0.5347 - val_accuracy: 0.8182\n",
      "Epoch 156/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1839 - accuracy: 0.9385 - val_loss: 0.5353 - val_accuracy: 0.8182\n",
      "Epoch 157/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1833 - accuracy: 0.9385 - val_loss: 0.5358 - val_accuracy: 0.8182\n",
      "Epoch 158/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1832 - accuracy: 0.9385 - val_loss: 0.5356 - val_accuracy: 0.8182\n",
      "Epoch 159/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1822 - accuracy: 0.9385 - val_loss: 0.5350 - val_accuracy: 0.8182\n",
      "Epoch 160/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1820 - accuracy: 0.9385 - val_loss: 0.5352 - val_accuracy: 0.8182\n",
      "Epoch 161/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1808 - accuracy: 0.9385 - val_loss: 0.5345 - val_accuracy: 0.8182\n",
      "Epoch 162/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1802 - accuracy: 0.9385 - val_loss: 0.5327 - val_accuracy: 0.8182\n",
      "Epoch 163/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1793 - accuracy: 0.9385 - val_loss: 0.5326 - val_accuracy: 0.8182\n",
      "Epoch 164/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1785 - accuracy: 0.9385 - val_loss: 0.5332 - val_accuracy: 0.8182\n",
      "Epoch 165/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1779 - accuracy: 0.9385 - val_loss: 0.5340 - val_accuracy: 0.8182\n",
      "Epoch 166/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1773 - accuracy: 0.9385 - val_loss: 0.5351 - val_accuracy: 0.8182\n",
      "Epoch 167/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1768 - accuracy: 0.9385 - val_loss: 0.5364 - val_accuracy: 0.8182\n",
      "Epoch 168/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1761 - accuracy: 0.9385 - val_loss: 0.5374 - val_accuracy: 0.8182\n",
      "Epoch 169/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1756 - accuracy: 0.9385 - val_loss: 0.5383 - val_accuracy: 0.8182\n",
      "Epoch 170/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1750 - accuracy: 0.9385 - val_loss: 0.5388 - val_accuracy: 0.8182\n",
      "Epoch 171/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1744 - accuracy: 0.9385 - val_loss: 0.5394 - val_accuracy: 0.8182\n",
      "Epoch 172/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1738 - accuracy: 0.9385 - val_loss: 0.5402 - val_accuracy: 0.8182\n",
      "Epoch 173/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1730 - accuracy: 0.9385 - val_loss: 0.5418 - val_accuracy: 0.8182\n",
      "Epoch 174/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1725 - accuracy: 0.9385 - val_loss: 0.5438 - val_accuracy: 0.8182\n",
      "Epoch 175/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1719 - accuracy: 0.9385 - val_loss: 0.5456 - val_accuracy: 0.8182\n",
      "Epoch 176/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1714 - accuracy: 0.9385 - val_loss: 0.5473 - val_accuracy: 0.8182\n",
      "Epoch 177/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1708 - accuracy: 0.9385 - val_loss: 0.5485 - val_accuracy: 0.8182\n",
      "Epoch 178/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1703 - accuracy: 0.9385 - val_loss: 0.5496 - val_accuracy: 0.8182\n",
      "Epoch 179/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1698 - accuracy: 0.9385 - val_loss: 0.5506 - val_accuracy: 0.8182\n",
      "Epoch 180/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1693 - accuracy: 0.9385 - val_loss: 0.5489 - val_accuracy: 0.8182\n",
      "Epoch 181/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1687 - accuracy: 0.9385 - val_loss: 0.5435 - val_accuracy: 0.8182\n",
      "Epoch 182/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1676 - accuracy: 0.9385 - val_loss: 0.5400 - val_accuracy: 0.8182\n",
      "Epoch 183/200\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1670 - accuracy: 0.9385 - val_loss: 0.5368 - val_accuracy: 0.8182\n",
      "Epoch 184/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1664 - accuracy: 0.9385 - val_loss: 0.5338 - val_accuracy: 0.8182\n",
      "Epoch 185/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1663 - accuracy: 0.9385 - val_loss: 0.5325 - val_accuracy: 0.8182\n",
      "Epoch 186/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1659 - accuracy: 0.9385 - val_loss: 0.5318 - val_accuracy: 0.8182\n",
      "Epoch 187/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1656 - accuracy: 0.9385 - val_loss: 0.5317 - val_accuracy: 0.8182\n",
      "Epoch 188/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1653 - accuracy: 0.9385 - val_loss: 0.5319 - val_accuracy: 0.8182\n",
      "Epoch 189/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1650 - accuracy: 0.9385 - val_loss: 0.5322 - val_accuracy: 0.8182\n",
      "Epoch 190/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1647 - accuracy: 0.9538 - val_loss: 0.5327 - val_accuracy: 0.8182\n",
      "Epoch 191/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1642 - accuracy: 0.9538 - val_loss: 0.5337 - val_accuracy: 0.8182\n",
      "Epoch 192/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1636 - accuracy: 0.9538 - val_loss: 0.5351 - val_accuracy: 0.8182\n",
      "Epoch 193/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1629 - accuracy: 0.9538 - val_loss: 0.5365 - val_accuracy: 0.8182\n",
      "Epoch 194/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1626 - accuracy: 0.9538 - val_loss: 0.5376 - val_accuracy: 0.8182\n",
      "Epoch 195/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1626 - accuracy: 0.9538 - val_loss: 0.5387 - val_accuracy: 0.8182\n",
      "Epoch 196/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1625 - accuracy: 0.9538 - val_loss: 0.5401 - val_accuracy: 0.8182\n",
      "Epoch 197/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1621 - accuracy: 0.9538 - val_loss: 0.5417 - val_accuracy: 0.8182\n",
      "Epoch 198/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1617 - accuracy: 0.9538 - val_loss: 0.5430 - val_accuracy: 0.8182\n",
      "Epoch 199/200\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1612 - accuracy: 0.9538 - val_loss: 0.5442 - val_accuracy: 0.8182\n",
      "Epoch 200/200\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1606 - accuracy: 0.9538 - val_loss: 0.5453 - val_accuracy: 0.8182\n",
      "6.8169 seconds elapsed.\n"
     ]
    }
   ],
   "source": [
    "print('----START PART C5: 2 hidden layers. 200 epochs----')\n",
    "# fit new model with 7 inputs\n",
    "tic = time.time()\n",
    "modelC5.fit(X_train_std, y_train,\n",
    "            validation_data=(X_test_std, y_test),\n",
    "            epochs=200, batch_size=32)\n",
    "toc = time.time()\n",
    "print(f'{(toc - tic):.04f} seconds elapsed.')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T21:49:09.856966800Z",
     "start_time": "2023-12-02T21:49:03.031823700Z"
    }
   },
   "id": "f0e20a633a5c61d2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Experiment C6 (HALF EPOCHS):\n",
    "* Explore how halving the number of epochs from 100 to 50 steps \n",
    "  impacts model performance \n",
    "* Still using 2 hidden layers\n",
    "\n",
    "All other parameters are the same as C1\n",
    "\n",
    "Create new model C6\n",
    "Standardized Data\n",
    "De-Correlation: None\n",
    "* Input Layer: 7 neurons\n",
    "* Hidden Layers: 2\n",
    "    * Layer 1: 16 neurons; RELU\n",
    "    * Layer 2: 16 neurons; RELU\n",
    "* Output Layer: 1 neuron; Sigmoid\n",
    "* Loss fn: Binary Cross Entropy\n",
    "* Optimizer: Adam\n",
    "* Metrics: Accuracy\n",
    "\n",
    "Hyperparams:\n",
    "* Epochs: 50\n",
    "* Train-Test Split: 67/33\n",
    "* Batch Size: 32"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c50ef6a37b93d3ba"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part C6 model constructed\n"
     ]
    }
   ],
   "source": [
    "modelC6 = keras.Sequential()\n",
    "modelC6.add(layers.Dense(16, input_shape=(7,),\n",
    "                        activation='relu'))\n",
    "modelC6.add(layers.Dense(16, activation='relu'))\n",
    "modelC6.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "modelC6.compile(loss=\"binary_crossentropy\", optimizer='adam',\n",
    "                metrics=['accuracy'])\n",
    "print('Part C6 model constructed')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T22:18:50.562384400Z",
     "start_time": "2023-12-02T22:18:50.514664500Z"
    }
   },
   "id": "8c0c8c6282607ca1"
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----START PART C6: 2 hidden layers. 50 epochs----\n",
      "Epoch 1/50\n",
      "3/3 [==============================] - 1s 65ms/step - loss: 0.6746 - accuracy: 0.5077 - val_loss: 0.6493 - val_accuracy: 0.5758\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6653 - accuracy: 0.5077 - val_loss: 0.6429 - val_accuracy: 0.6061\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6577 - accuracy: 0.5538 - val_loss: 0.6370 - val_accuracy: 0.6061\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6502 - accuracy: 0.5385 - val_loss: 0.6313 - val_accuracy: 0.6061\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6431 - accuracy: 0.5692 - val_loss: 0.6260 - val_accuracy: 0.6061\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6360 - accuracy: 0.6000 - val_loss: 0.6213 - val_accuracy: 0.6364\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6292 - accuracy: 0.6462 - val_loss: 0.6164 - val_accuracy: 0.6061\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6226 - accuracy: 0.6769 - val_loss: 0.6115 - val_accuracy: 0.6061\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6156 - accuracy: 0.6923 - val_loss: 0.6068 - val_accuracy: 0.6364\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6088 - accuracy: 0.7231 - val_loss: 0.6020 - val_accuracy: 0.6364\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6020 - accuracy: 0.7231 - val_loss: 0.5972 - val_accuracy: 0.6667\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5953 - accuracy: 0.7538 - val_loss: 0.5924 - val_accuracy: 0.6667\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5889 - accuracy: 0.7846 - val_loss: 0.5877 - val_accuracy: 0.6970\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5826 - accuracy: 0.8000 - val_loss: 0.5830 - val_accuracy: 0.6970\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5767 - accuracy: 0.8000 - val_loss: 0.5782 - val_accuracy: 0.6970\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5706 - accuracy: 0.8154 - val_loss: 0.5736 - val_accuracy: 0.6970\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5650 - accuracy: 0.8308 - val_loss: 0.5690 - val_accuracy: 0.6667\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5593 - accuracy: 0.8308 - val_loss: 0.5643 - val_accuracy: 0.6667\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5528 - accuracy: 0.8462 - val_loss: 0.5598 - val_accuracy: 0.6667\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5468 - accuracy: 0.8615 - val_loss: 0.5560 - val_accuracy: 0.6667\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5408 - accuracy: 0.8615 - val_loss: 0.5519 - val_accuracy: 0.6970\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5351 - accuracy: 0.8769 - val_loss: 0.5478 - val_accuracy: 0.7273\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5296 - accuracy: 0.8769 - val_loss: 0.5434 - val_accuracy: 0.7273\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5232 - accuracy: 0.8769 - val_loss: 0.5387 - val_accuracy: 0.7273\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5165 - accuracy: 0.8769 - val_loss: 0.5341 - val_accuracy: 0.7273\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5101 - accuracy: 0.8769 - val_loss: 0.5298 - val_accuracy: 0.7576\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5041 - accuracy: 0.8769 - val_loss: 0.5262 - val_accuracy: 0.7576\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4980 - accuracy: 0.8923 - val_loss: 0.5230 - val_accuracy: 0.7576\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4927 - accuracy: 0.8923 - val_loss: 0.5194 - val_accuracy: 0.7576\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4868 - accuracy: 0.8923 - val_loss: 0.5154 - val_accuracy: 0.7879\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4807 - accuracy: 0.9077 - val_loss: 0.5112 - val_accuracy: 0.7879\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4743 - accuracy: 0.9231 - val_loss: 0.5073 - val_accuracy: 0.7879\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4680 - accuracy: 0.9231 - val_loss: 0.5035 - val_accuracy: 0.7879\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4612 - accuracy: 0.9231 - val_loss: 0.4997 - val_accuracy: 0.7879\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4546 - accuracy: 0.9231 - val_loss: 0.4955 - val_accuracy: 0.7879\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4483 - accuracy: 0.9231 - val_loss: 0.4912 - val_accuracy: 0.7879\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4418 - accuracy: 0.9385 - val_loss: 0.4869 - val_accuracy: 0.7879\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4357 - accuracy: 0.9385 - val_loss: 0.4828 - val_accuracy: 0.7879\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4295 - accuracy: 0.9385 - val_loss: 0.4787 - val_accuracy: 0.7879\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4233 - accuracy: 0.9385 - val_loss: 0.4747 - val_accuracy: 0.7879\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4176 - accuracy: 0.9385 - val_loss: 0.4708 - val_accuracy: 0.7879\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4116 - accuracy: 0.9385 - val_loss: 0.4669 - val_accuracy: 0.7879\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4055 - accuracy: 0.9385 - val_loss: 0.4636 - val_accuracy: 0.7879\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4003 - accuracy: 0.9385 - val_loss: 0.4609 - val_accuracy: 0.7879\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3957 - accuracy: 0.9385 - val_loss: 0.4582 - val_accuracy: 0.7879\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3908 - accuracy: 0.9385 - val_loss: 0.4556 - val_accuracy: 0.7879\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3855 - accuracy: 0.9385 - val_loss: 0.4532 - val_accuracy: 0.7879\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3806 - accuracy: 0.9385 - val_loss: 0.4507 - val_accuracy: 0.7879\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3753 - accuracy: 0.9385 - val_loss: 0.4482 - val_accuracy: 0.7879\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3703 - accuracy: 0.9385 - val_loss: 0.4458 - val_accuracy: 0.7879\n",
      "2.2490 seconds elapsed.\n"
     ]
    }
   ],
   "source": [
    "print('----START PART C6: 2 hidden layers. 50 epochs----')\n",
    "# fit new model with 7 inputs\n",
    "tic = time.time()\n",
    "modelC6.fit(X_train_std, y_train,\n",
    "            validation_data=(X_test_std, y_test),\n",
    "            epochs=50, batch_size=32)\n",
    "toc = time.time()\n",
    "print(f'{(toc - tic):.04f} seconds elapsed.')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T22:19:08.290047800Z",
     "start_time": "2023-12-02T22:19:06.032704400Z"
    }
   },
   "id": "c32363fa6e34f81a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Experiment C7 (DOUBLE BATCH SIZE):\n",
    "* Explore how doubling the batch size from 32 to 64 \n",
    "  impacts model performance \n",
    "* Still using 2 hidden layers\n",
    "\n",
    "All other parameters are the same as C1\n",
    "\n",
    "Create new model C7\n",
    "Standardized Data\n",
    "De-Correlation: None\n",
    "* Input Layer: 7 neurons\n",
    "* Hidden Layers: 2\n",
    "    * Layer 1: 16 neurons; RELU\n",
    "    * Layer 2: 16 neurons; RELU\n",
    "* Output Layer: 1 neuron; Sigmoid\n",
    "* Loss fn: Binary Cross Entropy\n",
    "* Optimizer: Adam\n",
    "* Metrics: Accuracy\n",
    "\n",
    "Hyperparams:\n",
    "* Epochs: 100\n",
    "* Train-Test Split: 67/33\n",
    "* Batch Size: 64"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3f6def3504e2d4f1"
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part C7 model constructed\n"
     ]
    }
   ],
   "source": [
    "# C7: Double batch size to 64. No correlation drops. 100 Epochs\n",
    "modelC7 = keras.Sequential()\n",
    "modelC7.add(layers.Dense(16, input_shape=(7,),\n",
    "                         activation='relu'))\n",
    "modelC7.add(layers.Dense(16, activation='relu'))\n",
    "modelC7.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "modelC7.compile(loss=\"binary_crossentropy\", optimizer='adam',\n",
    "                metrics=['accuracy'])\n",
    "print('Part C7 model constructed')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T22:22:54.822657200Z",
     "start_time": "2023-12-02T22:22:54.745668800Z"
    }
   },
   "id": "5cca2a9083fe3a30"
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----START PART C7: 64 batch size. 100 epochs----\n",
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 126ms/step - loss: 0.7578 - accuracy: 0.5077 - val_loss: 0.6974 - val_accuracy: 0.5455\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7480 - accuracy: 0.5077 - val_loss: 0.6914 - val_accuracy: 0.5455\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7399 - accuracy: 0.5077 - val_loss: 0.6849 - val_accuracy: 0.5455\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.7315 - accuracy: 0.5077 - val_loss: 0.6784 - val_accuracy: 0.5455\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.7235 - accuracy: 0.5077 - val_loss: 0.6729 - val_accuracy: 0.5455\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.7166 - accuracy: 0.5077 - val_loss: 0.6677 - val_accuracy: 0.5455\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.7102 - accuracy: 0.5231 - val_loss: 0.6627 - val_accuracy: 0.5455\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.7038 - accuracy: 0.5231 - val_loss: 0.6582 - val_accuracy: 0.5152\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6980 - accuracy: 0.5231 - val_loss: 0.6537 - val_accuracy: 0.5152\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6923 - accuracy: 0.5231 - val_loss: 0.6492 - val_accuracy: 0.5152\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6866 - accuracy: 0.5231 - val_loss: 0.6448 - val_accuracy: 0.5152\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6812 - accuracy: 0.5231 - val_loss: 0.6405 - val_accuracy: 0.5152\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6760 - accuracy: 0.5077 - val_loss: 0.6362 - val_accuracy: 0.5152\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6708 - accuracy: 0.5077 - val_loss: 0.6319 - val_accuracy: 0.5152\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6658 - accuracy: 0.5385 - val_loss: 0.6279 - val_accuracy: 0.5455\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6610 - accuracy: 0.5385 - val_loss: 0.6244 - val_accuracy: 0.5455\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6566 - accuracy: 0.5538 - val_loss: 0.6210 - val_accuracy: 0.5455\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6522 - accuracy: 0.5538 - val_loss: 0.6172 - val_accuracy: 0.5455\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6477 - accuracy: 0.5538 - val_loss: 0.6135 - val_accuracy: 0.5455\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.6430 - accuracy: 0.5846 - val_loss: 0.6099 - val_accuracy: 0.5455\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.6386 - accuracy: 0.5846 - val_loss: 0.6065 - val_accuracy: 0.5758\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6343 - accuracy: 0.6000 - val_loss: 0.6034 - val_accuracy: 0.5758\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6302 - accuracy: 0.6154 - val_loss: 0.6003 - val_accuracy: 0.6061\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.6261 - accuracy: 0.6154 - val_loss: 0.5975 - val_accuracy: 0.6061\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6223 - accuracy: 0.6308 - val_loss: 0.5947 - val_accuracy: 0.6061\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6186 - accuracy: 0.6615 - val_loss: 0.5925 - val_accuracy: 0.6061\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.6153 - accuracy: 0.6615 - val_loss: 0.5906 - val_accuracy: 0.6061\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6125 - accuracy: 0.6615 - val_loss: 0.5887 - val_accuracy: 0.6061\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.6095 - accuracy: 0.6615 - val_loss: 0.5864 - val_accuracy: 0.5758\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.6061 - accuracy: 0.6769 - val_loss: 0.5840 - val_accuracy: 0.6061\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.6025 - accuracy: 0.7077 - val_loss: 0.5814 - val_accuracy: 0.6364\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.5986 - accuracy: 0.7077 - val_loss: 0.5786 - val_accuracy: 0.6364\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.5946 - accuracy: 0.7077 - val_loss: 0.5760 - val_accuracy: 0.6364\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.5906 - accuracy: 0.7077 - val_loss: 0.5733 - val_accuracy: 0.6364\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.5866 - accuracy: 0.7231 - val_loss: 0.5704 - val_accuracy: 0.6364\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.5824 - accuracy: 0.7385 - val_loss: 0.5677 - val_accuracy: 0.6364\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.5784 - accuracy: 0.7385 - val_loss: 0.5652 - val_accuracy: 0.6364\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.5746 - accuracy: 0.7385 - val_loss: 0.5629 - val_accuracy: 0.6364\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.5710 - accuracy: 0.7385 - val_loss: 0.5606 - val_accuracy: 0.6364\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.5676 - accuracy: 0.7385 - val_loss: 0.5582 - val_accuracy: 0.6364\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.5640 - accuracy: 0.7538 - val_loss: 0.5558 - val_accuracy: 0.6667\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.5605 - accuracy: 0.7538 - val_loss: 0.5532 - val_accuracy: 0.6667\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.5569 - accuracy: 0.7538 - val_loss: 0.5506 - val_accuracy: 0.7273\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.5532 - accuracy: 0.7692 - val_loss: 0.5479 - val_accuracy: 0.7273\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.5494 - accuracy: 0.7538 - val_loss: 0.5452 - val_accuracy: 0.7576\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.5454 - accuracy: 0.7538 - val_loss: 0.5427 - val_accuracy: 0.7576\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.5415 - accuracy: 0.7538 - val_loss: 0.5399 - val_accuracy: 0.8485\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.5373 - accuracy: 0.7385 - val_loss: 0.5371 - val_accuracy: 0.8485\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.5331 - accuracy: 0.7385 - val_loss: 0.5346 - val_accuracy: 0.8485\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.5292 - accuracy: 0.7385 - val_loss: 0.5318 - val_accuracy: 0.8485\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.5252 - accuracy: 0.7538 - val_loss: 0.5291 - val_accuracy: 0.8182\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.5211 - accuracy: 0.7538 - val_loss: 0.5265 - val_accuracy: 0.8182\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.5174 - accuracy: 0.7385 - val_loss: 0.5240 - val_accuracy: 0.8182\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.5138 - accuracy: 0.7692 - val_loss: 0.5215 - val_accuracy: 0.8182\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.5100 - accuracy: 0.7846 - val_loss: 0.5187 - val_accuracy: 0.8182\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.5061 - accuracy: 0.7692 - val_loss: 0.5161 - val_accuracy: 0.8182\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.5021 - accuracy: 0.7692 - val_loss: 0.5138 - val_accuracy: 0.8182\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.4984 - accuracy: 0.7846 - val_loss: 0.5115 - val_accuracy: 0.8182\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.4949 - accuracy: 0.7692 - val_loss: 0.5091 - val_accuracy: 0.8182\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.4914 - accuracy: 0.7846 - val_loss: 0.5067 - val_accuracy: 0.8182\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.4879 - accuracy: 0.8154 - val_loss: 0.5044 - val_accuracy: 0.8182\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.4844 - accuracy: 0.8154 - val_loss: 0.5022 - val_accuracy: 0.8182\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.4812 - accuracy: 0.8154 - val_loss: 0.5002 - val_accuracy: 0.8182\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.4781 - accuracy: 0.8154 - val_loss: 0.4990 - val_accuracy: 0.8182\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.4757 - accuracy: 0.8154 - val_loss: 0.4978 - val_accuracy: 0.8182\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.4732 - accuracy: 0.8308 - val_loss: 0.4964 - val_accuracy: 0.8182\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.4705 - accuracy: 0.8308 - val_loss: 0.4949 - val_accuracy: 0.8182\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.4678 - accuracy: 0.8308 - val_loss: 0.4934 - val_accuracy: 0.8182\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.4649 - accuracy: 0.8462 - val_loss: 0.4918 - val_accuracy: 0.8182\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.4618 - accuracy: 0.8462 - val_loss: 0.4900 - val_accuracy: 0.8182\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.4585 - accuracy: 0.8462 - val_loss: 0.4883 - val_accuracy: 0.8182\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.4551 - accuracy: 0.8462 - val_loss: 0.4867 - val_accuracy: 0.8182\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.4519 - accuracy: 0.8462 - val_loss: 0.4855 - val_accuracy: 0.8182\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.4490 - accuracy: 0.8462 - val_loss: 0.4841 - val_accuracy: 0.8485\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.4462 - accuracy: 0.8615 - val_loss: 0.4826 - val_accuracy: 0.8485\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.4432 - accuracy: 0.8615 - val_loss: 0.4809 - val_accuracy: 0.8485\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.4401 - accuracy: 0.8615 - val_loss: 0.4792 - val_accuracy: 0.8485\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.4368 - accuracy: 0.8615 - val_loss: 0.4774 - val_accuracy: 0.8485\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.4336 - accuracy: 0.8615 - val_loss: 0.4756 - val_accuracy: 0.8485\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.4305 - accuracy: 0.8615 - val_loss: 0.4738 - val_accuracy: 0.8182\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.4275 - accuracy: 0.8615 - val_loss: 0.4722 - val_accuracy: 0.8182\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.4245 - accuracy: 0.8769 - val_loss: 0.4705 - val_accuracy: 0.8182\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.4214 - accuracy: 0.8769 - val_loss: 0.4689 - val_accuracy: 0.8182\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.4186 - accuracy: 0.8615 - val_loss: 0.4673 - val_accuracy: 0.8182\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.4159 - accuracy: 0.8615 - val_loss: 0.4657 - val_accuracy: 0.8182\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.4133 - accuracy: 0.8615 - val_loss: 0.4642 - val_accuracy: 0.8182\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.4108 - accuracy: 0.8615 - val_loss: 0.4627 - val_accuracy: 0.8182\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.4081 - accuracy: 0.8615 - val_loss: 0.4612 - val_accuracy: 0.8182\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.4052 - accuracy: 0.8462 - val_loss: 0.4596 - val_accuracy: 0.8182\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.4021 - accuracy: 0.8462 - val_loss: 0.4580 - val_accuracy: 0.8182\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.3992 - accuracy: 0.8615 - val_loss: 0.4565 - val_accuracy: 0.8182\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.3963 - accuracy: 0.8615 - val_loss: 0.4550 - val_accuracy: 0.8182\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.3934 - accuracy: 0.8615 - val_loss: 0.4535 - val_accuracy: 0.8182\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.3906 - accuracy: 0.8615 - val_loss: 0.4520 - val_accuracy: 0.8182\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.3878 - accuracy: 0.8615 - val_loss: 0.4505 - val_accuracy: 0.8182\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.3849 - accuracy: 0.8615 - val_loss: 0.4492 - val_accuracy: 0.8182\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.3822 - accuracy: 0.8615 - val_loss: 0.4480 - val_accuracy: 0.8182\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.3796 - accuracy: 0.8615 - val_loss: 0.4467 - val_accuracy: 0.8182\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.3769 - accuracy: 0.8615 - val_loss: 0.4455 - val_accuracy: 0.8182\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.3741 - accuracy: 0.8615 - val_loss: 0.4444 - val_accuracy: 0.8182\n",
      "3.4842 seconds elapsed.\n"
     ]
    }
   ],
   "source": [
    "print('----START PART C7: 64 batch size. 100 epochs----')\n",
    "# fit new model with 7 inputs\n",
    "tic = time.time()\n",
    "modelC7.fit(X_train_std, y_train,\n",
    "            validation_data=(X_test_std, y_test),\n",
    "            epochs=100, batch_size=64)\n",
    "toc = time.time()\n",
    "print(f'{(toc - tic):.04f} seconds elapsed.')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T22:23:17.045701900Z",
     "start_time": "2023-12-02T22:23:13.551765700Z"
    }
   },
   "id": "42f0223cbd7c958a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Experiment C8 (TRAIN TEST SPLIT 50:50):\n",
    "* Explore how adjusting the train test split to 50:50 from 67:33 \n",
    "  impacts model performance \n",
    "* Still using 2 hidden layers\n",
    "\n",
    "All other parameters are the same as C1\n",
    "\n",
    "Create new model C8\n",
    "Standardized Data\n",
    "De-Correlation: None\n",
    "* Input Layer: 7 neurons\n",
    "* Hidden Layers: 2\n",
    "    * Layer 1: 16 neurons; RELU\n",
    "    * Layer 2: 16 neurons; RELU\n",
    "* Output Layer: 1 neuron; Sigmoid\n",
    "* Loss fn: Binary Cross Entropy\n",
    "* Optimizer: Adam\n",
    "* Metrics: Accuracy\n",
    "\n",
    "Hyperparams:\n",
    "* Epochs: 100\n",
    "* Train-Test Split: 50/50\n",
    "* Batch Size: 32"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b50d7a00853335f"
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part C8 model constructed\n"
     ]
    }
   ],
   "source": [
    "# C8: batch size to 32. No correlation drops. 100 Epochs.\n",
    "# 50: 50 Test: Train\n",
    "modelC8 = keras.Sequential()\n",
    "modelC8.add(layers.Dense(16, input_shape=(7,),\n",
    "                         activation='relu'))\n",
    "modelC8.add(layers.Dense(16, activation='relu'))\n",
    "modelC8.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "modelC8.compile(loss=\"binary_crossentropy\", optimizer='adam',\n",
    "                metrics=['accuracy'])\n",
    "print('Part C8 model constructed')\n",
    "\n",
    "# 50% train, 50% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y,\n",
    "                                                    test_size=0.5,\n",
    "                                                    random_state=seed)\n",
    "\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T22:27:02.842728200Z",
     "start_time": "2023-12-02T22:27:02.791184Z"
    }
   },
   "id": "3c4769dd832bd823"
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----START PART C8: 50:50 test-train----\n",
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 127ms/step - loss: 0.6519 - accuracy: 0.6327 - val_loss: 0.6439 - val_accuracy: 0.6327\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6425 - accuracy: 0.6327 - val_loss: 0.6379 - val_accuracy: 0.6327\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6336 - accuracy: 0.6531 - val_loss: 0.6323 - val_accuracy: 0.6531\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6252 - accuracy: 0.6735 - val_loss: 0.6264 - val_accuracy: 0.6735\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6173 - accuracy: 0.7143 - val_loss: 0.6204 - val_accuracy: 0.6735\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6089 - accuracy: 0.7143 - val_loss: 0.6148 - val_accuracy: 0.6939\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6006 - accuracy: 0.7143 - val_loss: 0.6093 - val_accuracy: 0.6939\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5927 - accuracy: 0.7347 - val_loss: 0.6037 - val_accuracy: 0.6939\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5849 - accuracy: 0.7347 - val_loss: 0.5981 - val_accuracy: 0.6939\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5772 - accuracy: 0.7551 - val_loss: 0.5924 - val_accuracy: 0.6735\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5690 - accuracy: 0.7551 - val_loss: 0.5868 - val_accuracy: 0.7143\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5619 - accuracy: 0.7551 - val_loss: 0.5812 - val_accuracy: 0.7143\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5542 - accuracy: 0.7755 - val_loss: 0.5758 - val_accuracy: 0.7143\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5466 - accuracy: 0.7959 - val_loss: 0.5706 - val_accuracy: 0.7143\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5393 - accuracy: 0.7959 - val_loss: 0.5656 - val_accuracy: 0.7347\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5316 - accuracy: 0.7959 - val_loss: 0.5608 - val_accuracy: 0.7347\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5246 - accuracy: 0.7959 - val_loss: 0.5561 - val_accuracy: 0.7347\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5171 - accuracy: 0.7959 - val_loss: 0.5515 - val_accuracy: 0.7347\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.5101 - accuracy: 0.7959 - val_loss: 0.5469 - val_accuracy: 0.7551\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5029 - accuracy: 0.7959 - val_loss: 0.5425 - val_accuracy: 0.7551\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.4957 - accuracy: 0.7959 - val_loss: 0.5383 - val_accuracy: 0.7551\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.4885 - accuracy: 0.7959 - val_loss: 0.5344 - val_accuracy: 0.7551\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.4814 - accuracy: 0.8163 - val_loss: 0.5307 - val_accuracy: 0.7551\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.4747 - accuracy: 0.8163 - val_loss: 0.5273 - val_accuracy: 0.7551\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.4675 - accuracy: 0.8163 - val_loss: 0.5242 - val_accuracy: 0.7551\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.4605 - accuracy: 0.8163 - val_loss: 0.5213 - val_accuracy: 0.7551\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.4544 - accuracy: 0.8163 - val_loss: 0.5187 - val_accuracy: 0.7551\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.4467 - accuracy: 0.8163 - val_loss: 0.5160 - val_accuracy: 0.7551\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.4402 - accuracy: 0.8163 - val_loss: 0.5132 - val_accuracy: 0.7755\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.4338 - accuracy: 0.8163 - val_loss: 0.5107 - val_accuracy: 0.7755\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.4269 - accuracy: 0.8163 - val_loss: 0.5084 - val_accuracy: 0.7959\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.4204 - accuracy: 0.8163 - val_loss: 0.5061 - val_accuracy: 0.7959\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.4138 - accuracy: 0.8367 - val_loss: 0.5042 - val_accuracy: 0.7755\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.4072 - accuracy: 0.8367 - val_loss: 0.5024 - val_accuracy: 0.7755\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4011 - accuracy: 0.8367 - val_loss: 0.5007 - val_accuracy: 0.7755\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.3945 - accuracy: 0.8367 - val_loss: 0.4989 - val_accuracy: 0.7755\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.3881 - accuracy: 0.8367 - val_loss: 0.4974 - val_accuracy: 0.7755\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.3819 - accuracy: 0.8571 - val_loss: 0.4957 - val_accuracy: 0.7755\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.3757 - accuracy: 0.8571 - val_loss: 0.4938 - val_accuracy: 0.7755\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.3697 - accuracy: 0.8776 - val_loss: 0.4921 - val_accuracy: 0.7959\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.3638 - accuracy: 0.8776 - val_loss: 0.4906 - val_accuracy: 0.7959\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.3579 - accuracy: 0.8776 - val_loss: 0.4893 - val_accuracy: 0.7959\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.3523 - accuracy: 0.8776 - val_loss: 0.4882 - val_accuracy: 0.7959\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.3469 - accuracy: 0.8776 - val_loss: 0.4875 - val_accuracy: 0.7959\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.3413 - accuracy: 0.8776 - val_loss: 0.4869 - val_accuracy: 0.7959\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.3362 - accuracy: 0.8776 - val_loss: 0.4867 - val_accuracy: 0.7959\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.3315 - accuracy: 0.8776 - val_loss: 0.4865 - val_accuracy: 0.7959\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.3267 - accuracy: 0.8776 - val_loss: 0.4865 - val_accuracy: 0.7959\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.3219 - accuracy: 0.8776 - val_loss: 0.4867 - val_accuracy: 0.7959\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.3174 - accuracy: 0.8980 - val_loss: 0.4871 - val_accuracy: 0.7959\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.3128 - accuracy: 0.8980 - val_loss: 0.4877 - val_accuracy: 0.7959\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.3082 - accuracy: 0.8980 - val_loss: 0.4884 - val_accuracy: 0.7959\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.3042 - accuracy: 0.8980 - val_loss: 0.4891 - val_accuracy: 0.7959\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.2999 - accuracy: 0.9184 - val_loss: 0.4897 - val_accuracy: 0.7959\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.2958 - accuracy: 0.9184 - val_loss: 0.4906 - val_accuracy: 0.7959\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.2920 - accuracy: 0.9184 - val_loss: 0.4914 - val_accuracy: 0.7959\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.2881 - accuracy: 0.9184 - val_loss: 0.4924 - val_accuracy: 0.7959\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.2844 - accuracy: 0.9388 - val_loss: 0.4933 - val_accuracy: 0.7959\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.2808 - accuracy: 0.9388 - val_loss: 0.4942 - val_accuracy: 0.7959\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.2773 - accuracy: 0.9388 - val_loss: 0.4950 - val_accuracy: 0.7959\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.2736 - accuracy: 0.9388 - val_loss: 0.4959 - val_accuracy: 0.7959\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.2702 - accuracy: 0.9388 - val_loss: 0.4969 - val_accuracy: 0.7959\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.2670 - accuracy: 0.9388 - val_loss: 0.4980 - val_accuracy: 0.7959\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.2637 - accuracy: 0.9388 - val_loss: 0.4990 - val_accuracy: 0.7959\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.2604 - accuracy: 0.9388 - val_loss: 0.4998 - val_accuracy: 0.7959\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.2569 - accuracy: 0.9388 - val_loss: 0.5006 - val_accuracy: 0.8163\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.2537 - accuracy: 0.9592 - val_loss: 0.5015 - val_accuracy: 0.8163\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.2508 - accuracy: 0.9592 - val_loss: 0.5023 - val_accuracy: 0.8163\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.2478 - accuracy: 0.9592 - val_loss: 0.5030 - val_accuracy: 0.8163\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.2445 - accuracy: 0.9592 - val_loss: 0.5042 - val_accuracy: 0.8163\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.2413 - accuracy: 0.9592 - val_loss: 0.5057 - val_accuracy: 0.8163\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.2383 - accuracy: 0.9592 - val_loss: 0.5070 - val_accuracy: 0.8163\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.2355 - accuracy: 0.9592 - val_loss: 0.5090 - val_accuracy: 0.8163\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.2325 - accuracy: 0.9592 - val_loss: 0.5113 - val_accuracy: 0.8163\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.2298 - accuracy: 0.9592 - val_loss: 0.5132 - val_accuracy: 0.8163\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.2270 - accuracy: 0.9592 - val_loss: 0.5152 - val_accuracy: 0.8163\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.2244 - accuracy: 0.9592 - val_loss: 0.5174 - val_accuracy: 0.8163\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.2217 - accuracy: 0.9592 - val_loss: 0.5197 - val_accuracy: 0.8163\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.2190 - accuracy: 0.9592 - val_loss: 0.5217 - val_accuracy: 0.8163\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.2164 - accuracy: 0.9592 - val_loss: 0.5237 - val_accuracy: 0.8163\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.2136 - accuracy: 0.9592 - val_loss: 0.5260 - val_accuracy: 0.8163\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.2114 - accuracy: 0.9592 - val_loss: 0.5285 - val_accuracy: 0.8163\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.2090 - accuracy: 0.9592 - val_loss: 0.5309 - val_accuracy: 0.8163\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.2065 - accuracy: 0.9592 - val_loss: 0.5334 - val_accuracy: 0.8163\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.2040 - accuracy: 0.9592 - val_loss: 0.5351 - val_accuracy: 0.8163\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.2015 - accuracy: 0.9592 - val_loss: 0.5372 - val_accuracy: 0.8163\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.1992 - accuracy: 0.9592 - val_loss: 0.5396 - val_accuracy: 0.8163\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.1967 - accuracy: 0.9592 - val_loss: 0.5414 - val_accuracy: 0.8163\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1943 - accuracy: 0.9592 - val_loss: 0.5429 - val_accuracy: 0.8163\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.1920 - accuracy: 0.9592 - val_loss: 0.5444 - val_accuracy: 0.8163\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1900 - accuracy: 0.9592 - val_loss: 0.5462 - val_accuracy: 0.8163\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.1876 - accuracy: 0.9592 - val_loss: 0.5480 - val_accuracy: 0.8163\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.1855 - accuracy: 0.9592 - val_loss: 0.5495 - val_accuracy: 0.8163\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.1833 - accuracy: 0.9592 - val_loss: 0.5517 - val_accuracy: 0.8163\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.1811 - accuracy: 0.9592 - val_loss: 0.5545 - val_accuracy: 0.8163\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.1791 - accuracy: 0.9592 - val_loss: 0.5572 - val_accuracy: 0.8163\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1770 - accuracy: 0.9592 - val_loss: 0.5595 - val_accuracy: 0.8163\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1751 - accuracy: 0.9592 - val_loss: 0.5611 - val_accuracy: 0.8163\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.1730 - accuracy: 0.9592 - val_loss: 0.5619 - val_accuracy: 0.8163\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1712 - accuracy: 0.9592 - val_loss: 0.5629 - val_accuracy: 0.8163\n",
      "3.5943 seconds elapsed.\n"
     ]
    }
   ],
   "source": [
    "print('----START PART C8: 50:50 test-train----')\n",
    "tic = time.time()\n",
    "modelC8.fit(X_train_std, y_train,\n",
    "            validation_data=(X_test_std, y_test),\n",
    "            epochs=100, batch_size=32)\n",
    "toc = time.time()\n",
    "print(f'{(toc - tic):.04f} seconds elapsed.')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T22:27:19.612765200Z",
     "start_time": "2023-12-02T22:27:16.005188100Z"
    }
   },
   "id": "532022bd8b44197f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Experiment C9 (TRAIN TEST SPLIT 20:80):\n",
    "* Explore how adjusting the train test split to 20:80 from 67:33 \n",
    "  impacts model performance \n",
    "* Still using 2 hidden layers\n",
    "\n",
    "All other parameters are the same as C1\n",
    "\n",
    "Create new model C9\n",
    "Standardized Data\n",
    "De-Correlation: None\n",
    "* Input Layer: 7 neurons\n",
    "* Hidden Layers: 2\n",
    "    * Layer 1: 16 neurons; RELU\n",
    "    * Layer 2: 16 neurons; RELU\n",
    "* Output Layer: 1 neuron; Sigmoid\n",
    "* Loss fn: Binary Cross Entropy\n",
    "* Optimizer: Adam\n",
    "* Metrics: Accuracy\n",
    "\n",
    "Hyperparams:\n",
    "* Epochs: 100\n",
    "* Train-Test Split: 20/80\n",
    "* Batch Size: 32"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1470e0aa7d8f46b8"
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part C9 model constructed\n"
     ]
    }
   ],
   "source": [
    "# C9: batch size to 32. No correlation drops. 100 Epochs.\n",
    "# 20:80 Test: Train\n",
    "modelC9 = keras.Sequential()\n",
    "modelC9.add(layers.Dense(16, input_shape=(7,),\n",
    "                         activation='relu'))\n",
    "modelC9.add(layers.Dense(16, activation='relu'))\n",
    "modelC9.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "modelC9.compile(loss=\"binary_crossentropy\", optimizer='adam',\n",
    "                metrics=['accuracy'])\n",
    "print('Part C9 model constructed')\n",
    "\n",
    "# 20% train, 80% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y,\n",
    "                                                    test_size=0.8,\n",
    "                                                    random_state=seed)\n",
    "\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T22:31:59.264696200Z",
     "start_time": "2023-12-02T22:31:59.209033400Z"
    }
   },
   "id": "786701631c7028c"
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----START PART C9: 20:80 test-train----\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 0.7392 - accuracy: 0.3684 - val_loss: 0.6763 - val_accuracy: 0.5949\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.7322 - accuracy: 0.3684 - val_loss: 0.6724 - val_accuracy: 0.5823\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.7252 - accuracy: 0.4211 - val_loss: 0.6686 - val_accuracy: 0.5823\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7185 - accuracy: 0.4211 - val_loss: 0.6647 - val_accuracy: 0.5823\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.7118 - accuracy: 0.4211 - val_loss: 0.6608 - val_accuracy: 0.6076\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.7051 - accuracy: 0.4211 - val_loss: 0.6570 - val_accuracy: 0.6076\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6986 - accuracy: 0.5263 - val_loss: 0.6533 - val_accuracy: 0.6076\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6921 - accuracy: 0.5789 - val_loss: 0.6494 - val_accuracy: 0.6329\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6855 - accuracy: 0.5789 - val_loss: 0.6457 - val_accuracy: 0.6203\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6791 - accuracy: 0.6316 - val_loss: 0.6419 - val_accuracy: 0.6329\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6727 - accuracy: 0.6842 - val_loss: 0.6381 - val_accuracy: 0.6582\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6664 - accuracy: 0.7368 - val_loss: 0.6344 - val_accuracy: 0.6582\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6603 - accuracy: 0.7368 - val_loss: 0.6306 - val_accuracy: 0.6582\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6542 - accuracy: 0.7368 - val_loss: 0.6269 - val_accuracy: 0.6709\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6481 - accuracy: 0.7368 - val_loss: 0.6232 - val_accuracy: 0.6835\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6422 - accuracy: 0.7368 - val_loss: 0.6194 - val_accuracy: 0.6835\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6366 - accuracy: 0.7368 - val_loss: 0.6157 - val_accuracy: 0.7215\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6310 - accuracy: 0.7368 - val_loss: 0.6120 - val_accuracy: 0.7342\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6255 - accuracy: 0.7368 - val_loss: 0.6083 - val_accuracy: 0.7468\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6200 - accuracy: 0.7368 - val_loss: 0.6045 - val_accuracy: 0.7468\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6146 - accuracy: 0.7895 - val_loss: 0.6008 - val_accuracy: 0.7468\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6093 - accuracy: 0.7895 - val_loss: 0.5972 - val_accuracy: 0.7595\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6040 - accuracy: 0.7895 - val_loss: 0.5937 - val_accuracy: 0.7722\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5988 - accuracy: 0.7895 - val_loss: 0.5901 - val_accuracy: 0.7848\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5936 - accuracy: 0.7895 - val_loss: 0.5866 - val_accuracy: 0.7848\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5885 - accuracy: 0.7895 - val_loss: 0.5831 - val_accuracy: 0.7975\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5835 - accuracy: 0.7895 - val_loss: 0.5797 - val_accuracy: 0.7975\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5786 - accuracy: 0.7895 - val_loss: 0.5762 - val_accuracy: 0.7975\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5738 - accuracy: 0.8421 - val_loss: 0.5728 - val_accuracy: 0.8101\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5691 - accuracy: 0.8421 - val_loss: 0.5695 - val_accuracy: 0.8101\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5644 - accuracy: 0.8421 - val_loss: 0.5662 - val_accuracy: 0.8101\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5598 - accuracy: 0.8421 - val_loss: 0.5629 - val_accuracy: 0.8101\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.5552 - accuracy: 0.8421 - val_loss: 0.5597 - val_accuracy: 0.8101\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5506 - accuracy: 0.8421 - val_loss: 0.5565 - val_accuracy: 0.8101\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5461 - accuracy: 0.8421 - val_loss: 0.5533 - val_accuracy: 0.8228\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5416 - accuracy: 0.8421 - val_loss: 0.5502 - val_accuracy: 0.8481\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5372 - accuracy: 0.8421 - val_loss: 0.5471 - val_accuracy: 0.8481\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5328 - accuracy: 0.8421 - val_loss: 0.5441 - val_accuracy: 0.8481\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5285 - accuracy: 0.8947 - val_loss: 0.5411 - val_accuracy: 0.8608\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5242 - accuracy: 0.9474 - val_loss: 0.5382 - val_accuracy: 0.8608\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5198 - accuracy: 0.9474 - val_loss: 0.5353 - val_accuracy: 0.8608\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5155 - accuracy: 0.9474 - val_loss: 0.5324 - val_accuracy: 0.8608\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5112 - accuracy: 0.9474 - val_loss: 0.5297 - val_accuracy: 0.8481\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5069 - accuracy: 0.9474 - val_loss: 0.5269 - val_accuracy: 0.8354\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5026 - accuracy: 0.9474 - val_loss: 0.5242 - val_accuracy: 0.8354\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4984 - accuracy: 0.9474 - val_loss: 0.5216 - val_accuracy: 0.8354\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4941 - accuracy: 0.9474 - val_loss: 0.5190 - val_accuracy: 0.8354\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4898 - accuracy: 0.9474 - val_loss: 0.5165 - val_accuracy: 0.8354\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4856 - accuracy: 0.9474 - val_loss: 0.5141 - val_accuracy: 0.8354\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4813 - accuracy: 0.9474 - val_loss: 0.5117 - val_accuracy: 0.8354\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4771 - accuracy: 0.9474 - val_loss: 0.5094 - val_accuracy: 0.8354\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4729 - accuracy: 0.9474 - val_loss: 0.5071 - val_accuracy: 0.8354\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4686 - accuracy: 0.9474 - val_loss: 0.5050 - val_accuracy: 0.8354\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4645 - accuracy: 0.9474 - val_loss: 0.5028 - val_accuracy: 0.8354\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4603 - accuracy: 0.9474 - val_loss: 0.5008 - val_accuracy: 0.8354\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4561 - accuracy: 0.9474 - val_loss: 0.4988 - val_accuracy: 0.8228\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4519 - accuracy: 0.9474 - val_loss: 0.4968 - val_accuracy: 0.8101\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4478 - accuracy: 0.9474 - val_loss: 0.4949 - val_accuracy: 0.8101\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4436 - accuracy: 0.9474 - val_loss: 0.4931 - val_accuracy: 0.8228\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4395 - accuracy: 0.9474 - val_loss: 0.4912 - val_accuracy: 0.8228\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4354 - accuracy: 0.9474 - val_loss: 0.4894 - val_accuracy: 0.8228\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4313 - accuracy: 0.9474 - val_loss: 0.4877 - val_accuracy: 0.8228\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4272 - accuracy: 0.9474 - val_loss: 0.4860 - val_accuracy: 0.8228\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4232 - accuracy: 0.9474 - val_loss: 0.4844 - val_accuracy: 0.8228\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4192 - accuracy: 0.9474 - val_loss: 0.4828 - val_accuracy: 0.8228\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4152 - accuracy: 0.9474 - val_loss: 0.4812 - val_accuracy: 0.8228\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4112 - accuracy: 0.9474 - val_loss: 0.4797 - val_accuracy: 0.8228\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4071 - accuracy: 0.9474 - val_loss: 0.4783 - val_accuracy: 0.8228\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.4031 - accuracy: 0.9474 - val_loss: 0.4769 - val_accuracy: 0.8228\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3991 - accuracy: 0.9474 - val_loss: 0.4756 - val_accuracy: 0.8228\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3951 - accuracy: 0.9474 - val_loss: 0.4743 - val_accuracy: 0.8228\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3911 - accuracy: 0.9474 - val_loss: 0.4730 - val_accuracy: 0.8228\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3871 - accuracy: 0.9474 - val_loss: 0.4718 - val_accuracy: 0.8228\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3831 - accuracy: 0.9474 - val_loss: 0.4706 - val_accuracy: 0.8228\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3791 - accuracy: 0.9474 - val_loss: 0.4694 - val_accuracy: 0.8228\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3751 - accuracy: 0.9474 - val_loss: 0.4683 - val_accuracy: 0.8228\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3711 - accuracy: 0.9474 - val_loss: 0.4671 - val_accuracy: 0.8228\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3671 - accuracy: 0.9474 - val_loss: 0.4661 - val_accuracy: 0.8354\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3632 - accuracy: 0.9474 - val_loss: 0.4650 - val_accuracy: 0.8354\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3592 - accuracy: 0.9474 - val_loss: 0.4640 - val_accuracy: 0.8354\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3553 - accuracy: 0.9474 - val_loss: 0.4631 - val_accuracy: 0.8354\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3513 - accuracy: 0.9474 - val_loss: 0.4622 - val_accuracy: 0.8354\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3474 - accuracy: 0.9474 - val_loss: 0.4613 - val_accuracy: 0.8354\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3435 - accuracy: 0.9474 - val_loss: 0.4604 - val_accuracy: 0.8228\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3397 - accuracy: 0.9474 - val_loss: 0.4594 - val_accuracy: 0.8228\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.3358 - accuracy: 0.9474 - val_loss: 0.4585 - val_accuracy: 0.8228\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3320 - accuracy: 0.9474 - val_loss: 0.4576 - val_accuracy: 0.8228\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3282 - accuracy: 0.9474 - val_loss: 0.4567 - val_accuracy: 0.8228\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3244 - accuracy: 0.9474 - val_loss: 0.4557 - val_accuracy: 0.8228\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3207 - accuracy: 0.9474 - val_loss: 0.4548 - val_accuracy: 0.8228\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3170 - accuracy: 0.9474 - val_loss: 0.4539 - val_accuracy: 0.8228\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.3133 - accuracy: 0.9474 - val_loss: 0.4531 - val_accuracy: 0.8228\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3097 - accuracy: 0.9474 - val_loss: 0.4523 - val_accuracy: 0.8228\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3061 - accuracy: 0.9474 - val_loss: 0.4515 - val_accuracy: 0.8228\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3025 - accuracy: 0.9474 - val_loss: 0.4507 - val_accuracy: 0.8228\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2990 - accuracy: 0.9474 - val_loss: 0.4500 - val_accuracy: 0.8228\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2955 - accuracy: 0.9474 - val_loss: 0.4493 - val_accuracy: 0.8228\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2920 - accuracy: 0.9474 - val_loss: 0.4486 - val_accuracy: 0.8228\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2886 - accuracy: 0.9474 - val_loss: 0.4480 - val_accuracy: 0.8228\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2852 - accuracy: 0.9474 - val_loss: 0.4474 - val_accuracy: 0.8228\n",
      "3.6503 seconds elapsed.\n"
     ]
    }
   ],
   "source": [
    "print('----START PART C9: 20:80 test-train----')\n",
    "tic = time.time()\n",
    "modelC9.fit(X_train_std, y_train,\n",
    "            validation_data=(X_test_std, y_test),\n",
    "            epochs=100, batch_size=32)\n",
    "toc = time.time()\n",
    "print(f'{(toc - tic):.04f} seconds elapsed.')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T22:32:17.177222Z",
     "start_time": "2023-12-02T22:32:13.515843600Z"
    }
   },
   "id": "cda8f4f07e1925ae"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Experiment C10 (TRAIN TEST SPLIT 80:20):\n",
    "* Explore how adjusting the train test split to 80:20 from 67:33 \n",
    "  impacts model performance \n",
    "* Still using 2 hidden layers\n",
    "\n",
    "All other parameters are the same as C1\n",
    "\n",
    "Create new model C10\n",
    "Standardized Data\n",
    "De-Correlation: None\n",
    "* Input Layer: 7 neurons\n",
    "* Hidden Layers: 2\n",
    "    * Layer 1: 16 neurons; RELU\n",
    "    * Layer 2: 16 neurons; RELU\n",
    "* Output Layer: 1 neuron; Sigmoid\n",
    "* Loss fn: Binary Cross Entropy\n",
    "* Optimizer: Adam\n",
    "* Metrics: Accuracy\n",
    "\n",
    "Hyperparams:\n",
    "* Epochs: 100\n",
    "* Train-Test Split: 80/20\n",
    "* Batch Size: 32"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "daf0d7213aefe45c"
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part C10 model constructed\n"
     ]
    }
   ],
   "source": [
    "# C10: batch size to 32. No correlation drops. 100 Epochs.\n",
    "# 80:20 Test: Train\n",
    "modelC10 = keras.Sequential()\n",
    "modelC10.add(layers.Dense(16, input_shape=(7,),\n",
    "                         activation='relu'))\n",
    "modelC10.add(layers.Dense(16, activation='relu'))\n",
    "modelC10.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "modelC10.compile(loss=\"binary_crossentropy\", optimizer='adam',\n",
    "                 metrics=['accuracy'])\n",
    "print('Part C10 model constructed')\n",
    "\n",
    "# 80% train, 20% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=seed)\n",
    "\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T22:34:46.545335800Z",
     "start_time": "2023-12-02T22:34:46.493678400Z"
    }
   },
   "id": "c0ca2865bf88665d"
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----START PART C10: 80:20 test-train----\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 63ms/step - loss: 0.7136 - accuracy: 0.5256 - val_loss: 0.8072 - val_accuracy: 0.4500\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6938 - accuracy: 0.5256 - val_loss: 0.7917 - val_accuracy: 0.4500\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6740 - accuracy: 0.5256 - val_loss: 0.7769 - val_accuracy: 0.4500\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6572 - accuracy: 0.5256 - val_loss: 0.7632 - val_accuracy: 0.4500\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6402 - accuracy: 0.5256 - val_loss: 0.7503 - val_accuracy: 0.4500\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6242 - accuracy: 0.5256 - val_loss: 0.7388 - val_accuracy: 0.4500\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6095 - accuracy: 0.5256 - val_loss: 0.7282 - val_accuracy: 0.4500\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5957 - accuracy: 0.5256 - val_loss: 0.7181 - val_accuracy: 0.4500\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5820 - accuracy: 0.5256 - val_loss: 0.7088 - val_accuracy: 0.4500\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5685 - accuracy: 0.5256 - val_loss: 0.7003 - val_accuracy: 0.4500\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5567 - accuracy: 0.5256 - val_loss: 0.6919 - val_accuracy: 0.4500\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5454 - accuracy: 0.5513 - val_loss: 0.6844 - val_accuracy: 0.4500\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5341 - accuracy: 0.5513 - val_loss: 0.6770 - val_accuracy: 0.4500\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5234 - accuracy: 0.5769 - val_loss: 0.6704 - val_accuracy: 0.4500\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5135 - accuracy: 0.5769 - val_loss: 0.6643 - val_accuracy: 0.4500\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5038 - accuracy: 0.5897 - val_loss: 0.6594 - val_accuracy: 0.4000\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4938 - accuracy: 0.6667 - val_loss: 0.6546 - val_accuracy: 0.4000\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4848 - accuracy: 0.6538 - val_loss: 0.6501 - val_accuracy: 0.4500\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4761 - accuracy: 0.6667 - val_loss: 0.6457 - val_accuracy: 0.4500\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4670 - accuracy: 0.6667 - val_loss: 0.6422 - val_accuracy: 0.4500\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4586 - accuracy: 0.6923 - val_loss: 0.6387 - val_accuracy: 0.4500\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4503 - accuracy: 0.7308 - val_loss: 0.6352 - val_accuracy: 0.5500\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4425 - accuracy: 0.7692 - val_loss: 0.6312 - val_accuracy: 0.6000\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4341 - accuracy: 0.7949 - val_loss: 0.6275 - val_accuracy: 0.6000\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4261 - accuracy: 0.7821 - val_loss: 0.6240 - val_accuracy: 0.6000\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4184 - accuracy: 0.8077 - val_loss: 0.6206 - val_accuracy: 0.6000\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4100 - accuracy: 0.8333 - val_loss: 0.6175 - val_accuracy: 0.5500\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4029 - accuracy: 0.8333 - val_loss: 0.6146 - val_accuracy: 0.5500\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3950 - accuracy: 0.8462 - val_loss: 0.6122 - val_accuracy: 0.6000\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3876 - accuracy: 0.8462 - val_loss: 0.6102 - val_accuracy: 0.6000\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3803 - accuracy: 0.8718 - val_loss: 0.6078 - val_accuracy: 0.6000\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3723 - accuracy: 0.8974 - val_loss: 0.6057 - val_accuracy: 0.5500\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3653 - accuracy: 0.8974 - val_loss: 0.6031 - val_accuracy: 0.5500\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3582 - accuracy: 0.8974 - val_loss: 0.6007 - val_accuracy: 0.5500\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3507 - accuracy: 0.8974 - val_loss: 0.5976 - val_accuracy: 0.6500\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3433 - accuracy: 0.8974 - val_loss: 0.5945 - val_accuracy: 0.6500\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3361 - accuracy: 0.8974 - val_loss: 0.5918 - val_accuracy: 0.6500\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3293 - accuracy: 0.9103 - val_loss: 0.5895 - val_accuracy: 0.7500\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3223 - accuracy: 0.9103 - val_loss: 0.5878 - val_accuracy: 0.7500\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3155 - accuracy: 0.9103 - val_loss: 0.5864 - val_accuracy: 0.7500\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3092 - accuracy: 0.9103 - val_loss: 0.5845 - val_accuracy: 0.7500\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3021 - accuracy: 0.9103 - val_loss: 0.5835 - val_accuracy: 0.7500\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2965 - accuracy: 0.9103 - val_loss: 0.5822 - val_accuracy: 0.7500\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2902 - accuracy: 0.9231 - val_loss: 0.5808 - val_accuracy: 0.7500\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2843 - accuracy: 0.9359 - val_loss: 0.5799 - val_accuracy: 0.7500\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2781 - accuracy: 0.9359 - val_loss: 0.5795 - val_accuracy: 0.7500\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2727 - accuracy: 0.9359 - val_loss: 0.5791 - val_accuracy: 0.7500\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.2673 - accuracy: 0.9231 - val_loss: 0.5795 - val_accuracy: 0.7500\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2620 - accuracy: 0.9231 - val_loss: 0.5802 - val_accuracy: 0.7500\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2567 - accuracy: 0.9231 - val_loss: 0.5810 - val_accuracy: 0.7500\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.2520 - accuracy: 0.9359 - val_loss: 0.5821 - val_accuracy: 0.7500\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.2470 - accuracy: 0.9359 - val_loss: 0.5833 - val_accuracy: 0.7500\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.2424 - accuracy: 0.9231 - val_loss: 0.5844 - val_accuracy: 0.7500\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.2379 - accuracy: 0.9231 - val_loss: 0.5859 - val_accuracy: 0.7500\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.2332 - accuracy: 0.9231 - val_loss: 0.5872 - val_accuracy: 0.7500\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.2293 - accuracy: 0.9231 - val_loss: 0.5886 - val_accuracy: 0.7500\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.2251 - accuracy: 0.9231 - val_loss: 0.5903 - val_accuracy: 0.7500\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.2210 - accuracy: 0.9231 - val_loss: 0.5923 - val_accuracy: 0.7500\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2171 - accuracy: 0.9231 - val_loss: 0.5945 - val_accuracy: 0.7500\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.2134 - accuracy: 0.9231 - val_loss: 0.5968 - val_accuracy: 0.7500\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.2099 - accuracy: 0.9231 - val_loss: 0.5988 - val_accuracy: 0.7500\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.2062 - accuracy: 0.9231 - val_loss: 0.6011 - val_accuracy: 0.7500\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.2030 - accuracy: 0.9231 - val_loss: 0.6041 - val_accuracy: 0.7500\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.1996 - accuracy: 0.9231 - val_loss: 0.6070 - val_accuracy: 0.7500\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.1967 - accuracy: 0.9231 - val_loss: 0.6097 - val_accuracy: 0.7500\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1936 - accuracy: 0.9231 - val_loss: 0.6128 - val_accuracy: 0.7500\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1904 - accuracy: 0.9231 - val_loss: 0.6160 - val_accuracy: 0.7500\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1878 - accuracy: 0.9231 - val_loss: 0.6192 - val_accuracy: 0.7500\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1848 - accuracy: 0.9231 - val_loss: 0.6226 - val_accuracy: 0.7500\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.1820 - accuracy: 0.9231 - val_loss: 0.6261 - val_accuracy: 0.7500\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1795 - accuracy: 0.9231 - val_loss: 0.6293 - val_accuracy: 0.7500\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.1769 - accuracy: 0.9231 - val_loss: 0.6326 - val_accuracy: 0.7500\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.1744 - accuracy: 0.9231 - val_loss: 0.6362 - val_accuracy: 0.7500\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 0.1718 - accuracy: 0.9231 - val_loss: 0.6397 - val_accuracy: 0.7500\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 0.1695 - accuracy: 0.9231 - val_loss: 0.6430 - val_accuracy: 0.7500\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.1673 - accuracy: 0.9231 - val_loss: 0.6465 - val_accuracy: 0.7500\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.1653 - accuracy: 0.9359 - val_loss: 0.6500 - val_accuracy: 0.7500\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.1631 - accuracy: 0.9359 - val_loss: 0.6538 - val_accuracy: 0.7500\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.1612 - accuracy: 0.9359 - val_loss: 0.6575 - val_accuracy: 0.7500\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.1591 - accuracy: 0.9359 - val_loss: 0.6615 - val_accuracy: 0.7500\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.1574 - accuracy: 0.9359 - val_loss: 0.6651 - val_accuracy: 0.7500\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.1551 - accuracy: 0.9359 - val_loss: 0.6685 - val_accuracy: 0.7500\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.1534 - accuracy: 0.9359 - val_loss: 0.6721 - val_accuracy: 0.7500\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 0.1517 - accuracy: 0.9615 - val_loss: 0.6753 - val_accuracy: 0.7500\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 0.1498 - accuracy: 0.9615 - val_loss: 0.6784 - val_accuracy: 0.7500\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 0.1482 - accuracy: 0.9615 - val_loss: 0.6817 - val_accuracy: 0.7500\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 0.1464 - accuracy: 0.9615 - val_loss: 0.6850 - val_accuracy: 0.7500\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 0.1448 - accuracy: 0.9615 - val_loss: 0.6885 - val_accuracy: 0.7500\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.1432 - accuracy: 0.9615 - val_loss: 0.6921 - val_accuracy: 0.7500\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.1417 - accuracy: 0.9615 - val_loss: 0.6959 - val_accuracy: 0.7500\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.1400 - accuracy: 0.9615 - val_loss: 0.6991 - val_accuracy: 0.7500\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.1385 - accuracy: 0.9615 - val_loss: 0.7023 - val_accuracy: 0.7500\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1369 - accuracy: 0.9615 - val_loss: 0.7057 - val_accuracy: 0.7500\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.1355 - accuracy: 0.9615 - val_loss: 0.7090 - val_accuracy: 0.7500\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.1340 - accuracy: 0.9615 - val_loss: 0.7124 - val_accuracy: 0.7500\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.1326 - accuracy: 0.9615 - val_loss: 0.7161 - val_accuracy: 0.7500\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1314 - accuracy: 0.9615 - val_loss: 0.7197 - val_accuracy: 0.7500\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.1300 - accuracy: 0.9615 - val_loss: 0.7234 - val_accuracy: 0.7500\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.1286 - accuracy: 0.9615 - val_loss: 0.7270 - val_accuracy: 0.7500\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.1274 - accuracy: 0.9615 - val_loss: 0.7305 - val_accuracy: 0.7500\n",
      "6.3986 seconds elapsed.\n"
     ]
    }
   ],
   "source": [
    "print('----START PART C10: 80:20 test-train----')\n",
    "tic = time.time()\n",
    "modelC10.fit(X_train_std, y_train,\n",
    "             validation_data=(X_test_std, y_test),\n",
    "             epochs=100, batch_size=32)\n",
    "toc = time.time()\n",
    "print(f'{(toc - tic):.04f} seconds elapsed.')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T22:35:10.233474800Z",
     "start_time": "2023-12-02T22:35:03.763772100Z"
    }
   },
   "id": "4df713a438b7910c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Experiment C11 (Double Second Layer Neurons):\n",
    "* Explore how adjusting second layer neuron count from 16 to 32 \n",
    "  impacts model performance \n",
    "* Still using 2 hidden layers\n",
    "\n",
    "All other parameters are the same as C1\n",
    "\n",
    "Create new model C11\n",
    "Standardized Data\n",
    "De-Correlation: None\n",
    "* Input Layer: 7 neurons\n",
    "* Hidden Layers: 2\n",
    "    * Layer 1: 16 neurons; RELU\n",
    "    * Layer 2: 32 neurons; RELU\n",
    "* Output Layer: 1 neuron; Sigmoid\n",
    "* Loss fn: Binary Cross Entropy\n",
    "* Optimizer: Adam\n",
    "* Metrics: Accuracy\n",
    "\n",
    "Hyperparams:\n",
    "* Epochs: 100\n",
    "* Train-Test Split: 67/33\n",
    "* Batch Size: 32"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6e93aa66dce5640e"
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part C11 model constructed\n"
     ]
    }
   ],
   "source": [
    "# C11: batch size to 32. No correlation drops. 100 Epochs.\n",
    "# 32 second layer neurons\n",
    "modelC11 = keras.Sequential()\n",
    "modelC11.add(layers.Dense(16, input_shape=(7,),\n",
    "                          activation='relu'))\n",
    "modelC11.add(layers.Dense(32, activation='relu'))\n",
    "modelC11.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "modelC11.compile(loss=\"binary_crossentropy\", optimizer='adam',\n",
    "                 metrics=['accuracy'])\n",
    "print('Part C11 model constructed')\n",
    "\n",
    "# 67% train, 33% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y,\n",
    "                                                    test_size=0.33,\n",
    "                                                    random_state=seed)\n",
    "\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T22:38:55.563917700Z",
     "start_time": "2023-12-02T22:38:55.501616400Z"
    }
   },
   "id": "33ae7804e989f3c1"
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----START PART C11: 32 second layer neurons test----\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 67ms/step - loss: 0.6914 - accuracy: 0.5077 - val_loss: 0.6378 - val_accuracy: 0.6667\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6724 - accuracy: 0.5538 - val_loss: 0.6245 - val_accuracy: 0.6667\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6575 - accuracy: 0.5692 - val_loss: 0.6137 - val_accuracy: 0.7576\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6436 - accuracy: 0.6462 - val_loss: 0.6045 - val_accuracy: 0.7576\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6320 - accuracy: 0.7385 - val_loss: 0.5959 - val_accuracy: 0.7576\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6205 - accuracy: 0.7692 - val_loss: 0.5873 - val_accuracy: 0.7576\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6092 - accuracy: 0.7692 - val_loss: 0.5789 - val_accuracy: 0.7576\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5991 - accuracy: 0.8000 - val_loss: 0.5711 - val_accuracy: 0.7576\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5898 - accuracy: 0.8154 - val_loss: 0.5651 - val_accuracy: 0.7576\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5820 - accuracy: 0.8154 - val_loss: 0.5589 - val_accuracy: 0.7576\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5733 - accuracy: 0.8154 - val_loss: 0.5524 - val_accuracy: 0.7576\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5645 - accuracy: 0.8154 - val_loss: 0.5458 - val_accuracy: 0.7576\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5551 - accuracy: 0.8154 - val_loss: 0.5386 - val_accuracy: 0.7879\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5451 - accuracy: 0.8462 - val_loss: 0.5316 - val_accuracy: 0.7879\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5356 - accuracy: 0.8462 - val_loss: 0.5250 - val_accuracy: 0.7879\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5263 - accuracy: 0.8462 - val_loss: 0.5186 - val_accuracy: 0.7879\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5176 - accuracy: 0.8615 - val_loss: 0.5130 - val_accuracy: 0.7879\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5088 - accuracy: 0.8923 - val_loss: 0.5079 - val_accuracy: 0.7879\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5009 - accuracy: 0.8923 - val_loss: 0.5026 - val_accuracy: 0.8182\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4927 - accuracy: 0.9077 - val_loss: 0.4970 - val_accuracy: 0.8182\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4846 - accuracy: 0.9077 - val_loss: 0.4911 - val_accuracy: 0.8485\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4764 - accuracy: 0.9077 - val_loss: 0.4854 - val_accuracy: 0.8485\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4683 - accuracy: 0.9077 - val_loss: 0.4804 - val_accuracy: 0.8485\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4605 - accuracy: 0.9077 - val_loss: 0.4752 - val_accuracy: 0.8485\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4531 - accuracy: 0.8923 - val_loss: 0.4695 - val_accuracy: 0.8485\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4454 - accuracy: 0.8923 - val_loss: 0.4639 - val_accuracy: 0.8485\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4374 - accuracy: 0.8923 - val_loss: 0.4586 - val_accuracy: 0.8485\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4297 - accuracy: 0.8923 - val_loss: 0.4537 - val_accuracy: 0.8485\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4222 - accuracy: 0.8923 - val_loss: 0.4489 - val_accuracy: 0.8485\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4149 - accuracy: 0.8923 - val_loss: 0.4440 - val_accuracy: 0.8485\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4077 - accuracy: 0.8923 - val_loss: 0.4391 - val_accuracy: 0.8485\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4006 - accuracy: 0.8923 - val_loss: 0.4342 - val_accuracy: 0.8485\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3936 - accuracy: 0.8923 - val_loss: 0.4293 - val_accuracy: 0.8485\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3867 - accuracy: 0.8923 - val_loss: 0.4245 - val_accuracy: 0.8485\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3803 - accuracy: 0.8923 - val_loss: 0.4203 - val_accuracy: 0.8485\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3742 - accuracy: 0.8923 - val_loss: 0.4163 - val_accuracy: 0.8485\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3677 - accuracy: 0.8923 - val_loss: 0.4128 - val_accuracy: 0.8485\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3610 - accuracy: 0.8923 - val_loss: 0.4101 - val_accuracy: 0.8485\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3551 - accuracy: 0.8923 - val_loss: 0.4074 - val_accuracy: 0.8485\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3486 - accuracy: 0.9077 - val_loss: 0.4049 - val_accuracy: 0.8485\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3422 - accuracy: 0.9077 - val_loss: 0.4025 - val_accuracy: 0.8485\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3358 - accuracy: 0.9231 - val_loss: 0.4000 - val_accuracy: 0.8182\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3301 - accuracy: 0.9231 - val_loss: 0.3973 - val_accuracy: 0.8182\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3245 - accuracy: 0.9231 - val_loss: 0.3945 - val_accuracy: 0.8182\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3197 - accuracy: 0.9231 - val_loss: 0.3919 - val_accuracy: 0.8182\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3149 - accuracy: 0.9231 - val_loss: 0.3896 - val_accuracy: 0.8182\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3100 - accuracy: 0.9231 - val_loss: 0.3876 - val_accuracy: 0.8182\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3053 - accuracy: 0.9231 - val_loss: 0.3857 - val_accuracy: 0.8182\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3003 - accuracy: 0.9231 - val_loss: 0.3842 - val_accuracy: 0.8182\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2959 - accuracy: 0.9231 - val_loss: 0.3829 - val_accuracy: 0.7879\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2922 - accuracy: 0.9231 - val_loss: 0.3815 - val_accuracy: 0.7879\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2890 - accuracy: 0.9231 - val_loss: 0.3805 - val_accuracy: 0.7879\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2856 - accuracy: 0.9231 - val_loss: 0.3801 - val_accuracy: 0.7879\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2820 - accuracy: 0.9231 - val_loss: 0.3803 - val_accuracy: 0.7879\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2783 - accuracy: 0.9231 - val_loss: 0.3803 - val_accuracy: 0.8182\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2748 - accuracy: 0.9231 - val_loss: 0.3803 - val_accuracy: 0.8182\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2708 - accuracy: 0.9231 - val_loss: 0.3802 - val_accuracy: 0.8182\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2672 - accuracy: 0.9231 - val_loss: 0.3802 - val_accuracy: 0.8182\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2631 - accuracy: 0.9231 - val_loss: 0.3801 - val_accuracy: 0.8182\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2597 - accuracy: 0.9231 - val_loss: 0.3803 - val_accuracy: 0.8182\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2562 - accuracy: 0.9231 - val_loss: 0.3805 - val_accuracy: 0.8182\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2528 - accuracy: 0.9231 - val_loss: 0.3805 - val_accuracy: 0.8182\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2495 - accuracy: 0.9231 - val_loss: 0.3803 - val_accuracy: 0.8182\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2460 - accuracy: 0.9231 - val_loss: 0.3802 - val_accuracy: 0.8182\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2426 - accuracy: 0.9231 - val_loss: 0.3802 - val_accuracy: 0.8182\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2392 - accuracy: 0.9231 - val_loss: 0.3803 - val_accuracy: 0.8182\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2361 - accuracy: 0.9231 - val_loss: 0.3809 - val_accuracy: 0.8182\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2328 - accuracy: 0.9385 - val_loss: 0.3822 - val_accuracy: 0.8182\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2303 - accuracy: 0.9385 - val_loss: 0.3835 - val_accuracy: 0.8182\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2278 - accuracy: 0.9385 - val_loss: 0.3842 - val_accuracy: 0.8182\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2250 - accuracy: 0.9385 - val_loss: 0.3842 - val_accuracy: 0.8182\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2224 - accuracy: 0.9385 - val_loss: 0.3839 - val_accuracy: 0.8182\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2197 - accuracy: 0.9385 - val_loss: 0.3841 - val_accuracy: 0.8182\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2172 - accuracy: 0.9385 - val_loss: 0.3841 - val_accuracy: 0.8182\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2148 - accuracy: 0.9385 - val_loss: 0.3841 - val_accuracy: 0.8182\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2122 - accuracy: 0.9385 - val_loss: 0.3844 - val_accuracy: 0.8182\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2097 - accuracy: 0.9538 - val_loss: 0.3846 - val_accuracy: 0.8182\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2077 - accuracy: 0.9538 - val_loss: 0.3847 - val_accuracy: 0.8182\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2053 - accuracy: 0.9538 - val_loss: 0.3850 - val_accuracy: 0.8182\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2032 - accuracy: 0.9538 - val_loss: 0.3854 - val_accuracy: 0.8182\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2010 - accuracy: 0.9538 - val_loss: 0.3862 - val_accuracy: 0.8182\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1991 - accuracy: 0.9538 - val_loss: 0.3871 - val_accuracy: 0.8182\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1972 - accuracy: 0.9538 - val_loss: 0.3879 - val_accuracy: 0.8182\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1953 - accuracy: 0.9538 - val_loss: 0.3886 - val_accuracy: 0.8182\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1939 - accuracy: 0.9538 - val_loss: 0.3892 - val_accuracy: 0.8182\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1925 - accuracy: 0.9538 - val_loss: 0.3899 - val_accuracy: 0.8182\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1912 - accuracy: 0.9538 - val_loss: 0.3906 - val_accuracy: 0.8182\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1897 - accuracy: 0.9538 - val_loss: 0.3913 - val_accuracy: 0.8182\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1881 - accuracy: 0.9538 - val_loss: 0.3922 - val_accuracy: 0.8182\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1864 - accuracy: 0.9538 - val_loss: 0.3932 - val_accuracy: 0.8182\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1846 - accuracy: 0.9538 - val_loss: 0.3941 - val_accuracy: 0.8182\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1836 - accuracy: 0.9538 - val_loss: 0.3956 - val_accuracy: 0.8182\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1823 - accuracy: 0.9538 - val_loss: 0.3970 - val_accuracy: 0.8182\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1814 - accuracy: 0.9538 - val_loss: 0.3981 - val_accuracy: 0.8182\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1795 - accuracy: 0.9538 - val_loss: 0.3986 - val_accuracy: 0.8182\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1779 - accuracy: 0.9538 - val_loss: 0.3994 - val_accuracy: 0.8182\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1766 - accuracy: 0.9538 - val_loss: 0.4002 - val_accuracy: 0.8182\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1752 - accuracy: 0.9538 - val_loss: 0.4013 - val_accuracy: 0.8182\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.1738 - accuracy: 0.9538 - val_loss: 0.4025 - val_accuracy: 0.8182\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1724 - accuracy: 0.9538 - val_loss: 0.4037 - val_accuracy: 0.8182\n",
      "3.7383 seconds elapsed.\n"
     ]
    }
   ],
   "source": [
    "print('----START PART C11: 32 second layer neurons test----')\n",
    "tic = time.time()\n",
    "modelC11.fit(X_train_std, y_train,\n",
    "             validation_data=(X_test_std, y_test),\n",
    "             epochs=100, batch_size=32)\n",
    "toc = time.time()\n",
    "print(f'{(toc - tic):.04f} seconds elapsed.')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T22:39:44.101594400Z",
     "start_time": "2023-12-02T22:39:40.348257300Z"
    }
   },
   "id": "f8ae67e815e720d7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Experiment C12 (Adding a 3rd Hidden Layer):\n",
    "* Explore how adding a third 16 layer hidden layer \n",
    "  impacts model performance \n",
    "* Still using 2 hidden layers\n",
    "\n",
    "All other parameters are the same as C1\n",
    "\n",
    "Create new model C12\n",
    "Standardized Data\n",
    "De-Correlation: None\n",
    "* Input Layer: 7 neurons\n",
    "* Hidden Layers: 3\n",
    "    * Layer 1: 16 neurons; RELU\n",
    "    * Layer 2: 16 neurons; RELU\n",
    "    * Layer 3: 16 neurons; RELU\n",
    "* Output Layer: 1 neuron; Sigmoid\n",
    "* Loss fn: Binary Cross Entropy\n",
    "* Optimizer: Adam\n",
    "* Metrics: Accuracy\n",
    "\n",
    "Hyperparams:\n",
    "* Epochs: 100\n",
    "* Train-Test Split: 67/33\n",
    "* Batch Size: 32"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "412a4b1d9ed4005c"
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part C12 model constructed\n"
     ]
    }
   ],
   "source": [
    "# C12: batch size to 32. No correlation drops. 100 Epochs.\n",
    "# C1 but a Third layer of 16 neurons.\n",
    "modelC12 = keras.Sequential()\n",
    "modelC12.add(layers.Dense(16, input_shape=(7,),\n",
    "                          activation='relu'))\n",
    "modelC12.add(layers.Dense(16, activation='relu'))\n",
    "modelC12.add(layers.Dense(16, activation='relu'))\n",
    "modelC12.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "modelC12.compile(loss=\"binary_crossentropy\", optimizer='adam',\n",
    "                 metrics=['accuracy'])\n",
    "print('Part C12 model constructed')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T22:43:03.655864Z",
     "start_time": "2023-12-02T22:43:03.615508800Z"
    }
   },
   "id": "3dc8c6ef8f365300"
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----START PART C12: 3rd layer of 16 neurons test----\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 71ms/step - loss: 0.7142 - accuracy: 0.4462 - val_loss: 0.6835 - val_accuracy: 0.4848\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.7035 - accuracy: 0.4769 - val_loss: 0.6793 - val_accuracy: 0.5152\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6952 - accuracy: 0.5385 - val_loss: 0.6756 - val_accuracy: 0.4848\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6885 - accuracy: 0.5692 - val_loss: 0.6721 - val_accuracy: 0.5455\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6831 - accuracy: 0.6462 - val_loss: 0.6690 - val_accuracy: 0.5758\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6772 - accuracy: 0.6769 - val_loss: 0.6659 - val_accuracy: 0.5455\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6722 - accuracy: 0.6615 - val_loss: 0.6629 - val_accuracy: 0.5758\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6668 - accuracy: 0.6769 - val_loss: 0.6598 - val_accuracy: 0.5758\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6615 - accuracy: 0.6769 - val_loss: 0.6565 - val_accuracy: 0.5758\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6560 - accuracy: 0.6923 - val_loss: 0.6532 - val_accuracy: 0.5758\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6510 - accuracy: 0.7231 - val_loss: 0.6500 - val_accuracy: 0.6061\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6455 - accuracy: 0.7692 - val_loss: 0.6471 - val_accuracy: 0.6364\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6403 - accuracy: 0.7692 - val_loss: 0.6442 - val_accuracy: 0.6364\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6346 - accuracy: 0.7538 - val_loss: 0.6412 - val_accuracy: 0.6364\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6293 - accuracy: 0.7538 - val_loss: 0.6382 - val_accuracy: 0.6364\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6242 - accuracy: 0.7692 - val_loss: 0.6349 - val_accuracy: 0.6364\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6188 - accuracy: 0.7692 - val_loss: 0.6314 - val_accuracy: 0.6364\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6128 - accuracy: 0.7692 - val_loss: 0.6276 - val_accuracy: 0.6667\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6073 - accuracy: 0.7538 - val_loss: 0.6231 - val_accuracy: 0.6667\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6018 - accuracy: 0.7385 - val_loss: 0.6185 - val_accuracy: 0.6667\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5951 - accuracy: 0.7538 - val_loss: 0.6146 - val_accuracy: 0.6667\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5904 - accuracy: 0.7538 - val_loss: 0.6112 - val_accuracy: 0.6667\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5853 - accuracy: 0.7692 - val_loss: 0.6077 - val_accuracy: 0.6970\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5808 - accuracy: 0.7538 - val_loss: 0.6043 - val_accuracy: 0.6970\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5750 - accuracy: 0.7538 - val_loss: 0.6004 - val_accuracy: 0.6970\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5692 - accuracy: 0.7692 - val_loss: 0.5958 - val_accuracy: 0.6970\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5631 - accuracy: 0.7692 - val_loss: 0.5911 - val_accuracy: 0.6970\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5564 - accuracy: 0.7846 - val_loss: 0.5859 - val_accuracy: 0.7273\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5495 - accuracy: 0.8154 - val_loss: 0.5804 - val_accuracy: 0.7576\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5431 - accuracy: 0.8154 - val_loss: 0.5752 - val_accuracy: 0.7576\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5358 - accuracy: 0.8308 - val_loss: 0.5701 - val_accuracy: 0.7273\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5293 - accuracy: 0.8615 - val_loss: 0.5654 - val_accuracy: 0.7273\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5233 - accuracy: 0.8615 - val_loss: 0.5605 - val_accuracy: 0.7273\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5165 - accuracy: 0.8615 - val_loss: 0.5554 - val_accuracy: 0.7273\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5097 - accuracy: 0.8615 - val_loss: 0.5501 - val_accuracy: 0.7576\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5023 - accuracy: 0.8615 - val_loss: 0.5446 - val_accuracy: 0.7576\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4947 - accuracy: 0.8615 - val_loss: 0.5394 - val_accuracy: 0.7879\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4869 - accuracy: 0.8615 - val_loss: 0.5350 - val_accuracy: 0.7879\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4796 - accuracy: 0.8615 - val_loss: 0.5298 - val_accuracy: 0.7879\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4716 - accuracy: 0.8615 - val_loss: 0.5243 - val_accuracy: 0.7879\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4629 - accuracy: 0.8615 - val_loss: 0.5187 - val_accuracy: 0.7879\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4548 - accuracy: 0.8615 - val_loss: 0.5131 - val_accuracy: 0.7879\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4459 - accuracy: 0.8615 - val_loss: 0.5074 - val_accuracy: 0.7879\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4375 - accuracy: 0.8615 - val_loss: 0.5024 - val_accuracy: 0.7879\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4291 - accuracy: 0.8769 - val_loss: 0.4980 - val_accuracy: 0.7879\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4209 - accuracy: 0.8769 - val_loss: 0.4939 - val_accuracy: 0.7879\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4127 - accuracy: 0.8769 - val_loss: 0.4894 - val_accuracy: 0.7879\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4047 - accuracy: 0.8769 - val_loss: 0.4842 - val_accuracy: 0.8182\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3966 - accuracy: 0.8769 - val_loss: 0.4794 - val_accuracy: 0.8182\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3888 - accuracy: 0.8769 - val_loss: 0.4748 - val_accuracy: 0.8182\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3808 - accuracy: 0.8769 - val_loss: 0.4699 - val_accuracy: 0.8182\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3724 - accuracy: 0.8769 - val_loss: 0.4653 - val_accuracy: 0.8182\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3638 - accuracy: 0.8769 - val_loss: 0.4615 - val_accuracy: 0.8182\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3556 - accuracy: 0.8769 - val_loss: 0.4584 - val_accuracy: 0.8182\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3472 - accuracy: 0.8769 - val_loss: 0.4555 - val_accuracy: 0.8182\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3386 - accuracy: 0.9077 - val_loss: 0.4526 - val_accuracy: 0.8182\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3304 - accuracy: 0.9077 - val_loss: 0.4494 - val_accuracy: 0.8182\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3225 - accuracy: 0.9231 - val_loss: 0.4453 - val_accuracy: 0.8182\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3155 - accuracy: 0.9385 - val_loss: 0.4418 - val_accuracy: 0.8182\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3081 - accuracy: 0.9385 - val_loss: 0.4389 - val_accuracy: 0.8182\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3007 - accuracy: 0.9385 - val_loss: 0.4360 - val_accuracy: 0.8182\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2937 - accuracy: 0.9385 - val_loss: 0.4326 - val_accuracy: 0.8182\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2871 - accuracy: 0.9385 - val_loss: 0.4295 - val_accuracy: 0.8182\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2798 - accuracy: 0.9385 - val_loss: 0.4285 - val_accuracy: 0.8182\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2722 - accuracy: 0.9385 - val_loss: 0.4291 - val_accuracy: 0.8182\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2648 - accuracy: 0.9385 - val_loss: 0.4308 - val_accuracy: 0.8182\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2578 - accuracy: 0.9385 - val_loss: 0.4318 - val_accuracy: 0.8182\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2507 - accuracy: 0.9385 - val_loss: 0.4318 - val_accuracy: 0.8182\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2442 - accuracy: 0.9385 - val_loss: 0.4326 - val_accuracy: 0.8182\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2380 - accuracy: 0.9385 - val_loss: 0.4334 - val_accuracy: 0.8182\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2323 - accuracy: 0.9385 - val_loss: 0.4355 - val_accuracy: 0.8182\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2264 - accuracy: 0.9385 - val_loss: 0.4395 - val_accuracy: 0.8182\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2213 - accuracy: 0.9385 - val_loss: 0.4428 - val_accuracy: 0.8182\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2168 - accuracy: 0.9385 - val_loss: 0.4456 - val_accuracy: 0.8182\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2128 - accuracy: 0.9385 - val_loss: 0.4498 - val_accuracy: 0.8182\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2103 - accuracy: 0.9385 - val_loss: 0.4528 - val_accuracy: 0.8182\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2076 - accuracy: 0.9385 - val_loss: 0.4555 - val_accuracy: 0.8182\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.2050 - accuracy: 0.9538 - val_loss: 0.4584 - val_accuracy: 0.8182\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.2022 - accuracy: 0.9538 - val_loss: 0.4615 - val_accuracy: 0.8182\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1995 - accuracy: 0.9538 - val_loss: 0.4651 - val_accuracy: 0.8182\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1973 - accuracy: 0.9385 - val_loss: 0.4703 - val_accuracy: 0.8182\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1964 - accuracy: 0.9385 - val_loss: 0.4753 - val_accuracy: 0.8182\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1951 - accuracy: 0.9385 - val_loss: 0.4792 - val_accuracy: 0.8182\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1930 - accuracy: 0.9385 - val_loss: 0.4821 - val_accuracy: 0.8182\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1907 - accuracy: 0.9385 - val_loss: 0.4828 - val_accuracy: 0.8182\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1874 - accuracy: 0.9538 - val_loss: 0.4822 - val_accuracy: 0.8182\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1835 - accuracy: 0.9385 - val_loss: 0.4827 - val_accuracy: 0.8182\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1803 - accuracy: 0.9385 - val_loss: 0.4799 - val_accuracy: 0.8182\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1761 - accuracy: 0.9385 - val_loss: 0.4760 - val_accuracy: 0.8182\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1707 - accuracy: 0.9385 - val_loss: 0.4745 - val_accuracy: 0.8182\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1681 - accuracy: 0.9385 - val_loss: 0.4744 - val_accuracy: 0.8182\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1646 - accuracy: 0.9385 - val_loss: 0.4756 - val_accuracy: 0.8182\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1619 - accuracy: 0.9385 - val_loss: 0.4769 - val_accuracy: 0.8182\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1596 - accuracy: 0.9385 - val_loss: 0.4793 - val_accuracy: 0.8182\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1577 - accuracy: 0.9385 - val_loss: 0.4839 - val_accuracy: 0.8182\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1566 - accuracy: 0.9385 - val_loss: 0.4824 - val_accuracy: 0.8182\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1532 - accuracy: 0.9385 - val_loss: 0.4747 - val_accuracy: 0.8182\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.1521 - accuracy: 0.9538 - val_loss: 0.4710 - val_accuracy: 0.8182\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1500 - accuracy: 0.9538 - val_loss: 0.4695 - val_accuracy: 0.8182\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.1500 - accuracy: 0.9538 - val_loss: 0.4686 - val_accuracy: 0.8788\n",
      "3.9186 seconds elapsed.\n"
     ]
    }
   ],
   "source": [
    "print('----START PART C12: 3rd layer of 16 neurons test----')\n",
    "tic = time.time()\n",
    "modelC12.fit(X_train_std, y_train,\n",
    "             validation_data=(X_test_std, y_test),\n",
    "             epochs=100, batch_size=32)\n",
    "toc = time.time()\n",
    "print(f'{(toc - tic):.04f} seconds elapsed.')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T22:43:22.747497500Z",
     "start_time": "2023-12-02T22:43:18.822496800Z"
    }
   },
   "id": "a10aabac6370db20"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Experiment C13 (SGD Optimizer):\n",
    "* Explore how changing from the adam optimizer to the sgd optimizer \n",
    "  impacts model performance \n",
    "* Still using 2 hidden layers\n",
    "\n",
    "All other parameters are the same as C1\n",
    "\n",
    "Create new model C13\n",
    "Standardized Data\n",
    "De-Correlation: None\n",
    "* Input Layer: 7 neurons\n",
    "* Hidden Layers: 2\n",
    "    * Layer 1: 16 neurons; RELU\n",
    "    * Layer 2: 16 neurons; RELU\n",
    "* Output Layer: 1 neuron; Sigmoid\n",
    "* Loss fn: Binary Cross Entropy\n",
    "* Optimizer: SGD\n",
    "* Metrics: Accuracy\n",
    "\n",
    "Hyperparams:\n",
    "* Epochs: 100\n",
    "* Train-Test Split: 67/33\n",
    "* Batch Size: 32"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f0be18c82ab93941"
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part C13 model constructed\n"
     ]
    }
   ],
   "source": [
    "# C13: batch size to 32. No correlation drops. 100 Epochs.\n",
    "# C1 but use SGD for the optimizer.\n",
    "modelC13 = keras.Sequential()\n",
    "modelC13.add(layers.Dense(16, input_shape=(7,),\n",
    "                          activation='relu'))\n",
    "modelC13.add(layers.Dense(16, activation='relu'))\n",
    "modelC13.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "modelC13.compile(loss=\"binary_crossentropy\", optimizer='sgd',\n",
    "                 metrics=['accuracy'])\n",
    "print('Part C13 model constructed')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T22:50:06.541757200Z",
     "start_time": "2023-12-02T22:50:06.465316100Z"
    }
   },
   "id": "95313cce91f1bead"
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----START PART C13: SGD Optimizer test----\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 0s 62ms/step - loss: 0.6945 - accuracy: 0.5077 - val_loss: 0.7238 - val_accuracy: 0.4848\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6893 - accuracy: 0.5077 - val_loss: 0.7185 - val_accuracy: 0.5152\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6848 - accuracy: 0.5231 - val_loss: 0.7159 - val_accuracy: 0.5455\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6822 - accuracy: 0.5538 - val_loss: 0.7102 - val_accuracy: 0.5455\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6780 - accuracy: 0.5692 - val_loss: 0.7034 - val_accuracy: 0.5455\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6727 - accuracy: 0.5692 - val_loss: 0.6988 - val_accuracy: 0.5455\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6678 - accuracy: 0.5846 - val_loss: 0.6944 - val_accuracy: 0.5455\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6624 - accuracy: 0.6000 - val_loss: 0.6759 - val_accuracy: 0.6364\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6501 - accuracy: 0.6615 - val_loss: 0.6686 - val_accuracy: 0.6364\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6442 - accuracy: 0.6923 - val_loss: 0.6649 - val_accuracy: 0.6667\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6398 - accuracy: 0.7231 - val_loss: 0.6552 - val_accuracy: 0.6667\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6318 - accuracy: 0.7385 - val_loss: 0.6498 - val_accuracy: 0.6667\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6270 - accuracy: 0.7385 - val_loss: 0.6455 - val_accuracy: 0.6970\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6218 - accuracy: 0.7538 - val_loss: 0.6400 - val_accuracy: 0.6970\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6159 - accuracy: 0.7846 - val_loss: 0.6357 - val_accuracy: 0.7576\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6116 - accuracy: 0.7846 - val_loss: 0.6343 - val_accuracy: 0.7879\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6097 - accuracy: 0.7846 - val_loss: 0.6308 - val_accuracy: 0.7879\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6055 - accuracy: 0.7846 - val_loss: 0.6291 - val_accuracy: 0.7879\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6033 - accuracy: 0.7692 - val_loss: 0.6254 - val_accuracy: 0.8182\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6011 - accuracy: 0.8000 - val_loss: 0.6217 - val_accuracy: 0.8182\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5965 - accuracy: 0.8000 - val_loss: 0.6183 - val_accuracy: 0.8182\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5929 - accuracy: 0.8000 - val_loss: 0.6142 - val_accuracy: 0.8182\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5889 - accuracy: 0.8308 - val_loss: 0.6118 - val_accuracy: 0.8182\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5853 - accuracy: 0.8308 - val_loss: 0.6063 - val_accuracy: 0.8182\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5802 - accuracy: 0.8308 - val_loss: 0.6021 - val_accuracy: 0.8182\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5761 - accuracy: 0.8308 - val_loss: 0.5964 - val_accuracy: 0.8182\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5702 - accuracy: 0.8308 - val_loss: 0.5920 - val_accuracy: 0.8182\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5658 - accuracy: 0.8308 - val_loss: 0.5892 - val_accuracy: 0.8182\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5620 - accuracy: 0.8462 - val_loss: 0.5859 - val_accuracy: 0.8182\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5577 - accuracy: 0.8462 - val_loss: 0.5819 - val_accuracy: 0.8182\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5533 - accuracy: 0.8308 - val_loss: 0.5774 - val_accuracy: 0.8182\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5484 - accuracy: 0.8308 - val_loss: 0.5744 - val_accuracy: 0.8182\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5440 - accuracy: 0.8308 - val_loss: 0.5716 - val_accuracy: 0.8182\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5399 - accuracy: 0.8462 - val_loss: 0.5691 - val_accuracy: 0.8182\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5361 - accuracy: 0.8462 - val_loss: 0.5645 - val_accuracy: 0.8182\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5311 - accuracy: 0.8462 - val_loss: 0.5621 - val_accuracy: 0.7879\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5267 - accuracy: 0.8615 - val_loss: 0.5582 - val_accuracy: 0.7879\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5223 - accuracy: 0.8769 - val_loss: 0.5536 - val_accuracy: 0.7879\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5174 - accuracy: 0.8615 - val_loss: 0.5485 - val_accuracy: 0.7879\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5124 - accuracy: 0.8615 - val_loss: 0.5452 - val_accuracy: 0.7879\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5077 - accuracy: 0.8615 - val_loss: 0.5425 - val_accuracy: 0.7879\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5038 - accuracy: 0.8615 - val_loss: 0.5400 - val_accuracy: 0.7879\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5001 - accuracy: 0.8769 - val_loss: 0.5351 - val_accuracy: 0.7879\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4954 - accuracy: 0.8615 - val_loss: 0.5307 - val_accuracy: 0.7879\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4904 - accuracy: 0.8615 - val_loss: 0.5282 - val_accuracy: 0.8182\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4867 - accuracy: 0.8615 - val_loss: 0.5251 - val_accuracy: 0.7879\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4824 - accuracy: 0.8615 - val_loss: 0.5212 - val_accuracy: 0.7879\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4777 - accuracy: 0.8615 - val_loss: 0.5170 - val_accuracy: 0.7879\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4724 - accuracy: 0.8615 - val_loss: 0.5139 - val_accuracy: 0.7879\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4683 - accuracy: 0.8615 - val_loss: 0.5113 - val_accuracy: 0.8182\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4640 - accuracy: 0.8615 - val_loss: 0.5096 - val_accuracy: 0.8182\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4613 - accuracy: 0.8615 - val_loss: 0.5060 - val_accuracy: 0.8182\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4574 - accuracy: 0.8615 - val_loss: 0.5029 - val_accuracy: 0.8182\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4529 - accuracy: 0.8615 - val_loss: 0.5006 - val_accuracy: 0.8182\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4486 - accuracy: 0.8615 - val_loss: 0.4979 - val_accuracy: 0.8182\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4447 - accuracy: 0.8615 - val_loss: 0.4962 - val_accuracy: 0.8182\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4435 - accuracy: 0.8615 - val_loss: 0.4921 - val_accuracy: 0.8182\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4396 - accuracy: 0.8615 - val_loss: 0.4921 - val_accuracy: 0.8182\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4384 - accuracy: 0.8615 - val_loss: 0.4891 - val_accuracy: 0.8182\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4342 - accuracy: 0.8615 - val_loss: 0.4860 - val_accuracy: 0.8182\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4310 - accuracy: 0.8769 - val_loss: 0.4840 - val_accuracy: 0.8182\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4275 - accuracy: 0.8769 - val_loss: 0.4813 - val_accuracy: 0.8182\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4235 - accuracy: 0.8769 - val_loss: 0.4795 - val_accuracy: 0.8182\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4207 - accuracy: 0.8769 - val_loss: 0.4773 - val_accuracy: 0.8182\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4171 - accuracy: 0.8769 - val_loss: 0.4737 - val_accuracy: 0.8182\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4132 - accuracy: 0.8769 - val_loss: 0.4718 - val_accuracy: 0.8182\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4104 - accuracy: 0.8769 - val_loss: 0.4717 - val_accuracy: 0.8182\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4100 - accuracy: 0.8769 - val_loss: 0.4704 - val_accuracy: 0.8182\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4084 - accuracy: 0.8769 - val_loss: 0.4674 - val_accuracy: 0.8182\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4052 - accuracy: 0.8923 - val_loss: 0.4651 - val_accuracy: 0.8485\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4030 - accuracy: 0.9077 - val_loss: 0.4623 - val_accuracy: 0.8485\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3986 - accuracy: 0.8923 - val_loss: 0.4604 - val_accuracy: 0.8485\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3953 - accuracy: 0.8923 - val_loss: 0.4589 - val_accuracy: 0.8485\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3922 - accuracy: 0.8923 - val_loss: 0.4574 - val_accuracy: 0.8485\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3897 - accuracy: 0.8923 - val_loss: 0.4563 - val_accuracy: 0.8485\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3873 - accuracy: 0.9077 - val_loss: 0.4534 - val_accuracy: 0.8182\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3828 - accuracy: 0.9077 - val_loss: 0.4515 - val_accuracy: 0.8182\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3799 - accuracy: 0.9077 - val_loss: 0.4494 - val_accuracy: 0.8182\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3748 - accuracy: 0.9077 - val_loss: 0.4478 - val_accuracy: 0.8182\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3720 - accuracy: 0.9077 - val_loss: 0.4466 - val_accuracy: 0.8182\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3690 - accuracy: 0.9077 - val_loss: 0.4451 - val_accuracy: 0.8182\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3652 - accuracy: 0.8923 - val_loss: 0.4435 - val_accuracy: 0.8182\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3612 - accuracy: 0.8923 - val_loss: 0.4417 - val_accuracy: 0.8182\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3585 - accuracy: 0.8923 - val_loss: 0.4399 - val_accuracy: 0.8182\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3550 - accuracy: 0.8923 - val_loss: 0.4388 - val_accuracy: 0.8182\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3525 - accuracy: 0.8923 - val_loss: 0.4383 - val_accuracy: 0.8182\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3512 - accuracy: 0.9077 - val_loss: 0.4354 - val_accuracy: 0.8182\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3470 - accuracy: 0.9077 - val_loss: 0.4343 - val_accuracy: 0.8182\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3430 - accuracy: 0.9077 - val_loss: 0.4344 - val_accuracy: 0.8182\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3416 - accuracy: 0.9077 - val_loss: 0.4323 - val_accuracy: 0.8182\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3390 - accuracy: 0.9077 - val_loss: 0.4314 - val_accuracy: 0.8182\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3371 - accuracy: 0.9077 - val_loss: 0.4301 - val_accuracy: 0.8182\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3343 - accuracy: 0.9077 - val_loss: 0.4285 - val_accuracy: 0.8182\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3326 - accuracy: 0.9077 - val_loss: 0.4275 - val_accuracy: 0.8182\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3303 - accuracy: 0.9077 - val_loss: 0.4272 - val_accuracy: 0.8182\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3306 - accuracy: 0.9077 - val_loss: 0.4260 - val_accuracy: 0.8182\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.3274 - accuracy: 0.9077 - val_loss: 0.4247 - val_accuracy: 0.8182\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3252 - accuracy: 0.9077 - val_loss: 0.4225 - val_accuracy: 0.8182\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3214 - accuracy: 0.9077 - val_loss: 0.4212 - val_accuracy: 0.8182\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3181 - accuracy: 0.9077 - val_loss: 0.4204 - val_accuracy: 0.8182\n",
      "3.4992 seconds elapsed.\n"
     ]
    }
   ],
   "source": [
    "print('----START PART C13: SGD Optimizer test----')\n",
    "tic = time.time()\n",
    "modelC13.fit(X_train_std, y_train,\n",
    "             validation_data=(X_test_std, y_test),\n",
    "             epochs=100, batch_size=32)\n",
    "toc = time.time()\n",
    "print(f'{(toc - tic):.04f} seconds elapsed.')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T22:50:52.449648900Z",
     "start_time": "2023-12-02T22:50:48.933614200Z"
    }
   },
   "id": "5c54d128f7e584fe"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Experiment C14 (Set first hidden layer neuron count to 8):\n",
    "* Explore how changing first hidden layer neuron count to 8 from 16 \n",
    "  impacts model performance \n",
    "* Still using 2 hidden layers\n",
    "\n",
    "All other parameters are the same as C1\n",
    "\n",
    "Create new model C14\n",
    "Standardized Data\n",
    "De-Correlation: None\n",
    "* Input Layer: 7 neurons\n",
    "* Hidden Layers: 2\n",
    "    * Layer 1: 8 neurons; RELU\n",
    "    * Layer 2: 16 neurons; RELU\n",
    "* Output Layer: 1 neuron; Sigmoid\n",
    "* Loss fn: Binary Cross Entropy\n",
    "* Optimizer: adam\n",
    "* Metrics: Accuracy\n",
    "\n",
    "Hyperparams:\n",
    "* Epochs: 100\n",
    "* Train-Test Split: 67/33\n",
    "* Batch Size: 32"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6a8722ff301e7298"
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part C14 model constructed\n"
     ]
    }
   ],
   "source": [
    "# C14: batch size to 32. No correlation drops. 100 Epochs.\n",
    "# C1 but use set first hidden layer to 8 neurons\n",
    "modelC14 = keras.Sequential()\n",
    "modelC14.add(layers.Dense(8, input_shape=(7,),\n",
    "                          activation='relu'))\n",
    "modelC14.add(layers.Dense(16, activation='relu'))\n",
    "modelC14.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "modelC14.compile(loss=\"binary_crossentropy\", optimizer='adam',\n",
    "                 metrics=['accuracy'])\n",
    "print('Part C14 model constructed')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T22:56:43.256575100Z",
     "start_time": "2023-12-02T22:56:43.213258500Z"
    }
   },
   "id": "51ff192f01e6a97b"
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----START PART C14: 8 hidden layer neurons test----\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 1s 68ms/step - loss: 0.7201 - accuracy: 0.4923 - val_loss: 0.6300 - val_accuracy: 0.5455\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.7092 - accuracy: 0.4923 - val_loss: 0.6233 - val_accuracy: 0.5455\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6997 - accuracy: 0.4923 - val_loss: 0.6174 - val_accuracy: 0.5455\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6924 - accuracy: 0.4923 - val_loss: 0.6118 - val_accuracy: 0.5455\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6850 - accuracy: 0.5077 - val_loss: 0.6062 - val_accuracy: 0.5455\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6781 - accuracy: 0.5077 - val_loss: 0.6007 - val_accuracy: 0.5758\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6712 - accuracy: 0.5077 - val_loss: 0.5953 - val_accuracy: 0.5758\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6647 - accuracy: 0.5077 - val_loss: 0.5906 - val_accuracy: 0.5758\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6579 - accuracy: 0.5077 - val_loss: 0.5863 - val_accuracy: 0.5758\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6520 - accuracy: 0.5077 - val_loss: 0.5819 - val_accuracy: 0.5758\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6460 - accuracy: 0.5077 - val_loss: 0.5776 - val_accuracy: 0.5758\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6403 - accuracy: 0.5231 - val_loss: 0.5731 - val_accuracy: 0.6061\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6344 - accuracy: 0.5231 - val_loss: 0.5690 - val_accuracy: 0.6364\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6296 - accuracy: 0.5385 - val_loss: 0.5652 - val_accuracy: 0.6364\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6250 - accuracy: 0.5846 - val_loss: 0.5616 - val_accuracy: 0.6667\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6204 - accuracy: 0.5846 - val_loss: 0.5582 - val_accuracy: 0.6667\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6158 - accuracy: 0.6154 - val_loss: 0.5547 - val_accuracy: 0.6364\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6108 - accuracy: 0.6154 - val_loss: 0.5512 - val_accuracy: 0.6667\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6059 - accuracy: 0.6308 - val_loss: 0.5480 - val_accuracy: 0.6667\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6014 - accuracy: 0.6923 - val_loss: 0.5450 - val_accuracy: 0.6364\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5970 - accuracy: 0.7077 - val_loss: 0.5420 - val_accuracy: 0.6364\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5924 - accuracy: 0.7231 - val_loss: 0.5388 - val_accuracy: 0.6667\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5876 - accuracy: 0.7692 - val_loss: 0.5354 - val_accuracy: 0.7273\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.5831 - accuracy: 0.7692 - val_loss: 0.5319 - val_accuracy: 0.7273\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5783 - accuracy: 0.7692 - val_loss: 0.5284 - val_accuracy: 0.7273\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5733 - accuracy: 0.8000 - val_loss: 0.5252 - val_accuracy: 0.7273\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5690 - accuracy: 0.8154 - val_loss: 0.5225 - val_accuracy: 0.7576\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5646 - accuracy: 0.8000 - val_loss: 0.5199 - val_accuracy: 0.7576\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5607 - accuracy: 0.8000 - val_loss: 0.5170 - val_accuracy: 0.7576\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5566 - accuracy: 0.8000 - val_loss: 0.5140 - val_accuracy: 0.7576\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5527 - accuracy: 0.8000 - val_loss: 0.5113 - val_accuracy: 0.7879\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5490 - accuracy: 0.8000 - val_loss: 0.5088 - val_accuracy: 0.7879\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5452 - accuracy: 0.8000 - val_loss: 0.5062 - val_accuracy: 0.7879\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5411 - accuracy: 0.8000 - val_loss: 0.5036 - val_accuracy: 0.7879\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5370 - accuracy: 0.8000 - val_loss: 0.5012 - val_accuracy: 0.7879\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5333 - accuracy: 0.8154 - val_loss: 0.4985 - val_accuracy: 0.7879\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5293 - accuracy: 0.8154 - val_loss: 0.4957 - val_accuracy: 0.7879\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.5250 - accuracy: 0.7846 - val_loss: 0.4928 - val_accuracy: 0.7879\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5211 - accuracy: 0.7846 - val_loss: 0.4898 - val_accuracy: 0.7879\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5168 - accuracy: 0.7846 - val_loss: 0.4869 - val_accuracy: 0.7879\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5128 - accuracy: 0.7846 - val_loss: 0.4843 - val_accuracy: 0.7879\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5090 - accuracy: 0.8000 - val_loss: 0.4821 - val_accuracy: 0.7879\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5056 - accuracy: 0.8154 - val_loss: 0.4796 - val_accuracy: 0.7879\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5017 - accuracy: 0.8308 - val_loss: 0.4771 - val_accuracy: 0.7879\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4974 - accuracy: 0.8308 - val_loss: 0.4746 - val_accuracy: 0.7879\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4935 - accuracy: 0.8308 - val_loss: 0.4721 - val_accuracy: 0.7879\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4894 - accuracy: 0.8462 - val_loss: 0.4699 - val_accuracy: 0.7879\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4855 - accuracy: 0.8308 - val_loss: 0.4682 - val_accuracy: 0.7879\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4818 - accuracy: 0.8308 - val_loss: 0.4664 - val_accuracy: 0.7879\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4778 - accuracy: 0.8308 - val_loss: 0.4645 - val_accuracy: 0.8182\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4739 - accuracy: 0.8308 - val_loss: 0.4626 - val_accuracy: 0.7879\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4696 - accuracy: 0.8308 - val_loss: 0.4608 - val_accuracy: 0.7879\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4653 - accuracy: 0.8308 - val_loss: 0.4590 - val_accuracy: 0.7879\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4612 - accuracy: 0.8308 - val_loss: 0.4572 - val_accuracy: 0.7879\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4573 - accuracy: 0.8308 - val_loss: 0.4554 - val_accuracy: 0.7879\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4534 - accuracy: 0.8308 - val_loss: 0.4534 - val_accuracy: 0.7879\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4499 - accuracy: 0.8308 - val_loss: 0.4516 - val_accuracy: 0.7879\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4465 - accuracy: 0.8308 - val_loss: 0.4500 - val_accuracy: 0.7879\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4431 - accuracy: 0.8308 - val_loss: 0.4486 - val_accuracy: 0.7879\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4395 - accuracy: 0.8308 - val_loss: 0.4472 - val_accuracy: 0.7879\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4358 - accuracy: 0.8308 - val_loss: 0.4460 - val_accuracy: 0.7879\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4320 - accuracy: 0.8308 - val_loss: 0.4448 - val_accuracy: 0.7879\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4284 - accuracy: 0.8308 - val_loss: 0.4437 - val_accuracy: 0.7879\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4252 - accuracy: 0.8308 - val_loss: 0.4425 - val_accuracy: 0.7879\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4219 - accuracy: 0.8308 - val_loss: 0.4414 - val_accuracy: 0.7879\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4188 - accuracy: 0.8308 - val_loss: 0.4403 - val_accuracy: 0.7879\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4160 - accuracy: 0.8308 - val_loss: 0.4391 - val_accuracy: 0.7879\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4129 - accuracy: 0.8308 - val_loss: 0.4380 - val_accuracy: 0.7879\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4098 - accuracy: 0.8308 - val_loss: 0.4369 - val_accuracy: 0.7879\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4064 - accuracy: 0.8308 - val_loss: 0.4358 - val_accuracy: 0.7879\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4029 - accuracy: 0.8462 - val_loss: 0.4348 - val_accuracy: 0.7879\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3991 - accuracy: 0.8462 - val_loss: 0.4339 - val_accuracy: 0.7879\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3957 - accuracy: 0.8462 - val_loss: 0.4331 - val_accuracy: 0.7879\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3924 - accuracy: 0.8462 - val_loss: 0.4324 - val_accuracy: 0.7879\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3893 - accuracy: 0.8462 - val_loss: 0.4316 - val_accuracy: 0.7879\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3858 - accuracy: 0.8462 - val_loss: 0.4309 - val_accuracy: 0.7879\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3821 - accuracy: 0.8615 - val_loss: 0.4302 - val_accuracy: 0.7879\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3785 - accuracy: 0.8769 - val_loss: 0.4296 - val_accuracy: 0.7879\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3752 - accuracy: 0.8769 - val_loss: 0.4291 - val_accuracy: 0.7879\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3718 - accuracy: 0.8769 - val_loss: 0.4286 - val_accuracy: 0.7879\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3684 - accuracy: 0.8769 - val_loss: 0.4281 - val_accuracy: 0.7879\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3651 - accuracy: 0.8769 - val_loss: 0.4277 - val_accuracy: 0.7879\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3617 - accuracy: 0.8769 - val_loss: 0.4273 - val_accuracy: 0.7879\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3584 - accuracy: 0.8615 - val_loss: 0.4269 - val_accuracy: 0.7879\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3547 - accuracy: 0.8769 - val_loss: 0.4265 - val_accuracy: 0.7879\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3512 - accuracy: 0.8923 - val_loss: 0.4262 - val_accuracy: 0.7879\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3478 - accuracy: 0.8923 - val_loss: 0.4260 - val_accuracy: 0.7879\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3445 - accuracy: 0.8923 - val_loss: 0.4258 - val_accuracy: 0.7879\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3417 - accuracy: 0.8923 - val_loss: 0.4257 - val_accuracy: 0.7879\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3389 - accuracy: 0.8923 - val_loss: 0.4255 - val_accuracy: 0.7879\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3361 - accuracy: 0.8923 - val_loss: 0.4256 - val_accuracy: 0.7879\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3333 - accuracy: 0.8923 - val_loss: 0.4256 - val_accuracy: 0.7879\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3309 - accuracy: 0.8923 - val_loss: 0.4257 - val_accuracy: 0.7879\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3282 - accuracy: 0.8923 - val_loss: 0.4260 - val_accuracy: 0.7879\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3251 - accuracy: 0.8923 - val_loss: 0.4263 - val_accuracy: 0.7879\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3223 - accuracy: 0.8923 - val_loss: 0.4266 - val_accuracy: 0.7879\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3201 - accuracy: 0.8923 - val_loss: 0.4270 - val_accuracy: 0.7879\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3180 - accuracy: 0.8769 - val_loss: 0.4275 - val_accuracy: 0.7879\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3158 - accuracy: 0.8769 - val_loss: 0.4279 - val_accuracy: 0.7879\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3140 - accuracy: 0.8769 - val_loss: 0.4283 - val_accuracy: 0.7879\n",
      "3.8685 seconds elapsed.\n"
     ]
    }
   ],
   "source": [
    "print('----START PART C14: 8 hidden layer neurons test----')\n",
    "tic = time.time()\n",
    "modelC14.fit(X_train_std, y_train,\n",
    "             validation_data=(X_test_std, y_test),\n",
    "             epochs=100, batch_size=32)\n",
    "toc = time.time()\n",
    "print(f'{(toc - tic):.04f} seconds elapsed.')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T22:57:01.206394900Z",
     "start_time": "2023-12-02T22:56:57.328856800Z"
    }
   },
   "id": "7498ec4415081bef"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Experiment C15 (Nadam optimizer, Train Test 30:70, Epoch 80, Batch 16):\n",
    "* Explore how changing optimizer to Nadam, Train test split to 30:70,\n",
    "  number of epochs to 80, and batch size to 16  \n",
    "  impacts model performance \n",
    "* Still using 2 hidden layers\n",
    "\n",
    "All other parameters are the same as C1\n",
    "\n",
    "Create new model C15\n",
    "Standardized Data\n",
    "De-Correlation: None\n",
    "* Input Layer: 7 neurons\n",
    "* Hidden Layers: 2\n",
    "    * Layer 1: 16 neurons; RELU\n",
    "    * Layer 2: 16 neurons; RELU\n",
    "* Output Layer: 1 neuron; Sigmoid\n",
    "* Loss fn: Binary Cross Entropy\n",
    "* Optimizer: Nadam\n",
    "* Metrics: Accuracy\n",
    "\n",
    "Hyperparams:\n",
    "* Epochs: 80\n",
    "* Train-Test Split: 30:70\n",
    "* Batch Size: 16"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1273a280b0f1f59c"
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part C15 model constructed\n"
     ]
    }
   ],
   "source": [
    "# C15: batch size to 16. No correlation drops. 80 Epochs.\n",
    "# Set Train:test to 30:70.\n",
    "# Set optimizer to Nadam\n",
    "\n",
    "modelC15 = keras.Sequential()\n",
    "modelC15.add(layers.Dense(16, input_shape=(7,),\n",
    "                          activation='relu'))\n",
    "modelC15.add(layers.Dense(16, activation='relu'))\n",
    "modelC15.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "modelC15.compile(loss=\"binary_crossentropy\", optimizer='Nadam',\n",
    "                 metrics=['accuracy'])\n",
    "print('Part C15 model constructed')\n",
    "\n",
    "# 30% train, 70% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y,\n",
    "                                                    test_size=0.70,\n",
    "                                                    random_state=seed)\n",
    "\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T23:01:10.416122700Z",
     "start_time": "2023-12-02T23:01:10.351960800Z"
    }
   },
   "id": "50bc2b7a51192054"
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----START PART C15: custom test----\n",
      "Epoch 1/80\n",
      "2/2 [==============================] - 1s 131ms/step - loss: 0.6737 - accuracy: 0.6207 - val_loss: 0.6784 - val_accuracy: 0.5942\n",
      "Epoch 2/80\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6665 - accuracy: 0.6207 - val_loss: 0.6732 - val_accuracy: 0.5797\n",
      "Epoch 3/80\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6595 - accuracy: 0.6207 - val_loss: 0.6677 - val_accuracy: 0.5652\n",
      "Epoch 4/80\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6529 - accuracy: 0.6552 - val_loss: 0.6625 - val_accuracy: 0.5507\n",
      "Epoch 5/80\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6444 - accuracy: 0.6552 - val_loss: 0.6568 - val_accuracy: 0.5652\n",
      "Epoch 6/80\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6367 - accuracy: 0.6897 - val_loss: 0.6509 - val_accuracy: 0.5797\n",
      "Epoch 7/80\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6289 - accuracy: 0.6897 - val_loss: 0.6448 - val_accuracy: 0.5942\n",
      "Epoch 8/80\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6200 - accuracy: 0.7241 - val_loss: 0.6386 - val_accuracy: 0.6087\n",
      "Epoch 9/80\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6115 - accuracy: 0.7586 - val_loss: 0.6321 - val_accuracy: 0.6232\n",
      "Epoch 10/80\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6032 - accuracy: 0.7931 - val_loss: 0.6257 - val_accuracy: 0.6377\n",
      "Epoch 11/80\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5942 - accuracy: 0.7931 - val_loss: 0.6192 - val_accuracy: 0.6522\n",
      "Epoch 12/80\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5851 - accuracy: 0.8276 - val_loss: 0.6127 - val_accuracy: 0.6667\n",
      "Epoch 13/80\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5756 - accuracy: 0.8621 - val_loss: 0.6062 - val_accuracy: 0.6812\n",
      "Epoch 14/80\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5668 - accuracy: 0.8966 - val_loss: 0.5997 - val_accuracy: 0.6957\n",
      "Epoch 15/80\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.5575 - accuracy: 0.8966 - val_loss: 0.5932 - val_accuracy: 0.6957\n",
      "Epoch 16/80\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5488 - accuracy: 0.8966 - val_loss: 0.5867 - val_accuracy: 0.6957\n",
      "Epoch 17/80\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5403 - accuracy: 0.8966 - val_loss: 0.5804 - val_accuracy: 0.6957\n",
      "Epoch 18/80\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5312 - accuracy: 0.8966 - val_loss: 0.5739 - val_accuracy: 0.7101\n",
      "Epoch 19/80\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5222 - accuracy: 0.8966 - val_loss: 0.5676 - val_accuracy: 0.6957\n",
      "Epoch 20/80\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.5134 - accuracy: 0.8966 - val_loss: 0.5614 - val_accuracy: 0.6957\n",
      "Epoch 21/80\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.5048 - accuracy: 0.9310 - val_loss: 0.5554 - val_accuracy: 0.6957\n",
      "Epoch 22/80\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4959 - accuracy: 0.9310 - val_loss: 0.5496 - val_accuracy: 0.6957\n",
      "Epoch 23/80\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.4874 - accuracy: 0.9310 - val_loss: 0.5440 - val_accuracy: 0.6957\n",
      "Epoch 24/80\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4785 - accuracy: 0.9310 - val_loss: 0.5384 - val_accuracy: 0.6957\n",
      "Epoch 25/80\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4702 - accuracy: 0.9310 - val_loss: 0.5332 - val_accuracy: 0.6957\n",
      "Epoch 26/80\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.4616 - accuracy: 0.9310 - val_loss: 0.5281 - val_accuracy: 0.7101\n",
      "Epoch 27/80\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4527 - accuracy: 0.9310 - val_loss: 0.5233 - val_accuracy: 0.7101\n",
      "Epoch 28/80\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4440 - accuracy: 0.9310 - val_loss: 0.5185 - val_accuracy: 0.7246\n",
      "Epoch 29/80\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4364 - accuracy: 0.9310 - val_loss: 0.5138 - val_accuracy: 0.7246\n",
      "Epoch 30/80\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.4286 - accuracy: 0.9310 - val_loss: 0.5094 - val_accuracy: 0.7246\n",
      "Epoch 31/80\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.4206 - accuracy: 0.9310 - val_loss: 0.5051 - val_accuracy: 0.7246\n",
      "Epoch 32/80\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.4129 - accuracy: 0.9310 - val_loss: 0.5010 - val_accuracy: 0.7246\n",
      "Epoch 33/80\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.4052 - accuracy: 0.9310 - val_loss: 0.4972 - val_accuracy: 0.7246\n",
      "Epoch 34/80\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.3975 - accuracy: 0.9310 - val_loss: 0.4936 - val_accuracy: 0.7246\n",
      "Epoch 35/80\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.3904 - accuracy: 0.9310 - val_loss: 0.4901 - val_accuracy: 0.7246\n",
      "Epoch 36/80\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.3831 - accuracy: 0.9310 - val_loss: 0.4868 - val_accuracy: 0.7246\n",
      "Epoch 37/80\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.3762 - accuracy: 0.9310 - val_loss: 0.4837 - val_accuracy: 0.7246\n",
      "Epoch 38/80\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.3693 - accuracy: 0.9310 - val_loss: 0.4808 - val_accuracy: 0.7246\n",
      "Epoch 39/80\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.3625 - accuracy: 0.9310 - val_loss: 0.4781 - val_accuracy: 0.7246\n",
      "Epoch 40/80\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.3555 - accuracy: 0.9310 - val_loss: 0.4756 - val_accuracy: 0.7246\n",
      "Epoch 41/80\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.3490 - accuracy: 0.9310 - val_loss: 0.4732 - val_accuracy: 0.7391\n",
      "Epoch 42/80\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.3424 - accuracy: 0.9310 - val_loss: 0.4711 - val_accuracy: 0.7391\n",
      "Epoch 43/80\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.3359 - accuracy: 0.9310 - val_loss: 0.4692 - val_accuracy: 0.7391\n",
      "Epoch 44/80\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.3298 - accuracy: 0.9310 - val_loss: 0.4676 - val_accuracy: 0.7391\n",
      "Epoch 45/80\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.3234 - accuracy: 0.9310 - val_loss: 0.4662 - val_accuracy: 0.7391\n",
      "Epoch 46/80\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.3174 - accuracy: 0.9310 - val_loss: 0.4647 - val_accuracy: 0.7536\n",
      "Epoch 47/80\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.3117 - accuracy: 0.9310 - val_loss: 0.4634 - val_accuracy: 0.7536\n",
      "Epoch 48/80\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.3059 - accuracy: 0.9310 - val_loss: 0.4621 - val_accuracy: 0.7536\n",
      "Epoch 49/80\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.3007 - accuracy: 0.9310 - val_loss: 0.4610 - val_accuracy: 0.7536\n",
      "Epoch 50/80\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.2950 - accuracy: 0.8966 - val_loss: 0.4598 - val_accuracy: 0.7536\n",
      "Epoch 51/80\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.2900 - accuracy: 0.8966 - val_loss: 0.4586 - val_accuracy: 0.7536\n",
      "Epoch 52/80\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.2851 - accuracy: 0.9310 - val_loss: 0.4576 - val_accuracy: 0.7536\n",
      "Epoch 53/80\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.2798 - accuracy: 0.9310 - val_loss: 0.4569 - val_accuracy: 0.7536\n",
      "Epoch 54/80\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.2754 - accuracy: 0.9310 - val_loss: 0.4562 - val_accuracy: 0.7681\n",
      "Epoch 55/80\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.2701 - accuracy: 0.9310 - val_loss: 0.4558 - val_accuracy: 0.7681\n",
      "Epoch 56/80\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.2657 - accuracy: 0.9310 - val_loss: 0.4556 - val_accuracy: 0.7681\n",
      "Epoch 57/80\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.2610 - accuracy: 0.9310 - val_loss: 0.4555 - val_accuracy: 0.7826\n",
      "Epoch 58/80\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.2569 - accuracy: 0.9310 - val_loss: 0.4557 - val_accuracy: 0.7826\n",
      "Epoch 59/80\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.2525 - accuracy: 0.9310 - val_loss: 0.4563 - val_accuracy: 0.7826\n",
      "Epoch 60/80\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.2486 - accuracy: 0.9310 - val_loss: 0.4571 - val_accuracy: 0.7826\n",
      "Epoch 61/80\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.2446 - accuracy: 0.9310 - val_loss: 0.4579 - val_accuracy: 0.7826\n",
      "Epoch 62/80\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.2407 - accuracy: 0.9655 - val_loss: 0.4589 - val_accuracy: 0.7826\n",
      "Epoch 63/80\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.2368 - accuracy: 0.9655 - val_loss: 0.4599 - val_accuracy: 0.7826\n",
      "Epoch 64/80\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.2334 - accuracy: 0.9655 - val_loss: 0.4609 - val_accuracy: 0.7826\n",
      "Epoch 65/80\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.2297 - accuracy: 0.9655 - val_loss: 0.4622 - val_accuracy: 0.7826\n",
      "Epoch 66/80\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.2260 - accuracy: 0.9655 - val_loss: 0.4638 - val_accuracy: 0.7826\n",
      "Epoch 67/80\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.2227 - accuracy: 0.9655 - val_loss: 0.4654 - val_accuracy: 0.7826\n",
      "Epoch 68/80\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.2192 - accuracy: 0.9655 - val_loss: 0.4669 - val_accuracy: 0.7826\n",
      "Epoch 69/80\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.2160 - accuracy: 0.9655 - val_loss: 0.4685 - val_accuracy: 0.7826\n",
      "Epoch 70/80\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.2129 - accuracy: 0.9655 - val_loss: 0.4702 - val_accuracy: 0.7826\n",
      "Epoch 71/80\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.2099 - accuracy: 0.9655 - val_loss: 0.4717 - val_accuracy: 0.7826\n",
      "Epoch 72/80\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.2070 - accuracy: 0.9655 - val_loss: 0.4736 - val_accuracy: 0.7826\n",
      "Epoch 73/80\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.2043 - accuracy: 0.9655 - val_loss: 0.4755 - val_accuracy: 0.7826\n",
      "Epoch 74/80\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.2015 - accuracy: 0.9655 - val_loss: 0.4773 - val_accuracy: 0.7826\n",
      "Epoch 75/80\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.1986 - accuracy: 0.9655 - val_loss: 0.4793 - val_accuracy: 0.7826\n",
      "Epoch 76/80\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.1959 - accuracy: 0.9655 - val_loss: 0.4814 - val_accuracy: 0.7826\n",
      "Epoch 77/80\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.1935 - accuracy: 0.9655 - val_loss: 0.4837 - val_accuracy: 0.7826\n",
      "Epoch 78/80\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1907 - accuracy: 0.9655 - val_loss: 0.4859 - val_accuracy: 0.7826\n",
      "Epoch 79/80\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.1884 - accuracy: 0.9655 - val_loss: 0.4883 - val_accuracy: 0.7826\n",
      "Epoch 80/80\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.1860 - accuracy: 0.9655 - val_loss: 0.4905 - val_accuracy: 0.7826\n",
      "3.6143 seconds elapsed.\n"
     ]
    }
   ],
   "source": [
    "print('----START PART C15: custom test----')\n",
    "tic = time.time()\n",
    "modelC15.fit(X_train_std, y_train,\n",
    "             validation_data=(X_test_std, y_test),\n",
    "             epochs=80, batch_size=16)\n",
    "toc = time.time()\n",
    "print(f'{(toc - tic):.04f} seconds elapsed.')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T23:01:39.115067900Z",
     "start_time": "2023-12-02T23:01:35.494666500Z"
    }
   },
   "id": "b490c923172e2b81"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Experiment C16 (Nadam optimizer, Train Test 30:70, Epoch 80, Batch 16):\n",
    "* Explore how changing optimizer to Nadam, Train test split to 30:70,\n",
    "  number of epochs to 80, and batch size to 16  \n",
    "  impacts model performance \n",
    "* Still using 2 hidden layers\n",
    "\n",
    "All other parameters are the same as C1\n",
    "\n",
    "Create new model C15\n",
    "Standardized Data\n",
    "De-Correlation: None\n",
    "* Input Layer: 7 neurons\n",
    "* Hidden Layers: 2\n",
    "    * Layer 1: 16 neurons; RELU\n",
    "    * Layer 2: 16 neurons; RELU\n",
    "* Output Layer: 1 neuron; Sigmoid\n",
    "* Loss fn: Binary Cross Entropy\n",
    "* Optimizer: Nadam\n",
    "* Metrics: Accuracy\n",
    "\n",
    "Hyperparams:\n",
    "* Epochs: 80\n",
    "* Train-Test Split: 30:70\n",
    "* Batch Size: 16"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "129043e6976830de"
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "# C16: ipynb playground\n",
    "# batch size to 16. No correlation drops. 80 Epochs.\n",
    "# Set Train:test to 30:70.\n",
    "# Set optimizer to Nadam\n",
    "\n",
    "modelC16 = keras.Sequential()\n",
    "modelC16.add(layers.Dense(16, input_shape=(7,),\n",
    "                          activation='relu'))\n",
    "modelC16.add(layers.Dense(16, activation='relu'))\n",
    "modelC16.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "modelC16.compile(loss=\"binary_crossentropy\", optimizer='Nadam',\n",
    "                 metrics=['accuracy'])\n",
    "print('Part C16 model constructed')\n",
    "\n",
    "# 30% train, 70% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y,\n",
    "                                                    test_size=0.70,\n",
    "                                                    random_state=seed)\n",
    "\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fda8937dd09988bd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('----START PART C16: Ipynb custom test----')\n",
    "tic = time.time()\n",
    "modelC16.fit(X_train_std, y_train,\n",
    "             validation_data=(X_test_std, y_test),\n",
    "             epochs=800, batch_size=16)\n",
    "toc = time.time()\n",
    "print(f'{(toc - tic):.04f} seconds elapsed.')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b48cfcf4199d3c57"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
